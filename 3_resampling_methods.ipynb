{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling Methods\n",
    "* two most commonly used resampling Methods\n",
    "\n",
    "(1) cross-validation\n",
    "\n",
    "(2) bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "lprice     float32\nlland      float32\nlarea      float32\nnbh       category\nrooms     category\ncbd        float32\ny81       category\nldist      float32\nbaths      float32\nage        float32\nagesq      float32\ndtype: object"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# download dataset to use throughout\n",
    "hprice3 = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/hprice3.dta')\n",
    "\n",
    "# pre-processing dataset\n",
    "## select interested columns\n",
    "col = ['lprice','lland','larea','nbh','rooms','cbd','y81','ldist','baths','age','agesq']\n",
    "df = hprice3[col]\n",
    "\n",
    "## change y81 and nbh to integers\n",
    "df[['y81','nbh', 'rooms']] = df[['y81','nbh','rooms']].astype(int) \n",
    "\n",
    "## change y81, nbh, rooms into categorical\n",
    "df['y81'] = df['y81'].astype('category')\n",
    "df['nbh'] = df['nbh'].astype(CategoricalDtype(ordered=False))\n",
    "df['rooms'] = df['rooms'].astype(CategoricalDtype(ordered=True))\n",
    "\n",
    "# view columns types of pre-processed dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "* these methods are used to do two things\n",
    "\n",
    "(1) Model Assessment: process of evaluating a model's performance\n",
    "\n",
    "(2) Model Selection: process of selecting the proper level of flexibility for a model\n",
    "\n",
    "* since models are 'trained' using training data sets, they are suitable to fit data in these training data sets only\n",
    "\n",
    "* since the validation set was not used to fit the model, these set of observations can be used to assess the performance of the model; therefore they allow us to do model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['lprice', 'lland', 'larea', 'cbd', 'ldist', 'baths', 'age', 'agesq',\n       'y81_1', 'nbh_1', 'nbh_2', 'nbh_3', 'nbh_4', 'nbh_5', 'nbh_6',\n       'rooms_5', 'rooms_6', 'rooms_7', 'rooms_8', 'rooms_9', 'rooms_10'],\n      dtype='object')"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continue preprocessing: convert categorical variables into dummy variables\n",
    "df1 = pd.get_dummies(df, columns=['y81', 'nbh','rooms'], drop_first = True)\n",
    "\n",
    "# get list of columns\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set Approach\n",
    "\n",
    "![](img\\validation_set_approach.png)\n",
    "\n",
    "* set of n observations are randomly split into a training set (in blue with other obs) and a validation set (in beige containing other obs)\n",
    "\n",
    "* the stat learning method is fit onto the training set\n",
    "\n",
    "* performance evaluated on the validation set\n",
    "\n",
    "* can be doing many (i.e j) times randomly, then all model assessment measures such as RMSE, R2, Cp, BIC, and AIC can be calculated many (i.e j) times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-9e4eecba3cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# run regression and do fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# predict testing set with training set regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m   1532\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1533\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import patsy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# separate dataframe while preserving datatypes (pmatrices disregards categorical variables)\n",
    "X = df1[list(df1[1:21])]\n",
    "y = df1[['lprice']]\n",
    "\n",
    "# do validation set splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# run regression and do fit\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train) # not sure how to fix error\n",
    "\n",
    "# predict testing set with training set regression\n",
    "reg.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe into numpy array\n",
    "df1_array = df1.to_numpy()\n",
    "\n",
    "# create specification using dataframe column object\n",
    "predictors = \" + \".join(list(df1.columns[1:15]))\n",
    "f = \" ~ \".join(['lprice',predictors])\n",
    "\n",
    "predict = reg.predict(X_test)\n",
    "\n",
    "#\n"
   ]
  }
 ]
}