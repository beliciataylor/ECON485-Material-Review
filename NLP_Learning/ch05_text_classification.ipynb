{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "* Data Retrieval\n",
    "* Data Preprocessing and Normalization\n",
    "* Building Train and Test Datasets\n",
    "* Feature Engineering Techniques\n",
    "    1. Traditional\n",
    "    2. Advanced\n",
    "* Classification Models\n",
    "    1. Multinomial Naive Bayes\n",
    "    2. Logistic Regression\n",
    "    3. Support Vector Machines\n",
    "    4. Ensemble Models\n",
    "    5. Random Forest\n",
    "    6. Gradient Boosting Machines\n",
    "* Evaluating Classification Models\n",
    "    1. Confusion Matrix\n",
    "* Building and Evaluating Our Text Classifier\n",
    "    1. Bag of Words Features with Classification Models\n",
    "    2. TF-IDF Features with Classification Models\n",
    "    3. Comparative Model Performance Evaluation\n",
    "    4. Word2Vec Embeddings with Classification Models\n",
    "    5. GloVe Embeddings with Classification Models\n",
    "    6. FastText Embeddings with Classification Models\n",
    "    7. Model Tuning\n",
    "    8. Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import nltk\n",
    "import text_normalizer as tn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = fetch_20newsgroups(subset='all', shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
    "data_labels_map = dict(enumerate(data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nBack in high school I worked as a lab assi...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nAE is in Dallas...try 214/241-6060 or 214/...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n[stuff deleted]\\n\\nOk, here's the solution t...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n\\nYeah, it's the second one.  And I believ...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nIf a Christian means someone who believes in...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Target Label  \\\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...            10   \n",
       "1  My brother is in the market for a high-perform...             3   \n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...            17   \n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...             3   \n",
       "4  1)    I have an old Jasmine drive which I cann...             4   \n",
       "5  \\n\\nBack in high school I worked as a lab assi...            12   \n",
       "6  \\n\\nAE is in Dallas...try 214/241-6060 or 214/...             4   \n",
       "7  \\n[stuff deleted]\\n\\nOk, here's the solution t...            10   \n",
       "8  \\n\\n\\nYeah, it's the second one.  And I believ...            10   \n",
       "9  \\nIf a Christian means someone who believes in...            19   \n",
       "\n",
       "                Target Name  \n",
       "0          rec.sport.hockey  \n",
       "1  comp.sys.ibm.pc.hardware  \n",
       "2     talk.politics.mideast  \n",
       "3  comp.sys.ibm.pc.hardware  \n",
       "4     comp.sys.mac.hardware  \n",
       "5           sci.electronics  \n",
       "6     comp.sys.mac.hardware  \n",
       "7          rec.sport.hockey  \n",
       "8          rec.sport.hockey  \n",
       "9        talk.religion.misc  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building the dataframe\n",
    "corpus, target_labels, target_names = (data.data, data.target, [data_labels_map[label] for label in data.target])\n",
    "data_df = pd.DataFrame({'Article': corpus, 'Target Label': target_labels, 'Target Name': target_names})\n",
    "print(data_df.shape)\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty documents: 515\n"
     ]
    }
   ],
   "source": [
    "total_nulls = data_df[data_df.Article.str.strip() == ''].shape[0]\n",
    "print(\"Empty documents:\", total_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18331, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all recrods with no textual content \n",
    "data_df = data_df[~(data_df.Article.str.strip() == '')]\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# just to keep negation if any in bi-grams\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "# normalize our corpus\n",
    "norm_corpus = tn.normalize_corpus(corpus=data_df['Article'], html_stripping=True, contraction_expansion=True, \n",
    "                                  accented_char_removal=True, text_lower_case=True, text_lemmatization=True, \n",
    "                                  text_stemming=False, special_char_removal=True, remove_digits=True, \n",
    "                                  stopword_removal=True, stopwords=stopword_list)\n",
    "\n",
    "data_df['Clean Article'] = norm_corpus\n",
    "\n",
    "# view sample data\n",
    "data_df = data_df[['Article', 'Clean Article', 'Target Label', 'Target Name']]\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.replace(r'^(\\s?)+$', np.nan, regex=True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
