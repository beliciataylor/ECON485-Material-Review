{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Analysis\n",
    "* Exploring WordNet\n",
    "    1. Understanding Synsets\n",
    "    2. Analyzing Lexical Semantic Relationships\n",
    "* Word Sense Disambiguity\n",
    "* Named Entity Recognition\n",
    "* Building an NER Tagger from Scratch\n",
    "* Building an End-to-End NER Tagger with Our Trained NER Model\n",
    "* Analyzing Semantic Representations\n",
    "    1. Propositional Logic\n",
    "    2. First Order Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring WordNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Synsets: 5\n"
    }
   ],
   "source": [
    "## Understanding Synsets\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "term = 'fruit'\n",
    "synsets = wn.synsets(term)\n",
    "# display total synsets\n",
    "print('Total Synsets:', len(synsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 Synset Part of Speech  \\\n0  Synset('fruit.n.01')     noun.plant   \n1  Synset('yield.n.03')  noun.artifact   \n2  Synset('fruit.n.03')     noun.event   \n3  Synset('fruit.v.01')  verb.creation   \n4  Synset('fruit.v.02')  verb.creation   \n\n                                      Definition          Lemmas  \\\n0  the ripened reproductive body of a seed plant         [fruit]   \n1                         an amount of a product  [yield, fruit]   \n2       the consequence of some effort or action         [fruit]   \n3                            cause to bear fruit         [fruit]   \n4                                     bear fruit         [fruit]   \n\n                                                  Examples  \n0                                                       []  \n1                                                       []  \n2  [he lived long enough to see the fruit of his policies]  \n3                                                       []  \n4                      [the trees fruited early this year]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Synset</th>\n      <th>Part of Speech</th>\n      <th>Definition</th>\n      <th>Lemmas</th>\n      <th>Examples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Synset('fruit.n.01')</td>\n      <td>noun.plant</td>\n      <td>the ripened reproductive body of a seed plant</td>\n      <td>[fruit]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Synset('yield.n.03')</td>\n      <td>noun.artifact</td>\n      <td>an amount of a product</td>\n      <td>[yield, fruit]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Synset('fruit.n.03')</td>\n      <td>noun.event</td>\n      <td>the consequence of some effort or action</td>\n      <td>[fruit]</td>\n      <td>[he lived long enough to see the fruit of his policies]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Synset('fruit.v.01')</td>\n      <td>verb.creation</td>\n      <td>cause to bear fruit</td>\n      <td>[fruit]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Synset('fruit.v.02')</td>\n      <td>verb.creation</td>\n      <td>bear fruit</td>\n      <td>[fruit]</td>\n      <td>[the trees fruited early this year]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "fruit_df = pd.DataFrame([{'Synset': synset, \n",
    "                          'Part of Speech': synset.lexname(), \n",
    "                          'Definition': synset.definition(), \n",
    "                          'Lemmas': synset.lemma_names(), \n",
    "                          'Examples': synset.examples()}\n",
    "                                for synset in synsets])\n",
    "fruit_df = fruit_df[['Synset', 'Part of Speech', 'Definition', 'Lemmas', 'Examples']]\n",
    "fruit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Synset('walk.v.01') -- entails --> [Synset('step.v.01')]\nSynset('eat.v.01') -- entails --> [Synset('chew.v.01'), Synset('swallow.v.01')]\nSynset('digest.v.01') -- entails --> [Synset('consume.v.02')]\n"
    }
   ],
   "source": [
    "## Analyzing Lexical Semantic Relationships\n",
    "### Entailments\n",
    "for action in ['walk', 'eat', 'digest']:\n",
    "    action_syn = wn.synsets(action, pos='v')[0]\n",
    "    print(action_syn, '-- entails -->', action_syn.entailments())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "bank.n.01 - sloping land (especially the slope beside a body of water)\ndepository_financial_institution.n.01 - a financial institution that accepts deposits and channels the money into lending activities\nbank.n.03 - a long ridge or pile\nbank.n.04 - an arrangement of similar objects in a row or in tiers\nbank.n.05 - a supply or stock held in reserve for future use (especially in emergencies)\nbank.n.06 - the funds held by a gambling house or the dealer in some gambling games\nbank.n.07 - a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\nsavings_bank.n.02 - a container (usually with a slot in the top) for keeping money at home\nbank.n.09 - a building in which the business of banking transacted\nbank.n.10 - a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\nbank.v.01 - tip laterally\nbank.v.02 - enclose with a bank\nbank.v.03 - do business with a bank or keep an account at a bank\nbank.v.04 - act as the banker in a game or in gambling\nbank.v.05 - be in the banking business\ndeposit.v.02 - put into a bank account\nbank.v.07 - cover with ashes so to control the rate of burning\ntrust.v.01 - have confidence or faith in\n"
    }
   ],
   "source": [
    "### Homonyms and Homographs\n",
    "for synset in wn.synsets('bank'):\n",
    "    print(synset.name(), '-', synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Synonym: large.a.01\nDefinition: above average in size or number or quantity or magnitude or extent\nAntonym: small.a.01\nDefinition: limited or below average in number or quantity or magnitude or extent\n"
    }
   ],
   "source": [
    "### Synonyms and Antonyms\n",
    "term = 'large'\n",
    "synsets = wn.synsets(term)\n",
    "adj_large = synsets[1]\n",
    "adj_large = adj_large.lemmas()[0]\n",
    "adj_large_synonym = adj_large.synset()\n",
    "adj_large_antonym = adj_large.antonyms()[0].synset()\n",
    "\n",
    "print('Synonym:', adj_large_synonym.name())\n",
    "print('Definition:', adj_large_synonym.definition())\n",
    "print('Antonym:', adj_large_antonym.name())\n",
    "print('Definition:', adj_large_antonym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Synonym: rich_people.n.01\nDefinition: people who have possessions and wealth (considered as a group)\nAntonym: poor_people.n.01\nDefinition: people without possessions or wealth (considered as a group)\n\nSynonym: rich.a.01\nDefinition: possessing material wealth\nAntonym: poor.a.02\nDefinition: having little money or few possessions\n\nSynonym: rich.a.02\nDefinition: having an abundant supply of desirable qualities or substances (especially natural resources)\nAntonym: poor.a.04\nDefinition: lacking in specific resources, qualities or substances\n\n"
    }
   ],
   "source": [
    "term = 'rich'\n",
    "synsets = wn.synsets(term)[:3]\n",
    "\n",
    "for synset in synsets:\n",
    "    rich = synset.lemmas()[0]\n",
    "    rich_synonym = rich.synset()\n",
    "    rich_antonym = rich.antonyms()[0].synset()\n",
    "\n",
    "    print('Synonym:', rich_synonym.name())\n",
    "    print('Definition:', rich_synonym.definition())\n",
    "    print('Antonym:', rich_antonym.name())\n",
    "    print('Definition:', rich_antonym.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Name: tree.n.01\nDefinition: a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n"
    }
   ],
   "source": [
    "### Hyponyms and Hypernyms\n",
    "term = 'tree'\n",
    "synsets = wn.synsets(term)\n",
    "tree = synsets[0]\n",
    "\n",
    "print('Name:', tree.name())\n",
    "print('Definition:', tree.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Hyponyms: 180\nSample Hyponyms\naalii.n.01 - a small Hawaiian tree with hard dark wood\n\nacacia.n.01 - any of various spiny trees or shrubs of the genus Acacia\n\nafrican_walnut.n.01 - tropical African timber tree with wood that resembles mahogany\n\nalbizzia.n.01 - any of numerous trees of the genus Albizia\n\nalder.n.02 - north temperate shrubs or trees having toothed leaves and conelike fruit; bark is used in tanning and dyeing and the wood is rot-resistant\n\nangelim.n.01 - any of several tropical American trees of the genus Andira\n\nangiospermous_tree.n.01 - any tree having seeds and ovules contained in the ovary\n\nanise_tree.n.01 - any of several evergreen shrubs and small trees of the genus Illicium\n\narbor.n.01 - tree (as opposed to shrub)\n\naroeira_blanca.n.01 - small resinous tree or shrub of Brazil\n\n"
    }
   ],
   "source": [
    "hyponyms = tree.hyponyms()\n",
    "print('Total Hyponyms:', len(hyponyms))\n",
    "print('Sample Hyponyms')\n",
    "for hyponym in hyponyms[:10]:\n",
    "    print(hyponym.name(), '-', hyponym.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[Synset('woody_plant.n.01')]\n"
    }
   ],
   "source": [
    "hypernyms = tree.hypernyms()\n",
    "print(hypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Hypernym paths: 1\n"
    }
   ],
   "source": [
    "# get total hierarchy pathways for 'tree'\n",
    "hypernym_paths = tree.hypernym_paths()\n",
    "print('Total Hypernym paths:', len(hypernym_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hypernym Hierarchy\nentity.n.01 -> physical_entity.n.01 -> object.n.01 -> whole.n.02 -> living_thing.n.01 -> organism.n.01 -> plant.n.02 -> vascular_plant.n.01 -> woody_plant.n.01 -> tree.n.01\n"
    }
   ],
   "source": [
    "# print the entire hypernym hierarchy\n",
    "print('Hypernym Hierarchy')\n",
    "print(' -> '.join(synset.name() for synset in hypernym_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Member Holonyms: 1\nMember Holonyms for [tree]:-\nforest.n.01 - the trees and other plants in a large densely wooded area\n\n"
    }
   ],
   "source": [
    "### Holonyms and Meronyms\n",
    "member_holonyms = tree.member_holonyms()\n",
    "print('Total Member Holonyms:', len(member_holonyms))\n",
    "print('Member Holonyms for [tree]:-')\n",
    "for holonym in member_holonyms:\n",
    "    print(holonym.name(), '-', holonym.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Part Meronyms: 5\nPart Meronyms for [tree]:-\nburl.n.02 - a large rounded outgrowth on the trunk or branch of a tree\n\ncrown.n.07 - the upper branches and leaves of a tree or other plant\n\nlimb.n.02 - any of the main branches arising from the trunk or a bough of a tree\n\nstump.n.01 - the base part of a tree that remains standing after the tree has been felled\n\ntrunk.n.01 - the main stem of a tree; usually covered with bark; the bole is usually the part that is commercially useful for lumber\n\n"
    }
   ],
   "source": [
    "part_meronyms = tree.part_meronyms()\n",
    "print('Total Part Meronyms:', len(part_meronyms))\n",
    "print('Part Meronyms for [tree]:-')\n",
    "for meronym in part_meronyms:\n",
    "    print(meronym.name(), '-', meronym.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Substance Meronyms: 2\nSubstance Meronyms for [tree]:-\nheartwood.n.01 - the older inactive central wood of a tree or woody plant; usually darker and denser than the surrounding sapwood\n\nsapwood.n.01 - newly formed outer wood lying between the cambium and the heartwood of a tree or woody plant; usually light colored; active in water conduction\n\n"
    }
   ],
   "source": [
    "# substance based meronyms for tree\n",
    "substance_meronyms = tree.substance_meronyms()\n",
    "print('Total Substance Meronyms:', len(substance_meronyms))\n",
    "print('Substance Meronyms for [tree]:-')\n",
    "for meronym in substance_meronyms:\n",
    "    print(meronym.name(), '-', meronym.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tree - a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n\nlion - large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n\ntiger - large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n\ncat - feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n\ndog - a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n\n"
    }
   ],
   "source": [
    "### Semantic Relationships and Similarity\n",
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "# create entities and extract names and definitions\n",
    "entities = [tree, lion, tiger, cat, dog]\n",
    "entity_names = [entity.name().split('.')[0] for entity in entities]\n",
    "entity_definitions = [entity.definition() for entity in entities]\n",
    "\n",
    "# print entiries and their definitions\n",
    "for entity, definition in zip(entity_names, entity_definitions):\n",
    "    print(entity, '-', definition)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           tree       lion      tiger        cat        dog\ntree       tree   organism   organism   organism   organism\nlion   organism       lion    big_cat     feline  carnivore\ntiger  organism    big_cat      tiger     feline  carnivore\ncat    organism     feline     feline        cat  carnivore\ndog    organism  carnivore  carnivore  carnivore        dog",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tree</th>\n      <th>lion</th>\n      <th>tiger</th>\n      <th>cat</th>\n      <th>dog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tree</th>\n      <td>tree</td>\n      <td>organism</td>\n      <td>organism</td>\n      <td>organism</td>\n      <td>organism</td>\n    </tr>\n    <tr>\n      <th>lion</th>\n      <td>organism</td>\n      <td>lion</td>\n      <td>big_cat</td>\n      <td>feline</td>\n      <td>carnivore</td>\n    </tr>\n    <tr>\n      <th>tiger</th>\n      <td>organism</td>\n      <td>big_cat</td>\n      <td>tiger</td>\n      <td>feline</td>\n      <td>carnivore</td>\n    </tr>\n    <tr>\n      <th>cat</th>\n      <td>organism</td>\n      <td>feline</td>\n      <td>feline</td>\n      <td>cat</td>\n      <td>carnivore</td>\n    </tr>\n    <tr>\n      <th>dog</th>\n      <td>organism</td>\n      <td>carnivore</td>\n      <td>carnivore</td>\n      <td>carnivore</td>\n      <td>dog</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "common_hypernyms = []\n",
    "for entity in entities:\n",
    "    # get pairwise lowest common hypernyms\n",
    "    common_hypernyms.append([entity.lowest_common_hypernyms(compared_entity)[0]\n",
    "                                            .name().split('.')[0]\n",
    "                             for compared_entity in entities])\n",
    "\n",
    "# build pairwise lower common hypernym matrix\n",
    "common_hypernym_frame = pd.DataFrame(common_hypernyms,\n",
    "                                     index=entity_names, \n",
    "                                     columns=entity_names)\n",
    "common_hypernym_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       tree  lion  tiger   cat   dog\ntree   1.00  0.07   0.07  0.08  0.12\nlion   0.07  1.00   0.33  0.25  0.17\ntiger  0.07  0.33   1.00  0.25  0.17\ncat    0.08  0.25   0.25  1.00  0.20\ndog    0.12  0.17   0.17  0.20  1.00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tree</th>\n      <th>lion</th>\n      <th>tiger</th>\n      <th>cat</th>\n      <th>dog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tree</th>\n      <td>1.00</td>\n      <td>0.07</td>\n      <td>0.07</td>\n      <td>0.08</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>lion</th>\n      <td>0.07</td>\n      <td>1.00</td>\n      <td>0.33</td>\n      <td>0.25</td>\n      <td>0.17</td>\n    </tr>\n    <tr>\n      <th>tiger</th>\n      <td>0.07</td>\n      <td>0.33</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0.17</td>\n    </tr>\n    <tr>\n      <th>cat</th>\n      <td>0.08</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>1.00</td>\n      <td>0.20</td>\n    </tr>\n    <tr>\n      <th>dog</th>\n      <td>0.12</td>\n      <td>0.17</td>\n      <td>0.17</td>\n      <td>0.20</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "similarities = []\n",
    "for entity in entities:\n",
    "    # get pairwise similarities\n",
    "    similarities.append([round(entity.path_similarity(compared_entity), 2) for compared_entity in entities])\n",
    "\n",
    "# build pairwise similarity matrix\n",
    "similarity_frame = pd.DataFrame(similarities, index=entity_names, columns=entity_names)\n",
    "similarity_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sentence: The fruits on that plant have ripened\nWord synset: Synset('fruit.n.01')\nCorresponding definition: the ripened reproductive body of a seed plant\n\nSentence: He finally reaped the fruit of his hard work as he won the race\nWord synset: Synset('fruit.n.03')\nCorresponding definition: the consequence of some effort or action\n\n"
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# sample text and word to disambiguate\n",
    "samples = [('The fruits on that plant have ripened', 'n'), \n",
    "            ('He finally reaped the fruit of his hard work as he won the race', 'n')]\n",
    "\n",
    "# perform word sense disambiguity\n",
    "word = 'fruit'\n",
    "for sentence, pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print('Sentence:', sentence)\n",
    "    print('Word synset:', word_syn)\n",
    "    print('Corresponding definition:', word_syn.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sentence: Lead is a very soft, malleable metal\nWord synset: Synset('lead.n.02')\nCorresponding definition: a soft heavy toxic malleable metallic element; bluish white when freshly cut but tarnishes readily to dull grey\n\nSentence: John is the actor who plays the lead in that movie\nWord synset: Synset('star.n.04')\nCorresponding definition: an actor who plays a principal role\n\nSentence: This road leads to nowhere\nWord synset: Synset('run.v.23')\nCorresponding definition: cause something to pass or lead somewhere\n\n"
    }
   ],
   "source": [
    "# sample text and word to disambiguate\n",
    "samples = [('Lead is a very soft, malleable metal', 'n'), \n",
    "            ('John is the actor who plays the lead in that movie', 'n'), \n",
    "            ('This road leads to nowhere', 'v')]\n",
    "word = 'lead'\n",
    "\n",
    "# perform word sense disambiguation\n",
    "for sentence, pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print('Sentence:', sentence)\n",
    "    print('Word synset:', word_syn)\n",
    "    print('Corresponding definition:', word_syn.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Three more countries have joined an “international grand committee” of parliaments, adding to calls for \n",
    "Facebook’s boss, Mark Zuckerberg, to give evidence on misinformation to the coalition. Brazil, Latvia and Singapore \n",
    "bring the total to eight different parliaments across the world, with plans to send representatives to London on 27 \n",
    "November with the intention of hearing from Zuckerberg. Since the Cambridge Analytica scandal broke, the Facebook chief \n",
    "has only appeared in front of two legislatures: the American Senate and House of Representatives, and the European parliament. \n",
    "Facebook has consistently rebuffed attempts from others, including the UK and Canadian parliaments, to hear from Zuckerberg. \n",
    "He added that an article in the New York Times on Thursday, in which the paper alleged a pattern of behaviour from Facebook \n",
    "to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly \n",
    "dealt with within Facebook.”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Three', 'CARDINAL'), ('more', ''), ('countries', ''), ('have', ''), ('joined', ''), ('an', ''), ('“', ''), ('international', ''), ('grand', ''), ('committee', ''), ('”', ''), ('of', ''), ('parliaments', ''), (',', ''), ('adding', ''), ('to', ''), ('calls', ''), ('for', ''), ('Facebook', 'ORG'), ('’s', 'ORG'), ('boss', ''), (',', ''), ('Mark', 'PERSON'), ('Zuckerberg', 'PERSON'), (',', ''), ('to', ''), ('give', ''), ('evidence', ''), ('on', ''), ('misinformation', ''), ('to', ''), ('the', ''), ('coalition', ''), ('.', ''), ('Brazil', 'GPE'), (',', ''), ('Latvia', 'GPE'), ('and', ''), ('Singapore', 'GPE'), ('bring', ''), ('the', ''), ('total', ''), ('to', ''), ('eight', 'CARDINAL'), ('different', ''), ('parliaments', ''), ('across', ''), ('the', ''), ('world', ''), (',', ''), ('with', ''), ('plans', ''), ('to', ''), ('send', ''), ('representatives', ''), ('to', ''), ('London', 'GPE'), ('on', ''), ('27', 'DATE'), ('November', 'DATE'), ('with', ''), ('the', ''), ('intention', ''), ('of', ''), ('hearing', ''), ('from', ''), ('Zuckerberg', 'GPE'), ('.', ''), ('Since', ''), ('the', ''), ('Cambridge', 'LOC'), ('Analytica', 'LOC'), ('scandal', ''), ('broke', ''), (',', ''), ('the', ''), ('Facebook', 'ORG'), ('chief', ''), ('has', ''), ('only', ''), ('appeared', ''), ('in', ''), ('front', ''), ('of', ''), ('two', 'CARDINAL'), ('legislatures', ''), (':', ''), ('the', 'ORG'), ('American', 'ORG'), ('Senate', 'ORG'), ('and', ''), ('House', 'ORG'), ('of', 'ORG'), ('Representatives', 'ORG'), (',', ''), ('and', ''), ('the', ''), ('European', 'NORP'), ('parliament', ''), ('.', ''), ('Facebook', 'ORG'), ('has', ''), ('consistently', ''), ('rebuffed', ''), ('attempts', ''), ('from', ''), ('others', ''), (',', ''), ('including', ''), ('the', ''), ('UK', 'GPE'), ('and', ''), ('Canadian', 'NORP'), ('parliaments', ''), (',', ''), ('to', ''), ('hear', ''), ('from', ''), ('Zuckerberg', 'GPE'), ('.', ''), ('He', ''), ('added', ''), ('that', ''), ('an', ''), ('article', ''), ('in', ''), ('the', 'ORG'), ('New', 'ORG'), ('York', 'ORG'), ('Times', 'ORG'), ('on', ''), ('Thursday', 'DATE'), (',', ''), ('in', ''), ('which', ''), ('the', ''), ('paper', ''), ('alleged', ''), ('a', ''), ('pattern', ''), ('of', ''), ('behaviour', ''), ('from', ''), ('Facebook', 'ORG'), ('to', ''), ('“', ''), ('delay', ''), (',', ''), ('deny', ''), ('and', ''), ('deflect', ''), ('”', ''), ('negative', ''), ('news', ''), ('stories', ''), (',', ''), ('“', ''), ('raises', ''), ('further', ''), ('questions', ''), ('about', ''), ('how', ''), ('recent', ''), ('data', ''), ('breaches', ''), ('were', ''), ('allegedly', ''), ('dealt', ''), ('with', ''), ('within', ''), ('Facebook', 'ORG'), ('.', ''), ('”', '')]\n"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = re.sub(r'\\n', '', text) # remove extra newlines\n",
    "\n",
    "# not working\n",
    "#import spacy\n",
    "#nlp = spacy.load('web_en_core_sm')\n",
    "\n",
    "# github help\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "text_nlp = nlp(text)\n",
    "# print named entites in article\n",
    "ner_tagged = [(word.text, word.ent_type_) for word in text_nlp]\n",
    "print(ner_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Three\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n</mark>\n more countries have joined an “international grand committee” of parliaments, adding to calls for \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Facebook’s\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n boss, \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Mark Zuckerberg\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n, to give evidence on misinformation to the coalition. \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Brazil\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n, \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Latvia\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n and \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Singapore\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n bring the total to \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    eight\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n</mark>\n different parliaments across the world, with plans to send representatives to \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    London\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n on \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    27 November\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n</mark>\n with the intention of hearing from \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Zuckerberg\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n. Since the \n<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Cambridge Analytica\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n</mark>\n scandal broke, the \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Facebook\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n chief has only appeared in front of \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    two\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n</mark>\n legislatures: \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    the American Senate\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n and \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    House of Representatives\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n, and the \n<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    European\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n</mark>\n parliament. \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Facebook\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n has consistently rebuffed attempts from others, including the \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    UK\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n and \n<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Canadian\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n</mark>\n parliaments, to hear from \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Zuckerberg\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n. He added that an article in \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    the New York Times\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n on \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Thursday\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n</mark>\n, in which the paper alleged a pattern of behaviour from \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Facebook\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly dealt with within \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Facebook\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n.”</div></span>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# visualize named entities\n",
    "displacy.render(text_nlp, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Three', 'CARDINAL'), ('Facebook ’s', 'ORG'), ('Mark Zuckerberg', 'PERSON'), ('Brazil', 'GPE'), ('Latvia', 'GPE'), ('Singapore', 'GPE'), ('eight', 'CARDINAL'), ('London', 'GPE'), ('27 November', 'DATE'), ('Zuckerberg', 'GPE'), ('Cambridge Analytica', 'LOC'), ('Facebook', 'ORG'), ('two', 'CARDINAL'), ('the American Senate', 'ORG'), ('House of Representatives', 'ORG'), ('European', 'NORP'), ('Facebook', 'ORG'), ('UK', 'GPE'), ('Canadian', 'NORP'), ('Zuckerberg', 'GPE'), ('the New York Times', 'ORG'), ('Thursday', 'DATE'), ('Facebook', 'ORG'), ('Facebook', 'ORG')]\n"
    }
   ],
   "source": [
    "# extract named entities\n",
    "named_entities = []\n",
    "temp_entity_name = ''\n",
    "temp_named_entity = None\n",
    "for term, tag in ner_tagged:\n",
    "    if tag:\n",
    "        temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "        temp_named_entity = (temp_entity_name, tag)\n",
    "    else:\n",
    "        if temp_named_entity:\n",
    "            named_entities.append(temp_named_entity)\n",
    "            temp_entity_name = ''\n",
    "            temp_named_entity = None\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('ORG', 8),\n ('GPE', 7),\n ('CARDINAL', 3),\n ('DATE', 2),\n ('NORP', 2),\n ('PERSON', 1),\n ('LOC', 1)]"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# viewing the top entity types\n",
    "from collections import Counter\n",
    "c = Counter([item[1] for item in named_entities])\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "STANFORD_CLASSIFIER_PATH = r'/Users/beliciarodriguez/Downloads/stanford-ner-2014-08-27/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "STANFORD_NER_JAR_PATH = r'/Users/beliciarodriguez/Downloads/stanford-ner-2014-08-27/stanford-ner-3.4.1.jar'\n",
    "\n",
    "sn = StanfordNERTagger(STANFORD_CLASSIFIER_PATH, path_to_jar=STANFORD_NER_JAR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Facebooks', 'ORGANIZATION'), ('Latvia', 'LOCATION'), ('Singapore', 'LOCATION'), ('London', 'LOCATION'), ('Cambridge Analytica', 'ORGANIZATION'), ('Facebook', 'ORGANIZATION'), ('Senate', 'ORGANIZATION'), ('Facebook', 'ORGANIZATION'), ('UK', 'LOCATION'), ('New York Times', 'ORGANIZATION'), ('Facebook', 'ORGANIZATION')]\n"
    }
   ],
   "source": [
    "# perform NER tagging & extract relevant entities\n",
    "text_enc = text.encode('ascii', errors='ignore').decode('utf-8')\n",
    "ner_tagged = sn.tag(text_enc.split())\n",
    "\n",
    "named_entities = []\n",
    "temp_entity_name = ''\n",
    "temp_named_entity = None\n",
    "for term, tag in ner_tagged:\n",
    "    if tag != 'O':\n",
    "        temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "        temp_named_entity = (temp_entity_name, tag)\n",
    "    else:\n",
    "        if temp_named_entity:\n",
    "            named_entities.append(temp_named_entity)\n",
    "            temp_entity_name = ''\n",
    "            temp_named_entity = None\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('ORGANIZATION', 7), ('LOCATION', 4)]"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# get more frequent entities\n",
    "c = Counter([item[1] for item in named_entities])\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Three', 'NUMBER'), ('Facebook', 'ORGANIZATION'), ('boss', 'TITLE'), ('Mark Zuckerberg', 'PERSON'), ('Brazil', 'COUNTRY'), ('Latvia', 'COUNTRY'), ('Singapore', 'COUNTRY'), ('eight', 'NUMBER'), ('London', 'CITY'), ('27 November', 'DATE'), ('Zuckerberg', 'PERSON'), ('Cambridge Analytica', 'ORGANIZATION'), ('Facebook', 'ORGANIZATION'), ('two', 'NUMBER'), ('American Senate', 'ORGANIZATION'), ('House of Representatives', 'ORGANIZATION'), ('European', 'NATIONALITY'), ('Facebook', 'ORGANIZATION'), ('UK', 'COUNTRY'), ('Canadian', 'NATIONALITY'), ('Zuckerberg', 'PERSON'), ('New York Times', 'ORGANIZATION'), ('Thursday', 'DATE'), ('Facebook', 'ORGANIZATION'), ('Facebook', 'ORGANIZATION')]\n"
    }
   ],
   "source": [
    "# using Stanford's Core NLP (connected to server)\n",
    "from nltk.parse import CoreNLPParser\n",
    "import nltk\n",
    "\n",
    "# NER Tagging\n",
    "ner_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='ner')\n",
    "tags = list(ner_tagger.raw_tag_sents(nltk.sent_tokenize(text)))\n",
    "tags = [sublist[0] for sublist in tags]\n",
    "tags = [word_tag for sublist in tags for word_tag in sublist]\n",
    "\n",
    "# Extract Named Entities\n",
    "named_entities = []\n",
    "temp_entity_name = ''\n",
    "temp_named_entity = None\n",
    "for term, tag in tags:\n",
    "    if tag != 'O':\n",
    "        temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "        temp_named_entity = (temp_entity_name, tag)\n",
    "    else:\n",
    "        if temp_named_entity:\n",
    "            named_entities.append(temp_named_entity)\n",
    "            temp_entity_name = ''\n",
    "            temp_named_entity = None\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('ORGANIZATION', 9),\n ('COUNTRY', 4),\n ('NUMBER', 3),\n ('PERSON', 3),\n ('DATE', 2),\n ('NATIONALITY', 2),\n ('TITLE', 1),\n ('CITY', 1)]"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# find out top named entity types\n",
    "c = Counter([item[1] for item in named_entities])\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an NER Tagger from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1048575 entries, 0 to 1048574\nData columns (total 4 columns):\n #   Column      Non-Null Count    Dtype \n---  ------      --------------    ----- \n 0   Sentence #  1048575 non-null  object\n 1   Word        1048575 non-null  object\n 2   POS         1048575 non-null  object\n 3   Tag         1048575 non-null  object\ndtypes: object(4)\nmemory usage: 32.0+ MB\n"
    }
   ],
   "source": [
    "dataset_path = '/Users/beliciarodriguez/Downloads/ner_dataset.csv.gz'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(dataset_path, compression='gzip', encoding='ISO-8859-1')\n",
    "df = df.fillna(method='ffill')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                0            1              2            3            4        \\\nSentence #  Sentence: 1  Sentence: 1    Sentence: 1  Sentence: 1  Sentence: 1   \nWord          Thousands           of  demonstrators         have      marched   \nPOS                 NNS           IN            NNS          VBP          VBN   \nTag                   O            O              O            O            O   \n\n                5            6            7            8            9        \\\nSentence #  Sentence: 1  Sentence: 1  Sentence: 1  Sentence: 1  Sentence: 1   \nWord            through       London           to      protest          the   \nPOS                  IN          NNP           TO           VB           DT   \nTag                   O        B-geo            O            O            O   \n\n            ...          1048565          1048566          1048567  \\\nSentence #  ...  Sentence: 47958  Sentence: 47958  Sentence: 47959   \nWord        ...           impact                .           Indian   \nPOS         ...               NN                .               JJ   \nTag         ...                O                O            B-gpe   \n\n                    1048568          1048569          1048570  \\\nSentence #  Sentence: 47959  Sentence: 47959  Sentence: 47959   \nWord                 forces             said             they   \nPOS                     NNS              VBD              PRP   \nTag                       O                O                O   \n\n                    1048571          1048572          1048573          1048574  \nSentence #  Sentence: 47959  Sentence: 47959  Sentence: 47959  Sentence: 47959  \nWord              responded               to              the           attack  \nPOS                     VBD               TO               DT               NN  \nTag                       O                O                O                O  \n\n[4 rows x 1048575 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1048565</th>\n      <th>1048566</th>\n      <th>1048567</th>\n      <th>1048568</th>\n      <th>1048569</th>\n      <th>1048570</th>\n      <th>1048571</th>\n      <th>1048572</th>\n      <th>1048573</th>\n      <th>1048574</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Sentence #</th>\n      <td>Sentence: 1</td>\n      <td>Sentence: 1</td>\n      <td>Sentence: 1</td>\n      <td>Sentence: 1</td>\n      <td>Sentence: 1</td>\n      <td>Sentence: 1</td>\n      <td>Sentence: 1</td>\n      <td>Sentence: 1</td>\n      <td>Sentence: 1</td>\n      <td>Sentence: 1</td>\n      <td>...</td>\n      <td>Sentence: 47958</td>\n      <td>Sentence: 47958</td>\n      <td>Sentence: 47959</td>\n      <td>Sentence: 47959</td>\n      <td>Sentence: 47959</td>\n      <td>Sentence: 47959</td>\n      <td>Sentence: 47959</td>\n      <td>Sentence: 47959</td>\n      <td>Sentence: 47959</td>\n      <td>Sentence: 47959</td>\n    </tr>\n    <tr>\n      <th>Word</th>\n      <td>Thousands</td>\n      <td>of</td>\n      <td>demonstrators</td>\n      <td>have</td>\n      <td>marched</td>\n      <td>through</td>\n      <td>London</td>\n      <td>to</td>\n      <td>protest</td>\n      <td>the</td>\n      <td>...</td>\n      <td>impact</td>\n      <td>.</td>\n      <td>Indian</td>\n      <td>forces</td>\n      <td>said</td>\n      <td>they</td>\n      <td>responded</td>\n      <td>to</td>\n      <td>the</td>\n      <td>attack</td>\n    </tr>\n    <tr>\n      <th>POS</th>\n      <td>NNS</td>\n      <td>IN</td>\n      <td>NNS</td>\n      <td>VBP</td>\n      <td>VBN</td>\n      <td>IN</td>\n      <td>NNP</td>\n      <td>TO</td>\n      <td>VB</td>\n      <td>DT</td>\n      <td>...</td>\n      <td>NN</td>\n      <td>.</td>\n      <td>JJ</td>\n      <td>NNS</td>\n      <td>VBD</td>\n      <td>PRP</td>\n      <td>VBD</td>\n      <td>TO</td>\n      <td>DT</td>\n      <td>NN</td>\n    </tr>\n    <tr>\n      <th>Tag</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-geo</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>...</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-gpe</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 1048575 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(47959, 35178, 42, 17)"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "df['Sentence #'].nunique(), df.Word.nunique(), df.POS.nunique(), df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "O        887908\nB-geo     37644\nB-tim     20333\nB-org     20143\nI-per     17251\nB-per     16990\nI-org     16784\nB-gpe     15870\nI-geo      7414\nI-tim      6528\nB-art       402\nB-eve       308\nI-art       297\nI-eve       253\nB-nat       201\nI-gpe       198\nI-nat        51\nName: Tag, dtype: int64"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "df.Tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "# convert input sentence into features\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "# get corresponding outcome NER tag label for input sentence\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                   s['POS'].values.tolist(), \n",
    "                                                   s['Tag'].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('Sentence #').apply(agg_func)\n",
    "\n",
    "sentences = [s for s in grouped_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('Thousands', 'NNS', 'O'),\n ('of', 'IN', 'O'),\n ('demonstrators', 'NNS', 'O'),\n ('have', 'VBP', 'O'),\n ('marched', 'VBN', 'O'),\n ('through', 'IN', 'O'),\n ('London', 'NNP', 'B-geo'),\n ('to', 'TO', 'O'),\n ('protest', 'VB', 'O'),\n ('the', 'DT', 'O'),\n ('war', 'NN', 'O'),\n ('in', 'IN', 'O'),\n ('Iraq', 'NNP', 'B-geo'),\n ('and', 'CC', 'O'),\n ('demand', 'VB', 'O'),\n ('the', 'DT', 'O'),\n ('withdrawal', 'NN', 'O'),\n ('of', 'IN', 'O'),\n ('British', 'JJ', 'B-gpe'),\n ('troops', 'NNS', 'O'),\n ('from', 'IN', 'O'),\n ('that', 'DT', 'O'),\n ('country', 'NN', 'O'),\n ('.', '.', 'O')]"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "# view sample annotated sentence from our dataset\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[{'bias': 1.0,\n  'word.lower()': 'through',\n  'word[-3:]': 'ugh',\n  'word[-2:]': 'gh',\n  'word.isupper()': False,\n  'word.istitle()': False,\n  'word.isdigit()': False,\n  'postag': 'IN',\n  'postag[:2]': 'IN',\n  'BOS': True,\n  '+1:word.lower()': 'london',\n  '+1:word.istitle()': True,\n  '+1:word.isupper()': False,\n  '+1:postag': 'NNP',\n  '+1:postag[:2]': 'NN'},\n {'bias': 1.0,\n  'word.lower()': 'london',\n  'word[-3:]': 'don',\n  'word[-2:]': 'on',\n  'word.isupper()': False,\n  'word.istitle()': True,\n  'word.isdigit()': False,\n  'postag': 'NNP',\n  'postag[:2]': 'NN',\n  '-1:word.lower()': 'through',\n  '-1:word.istitle()': False,\n  '-1:word.isupper()': False,\n  '-1:postag': 'IN',\n  '-1:postag[:2]': 'IN',\n  'EOS': True}]"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "# view how each annotated tokenized sentence can be used for feat engineering w/ earlier defined fxn\n",
    "sent2features(sentences[0][5:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['O', 'B-geo']"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "sent2labels(sentences[0][5:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((35969,), (11990,))"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# prepared train and test datasets by feat engineering on input sentences\n",
    "# getting corresponding NER tag labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([sent2features(s) for s in sentences])\n",
    "y = np.array([sent2labels(s) for s in sentences])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "loading training data to CRFsuite: 100%|██████████| 35969/35969 [00:34<00:00, 1034.76it/s]\n\nFeature generation\ntype: CRF1d\nfeature.minfreq: 0.000000\nfeature.possible_states: 0\nfeature.possible_transitions: 1\n0....1....2....3....4....5....6....7....8....9....10\nNumber of features: 133629\nSeconds required: 4.796\n\nL-BFGS optimization\nc1: 0.100000\nc2: 0.100000\nnum_memories: 6\nmax_iterations: 100\nepsilon: 0.000010\nstop: 10\ndelta: 0.000010\nlinesearch: MoreThuente\nlinesearch.max_iterations: 20\n\nIter 1   time=4.38  loss=1264028.26 active=132637 feature_norm=1.00\nIter 2   time=4.34  loss=994059.01 active=131294 feature_norm=4.42\nIter 3   time=2.21  loss=776413.87 active=125970 feature_norm=3.87\nIter 4   time=11.54 loss=422143.40 active=127018 feature_norm=3.24\nIter 5   time=2.15  loss=355775.44 active=129029 feature_norm=4.04\nIter 6   time=2.11  loss=264125.22 active=124046 feature_norm=6.10\nIter 7   time=2.08  loss=222304.71 active=117183 feature_norm=7.69\nIter 8   time=2.07  loss=197827.17 active=110838 feature_norm=8.75\nIter 9   time=2.10  loss=176877.92 active=105650 feature_norm=10.41\nIter 10  time=2.21  loss=158997.61 active=103459 feature_norm=11.60\nIter 11  time=2.45  loss=146328.53 active=100247 feature_norm=13.41\nIter 12  time=2.19  loss=137671.14 active=98635 feature_norm=14.69\nIter 13  time=2.21  loss=130471.62 active=97462 feature_norm=15.45\nIter 14  time=2.64  loss=118841.84 active=94124 feature_norm=17.81\nIter 15  time=2.12  loss=112928.42 active=92178 feature_norm=20.21\nIter 16  time=2.07  loss=105499.44 active=91978 feature_norm=22.27\nIter 17  time=2.14  loss=101994.76 active=91940 feature_norm=23.34\nIter 18  time=2.35  loss=96362.28 active=89453 feature_norm=26.63\nIter 19  time=2.43  loss=90647.28 active=89021 feature_norm=28.85\nIter 20  time=2.13  loss=85521.13 active=87547 feature_norm=32.66\nIter 21  time=2.18  loss=81239.75 active=87184 feature_norm=36.05\nIter 22  time=2.38  loss=77980.98 active=86649 feature_norm=39.45\nIter 23  time=2.40  loss=75036.81 active=86300 feature_norm=41.33\nIter 24  time=2.50  loss=70028.55 active=82924 feature_norm=47.18\nIter 25  time=4.62  loss=67859.30 active=82277 feature_norm=51.09\nIter 26  time=2.33  loss=64640.62 active=81815 feature_norm=54.83\nIter 27  time=2.25  loss=61783.61 active=80545 feature_norm=60.05\nIter 28  time=2.40  loss=59095.29 active=79506 feature_norm=66.46\nIter 29  time=2.37  loss=56799.57 active=79733 feature_norm=70.47\nIter 30  time=2.29  loss=54812.68 active=79492 feature_norm=75.32\nIter 31  time=2.05  loss=52807.07 active=78965 feature_norm=80.24\nIter 32  time=2.13  loss=50790.16 active=78225 feature_norm=88.16\nIter 33  time=2.03  loss=49548.49 active=78456 feature_norm=90.54\nIter 34  time=2.05  loss=48303.45 active=78007 feature_norm=94.98\nIter 35  time=2.14  loss=46171.65 active=76442 feature_norm=106.16\nIter 36  time=2.21  loss=45327.99 active=75732 feature_norm=115.55\nIter 37  time=2.21  loss=43822.08 active=75408 feature_norm=118.88\nIter 38  time=2.04  loss=42688.21 active=74715 feature_norm=125.25\nIter 39  time=2.25  loss=41275.71 active=73716 feature_norm=139.21\nIter 40  time=2.33  loss=40047.55 active=73576 feature_norm=147.46\nIter 41  time=2.15  loss=39265.28 active=73554 feature_norm=151.63\nIter 42  time=2.16  loss=38403.33 active=72721 feature_norm=159.70\nIter 43  time=2.18  loss=37608.69 active=72627 feature_norm=165.70\nIter 44  time=2.12  loss=36823.99 active=71771 feature_norm=172.98\nIter 45  time=2.15  loss=36326.35 active=70178 feature_norm=184.40\nIter 46  time=2.24  loss=35883.80 active=69283 feature_norm=186.01\nIter 47  time=2.28  loss=35560.99 active=68923 feature_norm=190.20\nIter 48  time=2.22  loss=35404.76 active=67538 feature_norm=199.98\nIter 49  time=2.23  loss=35012.55 active=67985 feature_norm=200.64\nIter 50  time=2.38  loss=34929.44 active=68033 feature_norm=200.67\nIter 51  time=2.13  loss=34693.21 active=67122 feature_norm=201.84\nIter 52  time=4.25  loss=34629.25 active=66830 feature_norm=201.25\nIter 53  time=2.11  loss=34459.64 active=66761 feature_norm=202.56\nIter 54  time=2.13  loss=34344.14 active=66577 feature_norm=203.72\nIter 55  time=2.24  loss=34165.12 active=66051 feature_norm=205.31\nIter 56  time=2.12  loss=34162.67 active=64890 feature_norm=206.81\nIter 57  time=2.12  loss=33943.85 active=65312 feature_norm=207.03\nIter 58  time=2.13  loss=33886.19 active=64897 feature_norm=207.50\nIter 59  time=2.23  loss=33780.88 active=64020 feature_norm=208.77\nIter 60  time=2.14  loss=33666.08 active=63580 feature_norm=209.40\nIter 61  time=2.14  loss=33571.12 active=63159 feature_norm=210.40\nIter 62  time=2.16  loss=33488.40 active=63013 feature_norm=210.87\nIter 63  time=2.21  loss=33397.52 active=62694 feature_norm=211.68\nIter 64  time=2.15  loss=33317.69 active=62488 feature_norm=212.22\nIter 65  time=2.19  loss=33247.01 active=62238 feature_norm=212.80\nIter 66  time=2.18  loss=33173.26 active=62029 feature_norm=213.27\nIter 67  time=2.43  loss=33108.73 active=61781 feature_norm=213.91\nIter 68  time=2.31  loss=33052.25 active=61575 feature_norm=214.27\nIter 69  time=2.12  loss=32996.19 active=61366 feature_norm=214.76\nIter 70  time=2.24  loss=32941.28 active=61153 feature_norm=215.10\nIter 71  time=2.23  loss=32894.22 active=60966 feature_norm=215.53\nIter 72  time=2.33  loss=32853.09 active=60815 feature_norm=215.78\nIter 73  time=2.12  loss=32814.22 active=60658 feature_norm=216.15\nIter 74  time=2.42  loss=32778.22 active=60513 feature_norm=216.37\nIter 75  time=2.18  loss=32743.64 active=60336 feature_norm=216.67\nIter 76  time=2.12  loss=32711.92 active=60185 feature_norm=216.86\nIter 77  time=2.09  loss=32682.08 active=60090 feature_norm=217.11\nIter 78  time=2.09  loss=32654.10 active=59916 feature_norm=217.27\nIter 79  time=2.14  loss=32627.76 active=59768 feature_norm=217.54\nIter 80  time=2.24  loss=32603.13 active=59701 feature_norm=217.65\nIter 81  time=2.21  loss=32580.63 active=59546 feature_norm=217.85\nIter 82  time=2.07  loss=32559.76 active=59413 feature_norm=217.96\nIter 83  time=2.15  loss=32538.88 active=59278 feature_norm=218.17\nIter 84  time=2.09  loss=32520.71 active=59165 feature_norm=218.27\nIter 85  time=2.04  loss=32501.10 active=59088 feature_norm=218.47\nIter 86  time=2.02  loss=32484.14 active=58988 feature_norm=218.56\nIter 87  time=2.07  loss=32467.58 active=58909 feature_norm=218.71\nIter 88  time=2.04  loss=32452.86 active=58808 feature_norm=218.80\nIter 89  time=2.03  loss=32437.92 active=58717 feature_norm=218.98\nIter 90  time=2.01  loss=32424.99 active=58671 feature_norm=219.06\nIter 91  time=2.04  loss=32411.01 active=58618 feature_norm=219.21\nIter 92  time=2.04  loss=32399.15 active=58552 feature_norm=219.29\nIter 93  time=2.10  loss=32386.63 active=58490 feature_norm=219.40\nIter 94  time=2.07  loss=32375.74 active=58448 feature_norm=219.48\nIter 95  time=2.11  loss=32364.54 active=58374 feature_norm=219.60\nIter 96  time=2.08  loss=32354.96 active=58381 feature_norm=219.68\nIter 97  time=2.40  loss=32344.27 active=58343 feature_norm=219.80\nIter 98  time=2.60  loss=32335.08 active=58304 feature_norm=219.87\nIter 99  time=2.19  loss=32324.92 active=58249 feature_norm=219.98\nIter 100 time=2.20  loss=32316.67 active=58226 feature_norm=220.04\nL-BFGS terminated with the maximum number of iterations\nTotal seconds required for training: 237.443\n\nStoring the model\nNumber of active features: 58226 (133629)\nNumber of active attributes: 29279 (90250)\nNumber of active labels: 17 (17)\nWriting labels\nWriting attributes\nWriting feature references for transitions\nWriting feature references for attributes\nSeconds required: 0.219\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=True)"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', \n",
    "                           c1=0.1, \n",
    "                           c2=0.1, \n",
    "                           max_iterations=100, \n",
    "                           all_possible_transitions=True, \n",
    "                           verbose=True)\n",
    "# crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['ner_model.pkl']"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "# save model using following code\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(crf, 'ner_model.pkl')\n",
    "\n",
    "# to load\n",
    "# crf = joblib.load('ner_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['O', 'O', 'O', 'O', 'B-per', 'I-per', 'O', 'B-org', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
    }
   ],
   "source": [
    "# evaluate model performance for NER tagging on test data\n",
    "# show sample prediction and actual labels\n",
    "y_pred = crf.predict(X_test)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['O', 'O', 'O', 'O', 'B-per', 'I-per', 'O', 'B-org', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n       B-org       0.81      0.73      0.77      5116\n       B-per       0.85      0.84      0.84      4239\n       I-per       0.85      0.90      0.88      4273\n       B-geo       0.86      0.91      0.89      9403\n       I-geo       0.81      0.80      0.81      1826\n       B-tim       0.93      0.89      0.91      5095\n       I-org       0.82      0.79      0.80      4195\n       B-gpe       0.97      0.94      0.96      3961\n       I-tim       0.84      0.81      0.82      1604\n       B-nat       0.50      0.24      0.32        55\n       B-eve       0.51      0.33      0.40        80\n       B-art       0.36      0.14      0.20       102\n       I-art       0.24      0.07      0.10        90\n       I-eve       0.45      0.19      0.27        74\n       I-gpe       0.86      0.53      0.66        36\n       I-nat       0.57      0.22      0.32        18\n\n   micro avg       0.86      0.85      0.86     40167\n   macro avg       0.70      0.58      0.62     40167\nweighted avg       0.86      0.85      0.85     40167\n\n"
    }
   ],
   "source": [
    "# evaluate model performance on entire test dataset\n",
    "# get key classification model performance metrics\n",
    "from sklearn_crfsuite import metrics as crf_metrics\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an End-to-End NER Tagger with Our Trained NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('Three', 'CD'),\n ('more', 'JJR'),\n ('countries', 'NNS'),\n ('have', 'VBP'),\n ('joined', 'VBN'),\n ('an', 'DT'),\n ('“', 'NNP'),\n ('international', 'JJ'),\n ('grand', 'JJ'),\n ('committee', 'NN')]"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "# tokenize our text and perform POS tagging\n",
    "import nltk\n",
    "\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "text_pos = nltk.pos_tag(text_tokens)\n",
    "text_pos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'bias': 1.0,\n 'word.lower()': 'three',\n 'word[-3:]': 'ree',\n 'word[-2:]': 'ee',\n 'word.isupper()': False,\n 'word.istitle()': True,\n 'word.isdigit()': False,\n 'postag': 'CD',\n 'postag[:2]': 'CD',\n 'BOS': True,\n '+1:word.lower()': 'more',\n '+1:word.istitle()': False,\n '+1:word.isupper()': False,\n '+1:postag': 'JJR',\n '+1:postag[:2]': 'JJ'}"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "# extract features from POS tagged text document\n",
    "features = [sent2features(text_pos)]\n",
    "features[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-art', 'I-art']"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "# use CRF model just trained to predict features we engineered from sample doc\n",
    "labels = crf.predict(features)\n",
    "doc_labels = labels[0]\n",
    "doc_labels[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Three', 'O'), ('more', 'O'), ('countries', 'O'), ('have', 'O'), ('joined', 'O'), ('an', 'O'), ('“', 'O'), ('international', 'O'), ('grand', 'O'), ('committee', 'O'), ('”', 'O'), ('of', 'O'), ('parliaments', 'O'), (',', 'O'), ('adding', 'O'), ('to', 'O'), ('calls', 'O'), ('for', 'O'), ('Facebook', 'B-art'), ('’', 'I-art'), ('s', 'O'), ('boss', 'O'), (',', 'O'), ('Mark', 'B-per'), ('Zuckerberg', 'I-per'), (',', 'O'), ('to', 'O'), ('give', 'O'), ('evidence', 'O'), ('on', 'O'), ('misinformation', 'O'), ('to', 'O'), ('the', 'O'), ('coalition', 'O'), ('.', 'O'), ('Brazil', 'B-geo'), (',', 'O'), ('Latvia', 'B-org'), ('and', 'I-org'), ('Singapore', 'I-org'), ('bring', 'O'), ('the', 'O'), ('total', 'O'), ('to', 'O'), ('eight', 'O'), ('different', 'O'), ('parliaments', 'O'), ('across', 'O'), ('the', 'O'), ('world', 'O'), (',', 'O'), ('with', 'O'), ('plans', 'O'), ('to', 'O'), ('send', 'O'), ('representatives', 'O'), ('to', 'O'), ('London', 'B-geo'), ('on', 'O'), ('27', 'B-tim'), ('November', 'I-tim'), ('with', 'O'), ('the', 'O'), ('intention', 'O'), ('of', 'O'), ('hearing', 'O'), ('from', 'O'), ('Zuckerberg', 'B-geo'), ('.', 'O'), ('Since', 'O'), ('the', 'O'), ('Cambridge', 'B-org'), ('Analytica', 'I-org'), ('scandal', 'O'), ('broke', 'O'), (',', 'O'), ('the', 'O'), ('Facebook', 'B-org'), ('chief', 'O'), ('has', 'O'), ('only', 'O'), ('appeared', 'O'), ('in', 'O'), ('front', 'O'), ('of', 'O'), ('two', 'O'), ('legislatures', 'O'), (':', 'O'), ('the', 'O'), ('American', 'B-gpe'), ('Senate', 'B-org'), ('and', 'I-org'), ('House', 'I-org'), ('of', 'I-org'), ('Representatives', 'I-org'), (',', 'O'), ('and', 'O'), ('the', 'O'), ('European', 'B-org'), ('parliament', 'I-org'), ('.', 'O'), ('Facebook', 'B-org'), ('has', 'O'), ('consistently', 'O'), ('rebuffed', 'O'), ('attempts', 'O'), ('from', 'O'), ('others', 'O'), (',', 'O'), ('including', 'O'), ('the', 'O'), ('UK', 'B-org'), ('and', 'O'), ('Canadian', 'B-gpe'), ('parliaments', 'O'), (',', 'O'), ('to', 'O'), ('hear', 'O'), ('from', 'O'), ('Zuckerberg', 'B-geo'), ('.', 'O'), ('He', 'O'), ('added', 'O'), ('that', 'O'), ('an', 'O'), ('article', 'O'), ('in', 'O'), ('the', 'O'), ('New', 'B-org'), ('York', 'I-org'), ('Times', 'I-org'), ('on', 'O'), ('Thursday', 'B-tim'), (',', 'O'), ('in', 'O'), ('which', 'O'), ('the', 'O'), ('paper', 'O'), ('alleged', 'O'), ('a', 'O'), ('pattern', 'O'), ('of', 'O'), ('behaviour', 'O'), ('from', 'O'), ('Facebook', 'B-org'), ('to', 'O'), ('“', 'O'), ('delay', 'O'), (',', 'O'), ('deny', 'O'), ('and', 'O'), ('deflect', 'O'), ('”', 'O'), ('negative', 'O'), ('news', 'O'), ('stories', 'O'), (',', 'O'), ('“', 'O'), ('raises', 'O'), ('further', 'O'), ('questions', 'O'), ('about', 'O'), ('how', 'O'), ('recent', 'O'), ('data', 'O'), ('breaches', 'O'), ('were', 'O'), ('allegedly', 'O'), ('dealt', 'O'), ('with', 'O'), ('within', 'O'), ('Facebook', 'B-art'), ('.', 'O'), ('”', 'O')]\n"
    }
   ],
   "source": [
    "# combo actual text tokens with corresponding NER tags\n",
    "# retrieve relevant named entities from NER tags\n",
    "text_ner = [(token, tag) for token, tag in zip(text_tokens, doc_labels)]\n",
    "print(text_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                          Entity    Tag\n0                                     Facebook ’  I-art\n1                                Mark Zuckerberg  I-per\n2                                         Brazil  B-geo\n3                           Latvia and Singapore  I-org\n4                                         London  B-geo\n5                                    27 November  I-tim\n6                                     Zuckerberg  B-geo\n7                            Cambridge Analytica  I-org\n8                                       Facebook  B-org\n9   American Senate and House of Representatives  I-org\n10                           European parliament  I-org\n11                                      Facebook  B-org\n12                                            UK  B-org\n13                                      Canadian  B-gpe\n14                                    Zuckerberg  B-geo\n15                                New York Times  I-org\n16                                      Thursday  B-tim\n17                                      Facebook  B-org\n18                                      Facebook  B-art",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Entity</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Facebook ’</td>\n      <td>I-art</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mark Zuckerberg</td>\n      <td>I-per</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Brazil</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Latvia and Singapore</td>\n      <td>I-org</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>London</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>27 November</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Zuckerberg</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Cambridge Analytica</td>\n      <td>I-org</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Facebook</td>\n      <td>B-org</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>American Senate and House of Representatives</td>\n      <td>I-org</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>European parliament</td>\n      <td>I-org</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Facebook</td>\n      <td>B-org</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>UK</td>\n      <td>B-org</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Canadian</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Zuckerberg</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>New York Times</td>\n      <td>I-org</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Thursday</td>\n      <td>B-tim</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Facebook</td>\n      <td>B-org</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Facebook</td>\n      <td>B-art</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# extract and display all named entities\n",
    "named_entities = []\n",
    "temp_entity_name = ''\n",
    "temp_named_entity = None\n",
    "for term, tag in text_ner:\n",
    "    if tag != 'O':\n",
    "        temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "        temp_named_entity = (temp_entity_name, tag)\n",
    "    else:\n",
    "        if temp_named_entity:\n",
    "            named_entities.append(temp_named_entity)\n",
    "            temp_entity_name = ''\n",
    "            temp_named_entity = None\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(named_entities, columns=['Entity', 'Tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Semantic Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# assign symbols and propositions\n",
    "symbol_P = 'P'\n",
    "symbol_Q = 'Q'\n",
    "\n",
    "proposition_P = 'He is hungry'\n",
    "propositon_Q = 'He will eat a sandwich'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['(P & Q)', '(P | Q)', '(P -> Q)', '(P <-> Q)']"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "# assign various truth values to the propositions\n",
    "p_statuses = [False, False, True, True]\n",
    "q_statuses = [False, True, False, True]\n",
    "\n",
    "# assign the various expressions combining the logical operators\n",
    "conjunction = '(P & Q)'\n",
    "disjunction = '(P | Q)'\n",
    "implication = '(P -> Q)'\n",
    "equivalence = '(P <-> Q)'\n",
    "expressions = [conjunction, disjunction, implication, equivalence]\n",
    "expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "P: He is hungry\nQ: He will eat a sandwich\n\nExpression Outcomes:-\n       P      Q  (P & Q)  (P | Q)  (P -> Q)  (P <-> Q)\n0  False  False    False    False      True       True\n1  False   True    False     True      True      False\n2   True  False    False     True     False      False\n3   True   True     True     True      True       True\n"
    }
   ],
   "source": [
    "# evaluate each expression using propositional logic\n",
    "results = []\n",
    "for status_p, status_q in zip(p_statuses, q_statuses):\n",
    "    dom = set([])\n",
    "    val = nltk.Valuation([(symbol_P, status_p), \n",
    "                          (symbol_Q, status_q)])\n",
    "    assignments = nltk.Assignment(dom)\n",
    "    model = nltk.Model(dom, val)\n",
    "    row = [status_p, status_q]\n",
    "    for expression in expressions:\n",
    "    # evaluate each expression based on proposition truth values\n",
    "        result = model.evaluate(expression, assignments) \n",
    "        row.append(result)\n",
    "    results.append(row)\n",
    "\n",
    "# build the result table\n",
    "columns = [symbol_P, symbol_Q, conjunction, \n",
    "           disjunction, implication, equivalence]           \n",
    "result_frame = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# display results\n",
    "print('P:', proposition_P)\n",
    "print('Q:', propositon_Q)\n",
    "print()\n",
    "print('Expression Outcomes:-')\n",
    "print(result_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Order Logic\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# for reading FOL expressions\n",
    "read_expr = nltk.sem.Expression.fromstring\n",
    "\n",
    "# initialize theorem provers\n",
    "os.environ['PROVER9'] = r'E:/Users/beliciarodriguez/prover9/LADR-2009-11A/bin'\n",
    "prover = nltk.Prover9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "# set the rule expressions\n",
    "rule = read_expr('all x. all y. (jumps_over(x,y) -> -jumps_over(y, x))')\n",
    "\n",
    "# set the event occured\n",
    "event = read_expr('jumps_over(fox, dog)')\n",
    "\n",
    "# set the outcome we want to evaluate -- the goal\n",
    "test_outcome = read_expr('jumps_over(dog, fox)')\n",
    "\n",
    "# get the result (took out verbose=True)\n",
    "prover.prove(goal=test_outcome, assumptions=[event,rule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "# set the rule expression\n",
    "rule = read_expr('all x. (studies(x, exam) -> pass(x, exam))')\n",
    "\n",
    "# set the events and outcomes we want to determine\n",
    "event1 = read_expr('-studies(John, exam)')\n",
    "test_outcome1 = read_expr('pass(John, exam)')\n",
    "\n",
    "# get results\n",
    "prover.prove(goal=test_outcome1, assumptions=[event1, rule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "# set the events and outcomes we want to determine\n",
    "event2 = read_expr('studies(Pierre, exam)')\n",
    "test_outcome2 = read_expr('pass(Pierre, exam)')\n",
    "\n",
    "# get results\n",
    "prover.prove(goal=test_outcome2, assumptions=[event2, rule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'rover': 'r',\n 'felix': 'f',\n 'garfield': 'g',\n 'alex': 'a',\n 'dog': {('a',), ('r',)},\n 'cat': {('g',)},\n 'fox': {('f',)},\n 'runs': {('a',), ('f',)},\n 'sleeps': {('g',), ('r',)},\n 'jumps_over': {('a', 'g'), ('a', 'r'), ('f', 'g'), ('f', 'r')}}"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "# define symbols (entities\\functions) and their values\n",
    "rules = \"\"\"\n",
    "    rover => r\n",
    "    felix => f\n",
    "    garfield => g\n",
    "    alex => a\n",
    "    dog => {r, a}\n",
    "    cat => {g}\n",
    "    fox => {f}\n",
    "    runs => {a, f}\n",
    "    sleeps => {r, g}\n",
    "    jumps_over => {(f, g), (a, g), (f, r), (a, r)}\n",
    "    \"\"\"\n",
    "\n",
    "val = nltk.Valuation.fromstring(rules)\n",
    "\n",
    "# view the valuation object of symbols and their assigned values (dictionary)\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "# define domain and build FOL based model\n",
    "dom = {'r', 'f', 'g', 'a'}\n",
    "m = nltk.Model(dom, val)\n",
    "\n",
    "# evaluate various expressions\n",
    "m.evaluate('jumps_over(felix, rover) & dog(rover) & runs(rover)', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "m.evaluate('jumps_over(felix, rover) & dog(rover) & -runs(rover)', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "m.evaluate('jumps_over(alex, garfield) & dog(alex) & cat(garfield) & sleeps(garfield)', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "# assign rover to x and felix to y in the domain\n",
    "g = nltk.Assignment(dom, [('x', 'r'), ('y', 'f')])\n",
    "\n",
    "# evaluate more expressions based on above assigned symbols\n",
    "m.evaluate('runs(y) & jumps_over(y, x) & sleeps(x)', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "m.evaluate('exists y. (fox(y) & runs(y))', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'a', 'f'}"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "# who are the animals who run?\n",
    "formula = read_expr('runs(x)')\n",
    "m.satisfiers(formula, 'x', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'f'}"
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "# animals who run and are also a fox?\n",
    "formula = read_expr('runs(x) & fox(x)')\n",
    "m.satisfiers(formula, 'x', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit88832310db0f46c6ba1b97f6fce48e8e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}