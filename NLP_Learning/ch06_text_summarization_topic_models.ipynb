{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization and Topic Models\n",
    "* Text Summarization and Information Extraction\n",
    "* Important Concepts\n",
    "* Keyphrase Extractions\n",
    "    1. Collocations\n",
    "    2. Weighted Tag-Based Phrase Extraction\n",
    "* Topic Modeling on Research Papers\n",
    "    1. The Main Objective\n",
    "    2. Data Retrieval\n",
    "    3. Load and View Dataset\n",
    "    4. Basic Text Wrangling\n",
    "* Topic Models with Gensim\n",
    "    1. Text Representation with Feature Engineering\n",
    "    2. Latent Semantic Indexing\n",
    "    3. Implementing LSI Topic Models from Scratch\n",
    "    4. Latent Dirichlet Allocation\n",
    "    5. LDA Models with MALLET\n",
    "    6. LDA Tuning: Finding the Optimal Number of Topics\n",
    "    7. Interpreting Topic Model Results\n",
    "    8. Predicting Topics for New Research Papers\n",
    "* Topic Models with Scikit-Learn\n",
    "    1. Text Representation with Feature Engineering\n",
    "    2. Latent Semantic Indexing\n",
    "    3. Latent Dirichlet Allocation\n",
    "    4. Non-Negative Matrix Factorization\n",
    "    5. Predicting Topics for New Research Papers\n",
    "    6. Visualizing Topic Models\n",
    "* Automated Document Summarization\n",
    "    1. Text Wrangling\n",
    "    2. Text Representation with Feature Engineering\n",
    "    3. Latent Semantic Analysis\n",
    "    4. TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if spacy doesn't run\n",
    "#!pip3 install spacy\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if nltk error\n",
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "#!pip3 install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract top k singular values and return corresponding U, S, & V matrices\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def low_rank_svd(matrix, singular_count=2):\n",
    "    u,s,vt = svds(matrix, k=singular_count)\n",
    "    return u,s,vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyphrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Alice ' s Adventures in Wonderland by Lewis Carroll 1865 ] \n",
      " alice adventures wonderland lewis carroll\n"
     ]
    }
   ],
   "source": [
    "## Collocations\n",
    "from nltk.corpus import gutenberg\n",
    "import text_normalizer as tn\n",
    "import nltk\n",
    "from operator import itemgetter\n",
    "\n",
    "# load corpus\n",
    "alice = gutenberg.sents(fileids='carroll-alice.txt')\n",
    "alice = [' '.join(ts) for ts in alice]\n",
    "norm_alice = list(filter(None,\n",
    "                         tn.normalize_corpus(alice, text_lemmatization=False)))\n",
    "\n",
    "# print and compare first line\n",
    "print(alice[0], '\\n', norm_alice[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (2, 3, 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_ngrams(sequence, n):\n",
    "    return list(\n",
    "            zip(*(sequence[index:]\n",
    "                  for index in range(n))))\n",
    "\n",
    "# test function\n",
    "compute_ngrams([1,2,3,4], 2) # bi-grams\n",
    "compute_ngrams([1,2,3,4], 3) # tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to flatten corpus into one big string of text\n",
    "def flatten_corpus(corpus):\n",
    "    return ' '.join([document.strip()\n",
    "                    for document in corpus])\n",
    "\n",
    "# get top n-grams for corpus of text\n",
    "def get_top_ngrams(corpus, ngram_val=1, limit=5):\n",
    "    corpus = flatten_corpus(corpus)\n",
    "    tokens = nltk.word_tokenize(corpus)\n",
    "    \n",
    "    ngrams = compute_ngrams(tokens, ngram_val)\n",
    "    ngrams_freq_dist = nltk.FreqDist(ngrams)\n",
    "    sorted_ngrams_fd = sorted(ngrams_freq_dist.items(),\n",
    "                              key=itemgetter(1), reverse=True)\n",
    "    sorted_ngrams = sorted_ngrams_fd[0:limit]\n",
    "    sorted_ngrams = [(' '.join(text), freq)\n",
    "                     for text, freq in sorted_ngrams]\n",
    "    return sorted_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said alice', 123),\n",
       " ('mock turtle', 56),\n",
       " ('march hare', 31),\n",
       " ('said king', 29),\n",
       " ('thought alice', 26),\n",
       " ('white rabbit', 22),\n",
       " ('said hatter', 22),\n",
       " ('said mock', 20),\n",
       " ('said caterpillar', 18),\n",
       " ('said gryphon', 18)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 bigrams\n",
    "get_top_ngrams(corpus=norm_alice, ngram_val=2, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said mock turtle', 20),\n",
       " ('said march hare', 10),\n",
       " ('poor little thing', 6),\n",
       " ('little golden key', 5),\n",
       " ('certainly said alice', 5),\n",
       " ('white kid gloves', 5),\n",
       " ('march hare said', 5),\n",
       " ('mock turtle said', 5),\n",
       " ('know said alice', 4),\n",
       " ('might well say', 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 trigrams\n",
    "get_top_ngrams(corpus=norm_alice, ngram_val=3, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.collocations.BigramCollocationFinder at 0x7f3a583abeb8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use NLTK's collocation finders\n",
    "# bigrams\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "\n",
    "finder = BigramCollocationFinder.from_documents([item.split() for item in norm_alice])\n",
    "finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'alice'),\n",
       " ('mock', 'turtle'),\n",
       " ('march', 'hare'),\n",
       " ('said', 'king'),\n",
       " ('thought', 'alice'),\n",
       " ('said', 'hatter'),\n",
       " ('white', 'rabbit'),\n",
       " ('said', 'mock'),\n",
       " ('said', 'caterpillar'),\n",
       " ('said', 'gryphon')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "# raw frequencies\n",
    "finder.nbest(bigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abide', 'figures'),\n",
       " ('acceptance', 'elegant'),\n",
       " ('accounting', 'tastes'),\n",
       " ('accustomed', 'usurpation'),\n",
       " ('act', 'crawling'),\n",
       " ('adjourn', 'immediate'),\n",
       " ('adoption', 'energetic'),\n",
       " ('affair', 'trusts'),\n",
       " ('agony', 'terror'),\n",
       " ('alarmed', 'proposal')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pointwise mutual information\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigrams\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures\n",
    "\n",
    "finder = TrigramCollocationFinder.from_documents([item.split() for item in norm_alice])\n",
    "\n",
    "trigram_measures = TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'mock', 'turtle'),\n",
       " ('said', 'march', 'hare'),\n",
       " ('poor', 'little', 'thing'),\n",
       " ('little', 'golden', 'key'),\n",
       " ('march', 'hare', 'said'),\n",
       " ('mock', 'turtle', 'said'),\n",
       " ('white', 'kid', 'gloves'),\n",
       " ('beau', 'ootiful', 'soo'),\n",
       " ('certainly', 'said', 'alice'),\n",
       " ('might', 'well', 'say')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw frequencies\n",
    "finder.nbest(trigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accustomed', 'usurpation', 'conquest'),\n",
       " ('adjourn', 'immediate', 'adoption'),\n",
       " ('adoption', 'energetic', 'remedies'),\n",
       " ('ancient', 'modern', 'seaography'),\n",
       " ('apple', 'roast', 'turkey'),\n",
       " ('arithmetic', 'ambition', 'distraction'),\n",
       " ('brother', 'latin', 'grammar'),\n",
       " ('canvas', 'bag', 'tied'),\n",
       " ('cherry', 'tart', 'custard'),\n",
       " ('circle', 'exact', 'shape')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pointwise mutual information\n",
    "finder.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Weighted Tag-Based Phrase Extraction\n",
    "data = open('elephants.txt', 'r+').readlines()\n",
    "sentences = nltk.sent_tokenize(data[0])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephants are large mammals of the family Elephantidae and the order Proboscidea.',\n",
       " 'Three species are currently recognised: the African bush elephant (Loxodonta africana), the African forest elephant (L. cyclotis), and the Asian elephant (Elephas maximus).',\n",
       " 'Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the first three lines\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephants are large mammals of the family Elephantidae and the order Proboscidea',\n",
       " 'Three species are currently recognised the African bush elephant Loxodonta africana the African forest elephant L cyclotis and the Asian elephant Elephas maximus',\n",
       " 'Elephants are scattered throughout subSaharan Africa South Asia and Southeast Asia']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_sentences = tn.normalize_corpus(sentences, text_lower_case=False, text_stemming=False,\n",
    "                                     text_lemmatization=False, stopword_removal=False)\n",
    "norm_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def get_chunks(sentences, grammar=r'NP: {<DT>? <JJ>* <NN.*>+}', stopword_list=stopwords):\n",
    "    all_chunks = []\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tagged_sents = [nltk.pos_tag(nltk.word_tokenize(sentence))]\n",
    "        chunks = [chunker.parse(tagged_sent)\n",
    "                     for tagged_sent in tagged_sents]\n",
    "        wtc_sents = [nltk.chunk.tree2conlltags(chunk)\n",
    "                        for chunk in chunks]\n",
    "        flattened_chunks = list(itertools.chain.from_iterable(wtc_sent for wtc_sent in wtc_sents))\n",
    "        valid_chunks_tagged = [(status, [wtc for wtc in chunk])\n",
    "                                    for status, chunk in itertools.groupby(flattened_chunks,\n",
    "                                                      lambda word_pos_chunk: \n",
    "                                                      word_pos_chunk[2] != 'O')]\n",
    "        valid_chunks = [' '.join(word.lower()\n",
    "                                 for word, tag, chunk in wtc_group\n",
    "                                     if word.lower() not in stopword_list)\n",
    "                                        for status, wtc_group in valid_chunks_tagged if status]\n",
    "        all_chunks.append(valid_chunks)\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elephants', 'large mammals', 'family elephantidae', 'order proboscidea'],\n",
       " ['species',\n",
       "  'african bush elephant loxodonta',\n",
       "  'african forest elephant l cyclotis',\n",
       "  'asian elephant elephas maximus'],\n",
       " ['elephants', 'subsaharan africa south asia', 'southeast asia'],\n",
       " ['elephantidae',\n",
       "  'family',\n",
       "  'order proboscidea',\n",
       "  'extinct members',\n",
       "  'order',\n",
       "  'deinotheres gomphotheres mammoths',\n",
       "  'mastodons'],\n",
       " ['elephants',\n",
       "  'several distinctive features',\n",
       "  'long trunk',\n",
       "  'proboscis',\n",
       "  'many purposes',\n",
       "  'water',\n",
       "  'grasping objects'],\n",
       " ['incisors', 'tusks', 'weapons', 'tools', 'objects'],\n",
       " ['elephants', 'flaps', 'body temperature'],\n",
       " ['pillarlike legs', 'great weight'],\n",
       " ['african elephants',\n",
       "  'ears',\n",
       "  'backs',\n",
       "  'asian elephants',\n",
       "  'ears',\n",
       "  'convex',\n",
       "  'level backs'],\n",
       " ['elephants', 'different habitats', 'savannahs forests deserts', 'marshes'],\n",
       " ['water'],\n",
       " ['keystone species', 'impact', 'environments'],\n",
       " ['animals',\n",
       "  'distance',\n",
       "  'elephants',\n",
       "  'predators',\n",
       "  'lions tigers hyenas',\n",
       "  'wild dogs',\n",
       "  'young elephants',\n",
       "  'calves'],\n",
       " ['elephants', 'fissionfusion society', 'multiple family groups'],\n",
       " ['females cows',\n",
       "  'family groups',\n",
       "  'female',\n",
       "  'calves',\n",
       "  'several related females'],\n",
       " ['groups', 'individual known', 'matriarch', 'cow'],\n",
       " ['males bulls', 'family groups', 'males'],\n",
       " ['adult',\n",
       "  'family groups',\n",
       "  'mate',\n",
       "  'enter state',\n",
       "  'increased testosterone',\n",
       "  'aggression',\n",
       "  'musth',\n",
       "  'dominance',\n",
       "  'reproductive success'],\n",
       " ['calves', 'centre', 'attention', 'family groups', 'mothers', 'years'],\n",
       " ['elephants', 'years', 'wild'],\n",
       " ['touch sight smell',\n",
       "  'sound elephants',\n",
       "  'infrasound',\n",
       "  'seismic communication',\n",
       "  'long distances'],\n",
       " ['elephant intelligence', 'primates', 'cetaceans'],\n",
       " ['selfawareness', 'dead individuals', 'kind'],\n",
       " ['african elephants',\n",
       "  'international union',\n",
       "  'conservation',\n",
       "  'nature iucn',\n",
       "  'asian elephant'],\n",
       " ['threats', 'populations', 'ivory trade', 'animals', 'ivory tusks'],\n",
       " ['threats', 'elephants', 'habitat destruction', 'conflicts', 'local people'],\n",
       " ['elephants', 'animals', 'asia'],\n",
       " ['past', 'war today', 'display', 'zoos', 'entertainment', 'circuses'],\n",
       " ['elephants', 'art folklore religion literature', 'popular culture']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = get_chunks(norm_sentences)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "def get_tfidf_weighted_keyphrases(sentences, grammar=r'NP: {<DT>? <JJ>* <NN.*>+}', top_n=10):\n",
    "    valid_chunks = get_chunks(sentences, grammar=grammar)\n",
    "    \n",
    "    dictionary = corpora.Dictionary(valid_chunks)\n",
    "    corpus = [dictionary.doc2bow(chunk) for chunk in valid_chunks]\n",
    "    \n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    weighted_phrases = {dictionary.get(idx): value for doc in corpus_tfidf for idx, value in doc}\n",
    "    weighted_phrases = sorted(weighted_phrases.items(),\n",
    "                              key=itemgetter(1), reverse=True)\n",
    "    weighted_phrases = [(term, round(wt,3)) for term, wt in weighted_phrases]\n",
    "    \n",
    "    return weighted_phrases[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('water', 1.0),\n",
       " ('asia', 0.807),\n",
       " ('wild', 0.764),\n",
       " ('great weight', 0.707),\n",
       " ('pillarlike legs', 0.707),\n",
       " ('southeast asia', 0.693),\n",
       " ('subsaharan africa south asia', 0.693),\n",
       " ('body temperature', 0.693),\n",
       " ('flaps', 0.693),\n",
       " ('fissionfusion society', 0.693),\n",
       " ('multiple family groups', 0.693),\n",
       " ('art folklore religion literature', 0.693),\n",
       " ('popular culture', 0.693),\n",
       " ('ears', 0.681),\n",
       " ('males', 0.653),\n",
       " ('males bulls', 0.653),\n",
       " ('family elephantidae', 0.607),\n",
       " ('large mammals', 0.607),\n",
       " ('years', 0.607),\n",
       " ('environments', 0.577),\n",
       " ('impact', 0.577),\n",
       " ('keystone species', 0.577),\n",
       " ('cetaceans', 0.577),\n",
       " ('elephant intelligence', 0.577),\n",
       " ('primates', 0.577),\n",
       " ('dead individuals', 0.577),\n",
       " ('kind', 0.577),\n",
       " ('selfawareness', 0.577),\n",
       " ('different habitats', 0.57),\n",
       " ('marshes', 0.57)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 30 tf-idf weighted keyphrases\n",
    "get_tfidf_weighted_keyphrases(sentences=norm_sentences, top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('african bush elephant', 0.261),\n",
       " ('including', 0.141),\n",
       " ('family', 0.137),\n",
       " ('cow', 0.124),\n",
       " ('forests', 0.108),\n",
       " ('female', 0.103),\n",
       " ('asia', 0.102),\n",
       " ('tigers', 0.098),\n",
       " ('ivory', 0.098),\n",
       " ('sight', 0.098),\n",
       " ('objects', 0.098),\n",
       " ('males', 0.088),\n",
       " ('known', 0.087),\n",
       " ('folklore', 0.087),\n",
       " ('religion', 0.087),\n",
       " ('larger ears', 0.085),\n",
       " ('water', 0.075),\n",
       " ('highly recognisable', 0.075),\n",
       " ('breathing lifting', 0.074),\n",
       " ('flaps', 0.073),\n",
       " ('africa', 0.072),\n",
       " ('gomphotheres', 0.072),\n",
       " ('animals tend', 0.071),\n",
       " ('success', 0.071),\n",
       " ('south', 0.07)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "\n",
    "key_words = keywords(data[0], ratio=1.0, scores=True, lemmatize=True)\n",
    "[(item, round(score,3)) for item, score in key_words][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling on Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Retrieval\n",
    "#!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset\n",
    "#!tar -xzf nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nips11', 'nips10', 'nips03', 'README_yann', 'MATLAB_NOTES', 'nips08', 'nips00', 'nips06', 'nips05', 'nips12', 'nips02', 'nips04', 'idx', 'orig', 'nips07', 'nips09', 'nips01', 'RAW_DATA_NOTES']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load and View Dataset\n",
    "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
    "# read all texts into a list\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814 \n",
      "NEU1OMO1PHIC NETWORKS BASED \n",
      "ON SPARSE OPTICAL ORTHOGONAL CODES \n",
      "Mario P. Vecchi and Jawad A. Salehl \n",
      "Bell Communications Research \n",
      "435 South Street \n",
      "Morristown, NJ 07960-1961 \n",
      "Abstract \n",
      "A family of neuromorphic networks specifically designed for communications \n",
      "and optical signal processing applications is presented. The information is encoded \n",
      "utilizing sparse Optical Orthogonal Code sequences on the basis of unipolar, binary \n",
      "(0, 1) signals. The generalized synaptic connectivity matrix is also unipolar, and \n",
      "clipped to binary (0, 1) values. In addition to high-capacity associative memory, \n",
      "the resulting neural networks can be used to implement general functions, such as \n",
      "code filtering, code mapping, code joining, code shifting and code projecting. \n",
      "1 Introduction \n",
      "Synthetic neural nets [1,2] represent an active and growing research field. Fundamental \n",
      "issues, as well as practical implementations with electronic and optical devices are being \n",
      "studied. In addition, several lea\n"
     ]
    }
   ],
   "source": [
    "print(papers[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "CPU times: user 50.2 s, sys: 175 ms, total: 50.4 s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Basic Text Wrangling\n",
    "import nltk\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "        \n",
    "    return norm_papers\n",
    "\n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neu1', 'omo1', 'phic', 'network', 'based', 'sparse', 'optical', 'orthogonal', 'code', 'mario', 'vecchi', 'jawad', 'salehl', 'bell', 'communication', 'research', 'south', 'street', 'morristown', 'nj', 'abstract', 'family', 'neuromorphic', 'network', 'specifically', 'designed', 'communication', 'optical', 'signal', 'processing', 'application', 'presented', 'information', 'encoded', 'utilizing', 'sparse', 'optical', 'orthogonal', 'code', 'sequence', 'basis', 'unipolar', 'binary', 'signal', 'generalized', 'synaptic', 'connectivity', 'matrix', 'also', 'unipolar']\n"
     ]
    }
   ],
   "source": [
    "# viewing a processed paper\n",
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neu1', 'omo1', 'phic', 'network', 'based', 'sparse', 'optical', 'orthogonal', 'code', 'mario', 'vecchi', 'jawad', 'salehl', 'bell', 'communication', 'research', 'south', 'street', 'morristown', 'nj_abstract', 'family', 'neuromorphic', 'network', 'specifically', 'designed', 'communication', 'optical', 'signal_processing', 'application', 'presented', 'information', 'encoded', 'utilizing', 'sparse', 'optical', 'orthogonal', 'code', 'sequence', 'basis', 'unipolar', 'binary', 'signal', 'generalized', 'synaptic', 'connectivity', 'matrix', 'also', 'unipolar', 'clipped', 'binary']\n"
     ]
    }
   ],
   "source": [
    "## Text Representation with Feature Engineering\n",
    "import gensim\n",
    "\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, \n",
    "                               threshold=20, delimiter=b'_') # higher threshold fewer phrases\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "# sample demonstration\n",
    "print(bigram_model[norm_papers[0]][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, '2f'), (1, '2our'), (2, '3the'), (3, '82o'), (4, '86ch'), (5, '_b'), (6, '_t'), (7, '_u'), (8, '_v'), (9, '_ym'), (10, '_z'), (11, 'ability'), (12, 'absence'), (13, 'ac'), (14, 'acad_sci')]\n",
      "Total Vocabulary Size 78892\n"
     ]
    }
   ],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
    "\n",
    "# create a dictionary representation of the documents\n",
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 7756\n"
     ]
    }
   ],
   "source": [
    "# filer out words that occur less than 20 documents, or more than 50% of the documents\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (8, 1), (13, 2), (20, 1), (24, 1), (34, 2), (46, 2), (52, 1), (56, 1), (57, 2), (58, 2), (66, 1), (76, 3), (77, 1), (83, 1), (86, 1), (87, 1), (100, 1), (101, 1), (103, 1), (105, 2), (108, 1), (113, 1), (117, 1), (118, 2), (119, 1), (126, 1), (130, 1), (132, 1), (138, 2), (148, 2), (155, 1), (169, 2), (172, 1), (173, 3), (177, 2), (185, 2), (186, 2), (189, 2), (190, 1), (200, 1), (210, 3), (211, 1), (217, 1), (218, 3), (222, 4), (227, 5), (231, 2), (240, 2), (245, 1)]\n"
     ]
    }
   ],
   "source": [
    "# transforming corpus into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('absence', 1), ('accurately', 1), ('addition', 2), ('american_institute', 1), ('application', 1), ('available', 2), ('body', 2), ('channel', 1), ('class', 1), ('clear', 2), ('clearly', 2), ('combination', 1), ('computational', 3), ('computer', 1), ('condition', 1), ('connected', 1), ('connectivity', 1), ('corresponding', 1), ('corresponds', 1), ('cross', 1), ('cycle', 2), ('defined', 1), ('design', 1), ('determined', 1), ('developed', 2), ('development', 1), ('directly', 1), ('discussion', 1), ('distinct', 1), ('easily', 2), ('end', 2), ('established', 1), ('far', 2), ('feedback', 1), ('fiber', 3), ('filter', 2), ('functional', 2), ('fundamental', 2), ('generally', 2), ('generate', 1), ('hard', 1), ('iii', 3), ('ij', 1), ('importance', 1), ('important', 3), ('indicated', 4), ('intensity', 5), ('interesting', 2), ('le', 2), ('line', 1)]\n"
     ]
    }
   ],
   "source": [
    "# viewing actual terms and their counts\n",
    "print([(dictionary[idx], freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers: 1740\n"
     ]
    }
   ],
   "source": [
    "# total papers in the corpus\n",
    "print('Total number of papers:', len(bow_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 59s, sys: 69.9 ms, total: 3min\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Latent Semantic Indexing\n",
    "TOTAL_TOPICS = 10\n",
    "lsi_bow = gensim.models.LsiModel(bow_corpus, id2word=dictionary, num_topics=TOTAL_TOPICS, \n",
    "                                 onepass=True, chunksize=1740, power_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.215*\"unit\" + 0.212*\"state\" + 0.187*\"training\" + 0.177*\"neuron\" + 0.162*\"pattern\" + 0.145*\"image\" + 0.140*\"vector\" + 0.125*\"feature\" + 0.122*\"cell\" + 0.110*\"layer\" + 0.101*\"task\" + 0.097*\"class\" + 0.091*\"probability\" + 0.089*\"signal\" + 0.087*\"step\" + 0.086*\"response\" + 0.085*\"representation\" + 0.083*\"noise\" + 0.082*\"rule\" + 0.081*\"distribution\"\n",
      "\n",
      "Topic #2:\n",
      "-0.487*\"neuron\" + -0.396*\"cell\" + 0.257*\"state\" + -0.191*\"response\" + 0.187*\"training\" + -0.170*\"stimulus\" + -0.117*\"activity\" + 0.109*\"class\" + -0.099*\"spike\" + -0.097*\"pattern\" + -0.096*\"circuit\" + -0.096*\"synaptic\" + 0.095*\"vector\" + -0.090*\"signal\" + -0.090*\"firing\" + -0.088*\"visual\" + 0.084*\"classifier\" + 0.083*\"action\" + 0.078*\"word\" + -0.078*\"cortical\"\n",
      "\n",
      "Topic #3:\n",
      "0.627*\"state\" + -0.395*\"image\" + 0.219*\"neuron\" + -0.209*\"feature\" + 0.188*\"action\" + -0.137*\"unit\" + -0.131*\"object\" + 0.130*\"control\" + -0.129*\"training\" + 0.109*\"policy\" + -0.103*\"classifier\" + -0.090*\"class\" + 0.081*\"step\" + 0.081*\"dynamic\" + -0.080*\"classification\" + -0.078*\"layer\" + -0.076*\"recognition\" + 0.074*\"reinforcement_learning\" + -0.069*\"representation\" + -0.068*\"pattern\"\n",
      "\n",
      "Topic #4:\n",
      "-0.686*\"unit\" + 0.433*\"image\" + -0.182*\"pattern\" + -0.131*\"layer\" + -0.123*\"hidden_unit\" + -0.121*\"net\" + -0.114*\"training\" + 0.112*\"feature\" + -0.109*\"activation\" + -0.107*\"rule\" + 0.097*\"neuron\" + -0.078*\"word\" + 0.070*\"pixel\" + -0.070*\"connection\" + 0.067*\"object\" + 0.065*\"state\" + 0.060*\"distribution\" + 0.059*\"face\" + -0.057*\"architecture\" + 0.055*\"estimate\"\n",
      "\n",
      "Topic #5:\n",
      "-0.428*\"image\" + -0.348*\"state\" + 0.266*\"neuron\" + -0.264*\"unit\" + 0.181*\"training\" + 0.174*\"class\" + -0.168*\"object\" + 0.167*\"classifier\" + -0.147*\"action\" + -0.122*\"visual\" + 0.117*\"vector\" + 0.115*\"node\" + 0.105*\"distribution\" + -0.103*\"motion\" + -0.099*\"feature\" + 0.097*\"classification\" + -0.097*\"control\" + -0.095*\"task\" + -0.087*\"cell\" + -0.083*\"representation\"\n",
      "\n",
      "Topic #6:\n",
      "-0.660*\"cell\" + 0.508*\"neuron\" + 0.213*\"image\" + 0.103*\"chip\" + 0.097*\"unit\" + -0.093*\"response\" + 0.090*\"object\" + -0.083*\"rat\" + -0.076*\"distribution\" + 0.070*\"circuit\" + -0.069*\"probability\" + -0.064*\"stimulus\" + 0.061*\"memory\" + 0.058*\"analog\" + 0.058*\"activation\" + -0.055*\"class\" + 0.053*\"bit\" + 0.052*\"net\" + -0.051*\"cortical\" + -0.050*\"firing\"\n",
      "\n",
      "Topic #7:\n",
      "0.353*\"word\" + -0.281*\"unit\" + 0.272*\"training\" + 0.257*\"classifier\" + 0.177*\"recognition\" + -0.159*\"distribution\" + 0.152*\"feature\" + 0.144*\"state\" + 0.142*\"pattern\" + -0.141*\"vector\" + 0.128*\"cell\" + 0.128*\"task\" + -0.122*\"approximation\" + -0.121*\"variable\" + -0.110*\"equation\" + 0.107*\"classification\" + -0.106*\"noise\" + 0.103*\"class\" + -0.101*\"matrix\" + 0.098*\"neuron\"\n",
      "\n",
      "Topic #8:\n",
      "-0.303*\"pattern\" + 0.243*\"signal\" + 0.236*\"control\" + 0.202*\"training\" + -0.181*\"rule\" + -0.178*\"state\" + 0.167*\"noise\" + -0.166*\"class\" + 0.162*\"word\" + -0.155*\"cell\" + -0.154*\"feature\" + 0.147*\"motion\" + 0.140*\"task\" + -0.127*\"node\" + -0.124*\"neuron\" + 0.116*\"target\" + 0.114*\"circuit\" + -0.114*\"probability\" + -0.110*\"classifier\" + -0.109*\"image\"\n",
      "\n",
      "Topic #9:\n",
      "-0.472*\"node\" + -0.254*\"circuit\" + 0.214*\"word\" + -0.201*\"chip\" + 0.190*\"neuron\" + 0.172*\"stimulus\" + -0.160*\"classifier\" + -0.152*\"current\" + 0.147*\"feature\" + -0.146*\"voltage\" + 0.145*\"distribution\" + -0.141*\"control\" + -0.124*\"rule\" + -0.110*\"layer\" + -0.105*\"analog\" + -0.091*\"tree\" + 0.084*\"response\" + 0.080*\"state\" + 0.079*\"probability\" + 0.079*\"estimate\"\n",
      "\n",
      "Topic #10:\n",
      "0.518*\"word\" + -0.254*\"training\" + 0.236*\"vector\" + -0.222*\"task\" + -0.194*\"pattern\" + -0.156*\"classifier\" + 0.149*\"node\" + 0.146*\"recognition\" + -0.139*\"control\" + 0.138*\"sequence\" + -0.126*\"rule\" + 0.125*\"circuit\" + 0.123*\"cell\" + -0.113*\"action\" + -0.105*\"neuron\" + 0.094*\"hmm\" + 0.093*\"character\" + 0.088*\"chip\" + 0.088*\"matrix\" + 0.085*\"structure\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lsi_bow.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.215), ('state', 0.212), ('training', 0.187), ('neuron', 0.177), ('pattern', 0.162), ('image', 0.145), ('vector', 0.14), ('feature', 0.125), ('cell', 0.122), ('layer', 0.11), ('task', 0.101), ('class', 0.097), ('probability', 0.091), ('signal', 0.089), ('step', 0.087), ('response', 0.086), ('representation', 0.085), ('noise', 0.083), ('rule', 0.082), ('distribution', 0.081)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('state', 0.257), ('training', 0.187), ('class', 0.109), ('vector', 0.095), ('classifier', 0.084), ('action', 0.083), ('word', 0.078)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.487), ('cell', -0.396), ('response', -0.191), ('stimulus', -0.17), ('activity', -0.117), ('spike', -0.099), ('pattern', -0.097), ('circuit', -0.096), ('synaptic', -0.096), ('signal', -0.09), ('firing', -0.09), ('visual', -0.088), ('cortical', -0.078)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('state', 0.627), ('neuron', 0.219), ('action', 0.188), ('control', 0.13), ('policy', 0.109), ('step', 0.081), ('dynamic', 0.081), ('reinforcement_learning', 0.074)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.395), ('feature', -0.209), ('unit', -0.137), ('object', -0.131), ('training', -0.129), ('classifier', -0.103), ('class', -0.09), ('classification', -0.08), ('layer', -0.078), ('recognition', -0.076), ('representation', -0.069), ('pattern', -0.068)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.433), ('feature', 0.112), ('neuron', 0.097), ('pixel', 0.07), ('object', 0.067), ('state', 0.065), ('distribution', 0.06), ('face', 0.059), ('estimate', 0.055)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -0.686), ('pattern', -0.182), ('layer', -0.131), ('hidden_unit', -0.123), ('net', -0.121), ('training', -0.114), ('activation', -0.109), ('rule', -0.107), ('word', -0.078), ('connection', -0.07), ('architecture', -0.057)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.266), ('training', 0.181), ('class', 0.174), ('classifier', 0.167), ('vector', 0.117), ('node', 0.115), ('distribution', 0.105), ('classification', 0.097)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.428), ('state', -0.348), ('unit', -0.264), ('object', -0.168), ('action', -0.147), ('visual', -0.122), ('motion', -0.103), ('feature', -0.099), ('control', -0.097), ('task', -0.095), ('cell', -0.087), ('representation', -0.083)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.508), ('image', 0.213), ('chip', 0.103), ('unit', 0.097), ('object', 0.09), ('circuit', 0.07), ('memory', 0.061), ('analog', 0.058), ('activation', 0.058), ('bit', 0.053), ('net', 0.052)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('cell', -0.66), ('response', -0.093), ('rat', -0.083), ('distribution', -0.076), ('probability', -0.069), ('stimulus', -0.064), ('class', -0.055), ('cortical', -0.051), ('firing', -0.05)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.353), ('training', 0.272), ('classifier', 0.257), ('recognition', 0.177), ('feature', 0.152), ('state', 0.144), ('pattern', 0.142), ('cell', 0.128), ('task', 0.128), ('classification', 0.107), ('class', 0.103), ('neuron', 0.098)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -0.281), ('distribution', -0.159), ('vector', -0.141), ('approximation', -0.122), ('variable', -0.121), ('equation', -0.11), ('noise', -0.106), ('matrix', -0.101)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('signal', 0.243), ('control', 0.236), ('training', 0.202), ('noise', 0.167), ('word', 0.162), ('motion', 0.147), ('task', 0.14), ('target', 0.116), ('circuit', 0.114)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('pattern', -0.303), ('rule', -0.181), ('state', -0.178), ('class', -0.166), ('cell', -0.155), ('feature', -0.154), ('node', -0.127), ('neuron', -0.124), ('probability', -0.114), ('classifier', -0.11), ('image', -0.109)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.214), ('neuron', 0.19), ('stimulus', 0.172), ('feature', 0.147), ('distribution', 0.145), ('response', 0.084), ('state', 0.08), ('probability', 0.079), ('estimate', 0.079)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('node', -0.472), ('circuit', -0.254), ('chip', -0.201), ('classifier', -0.16), ('current', -0.152), ('voltage', -0.146), ('control', -0.141), ('rule', -0.124), ('layer', -0.11), ('analog', -0.105), ('tree', -0.091)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.518), ('vector', 0.236), ('node', 0.149), ('recognition', 0.146), ('sequence', 0.138), ('circuit', 0.125), ('cell', 0.123), ('hmm', 0.094), ('character', 0.093), ('chip', 0.088), ('matrix', 0.088), ('structure', 0.085)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('training', -0.254), ('task', -0.222), ('pattern', -0.194), ('classifier', -0.156), ('control', -0.139), ('rule', -0.126), ('action', -0.113), ('neuron', -0.105)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    for term, wt in lsi_bow.show_topic(n, topn=20):\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt,3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt,3)))\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get U, S, VT matrices from topic model\n",
    "term_topic = lsi_bow.projection.u\n",
    "singular_values = lsi_bow.projection.s\n",
    "topic_document = (gensim.matutils.corpus2dense(lsi_bow[bow_corpus], len(singular_values)).T / singular_values).T\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
       "0  0.025  0.011  0.001  0.011  0.026  0.015 -0.030 -0.025 -0.016  0.073\n",
       "1  0.021 -0.028  0.004  0.003 -0.003 -0.000  0.008  0.009  0.008 -0.014\n",
       "2  0.027 -0.007 -0.006  0.017  0.017  0.035  0.008 -0.001 -0.079  0.075\n",
       "3  0.016 -0.017  0.013  0.008  0.024  0.028 -0.000 -0.019  0.008 -0.006\n",
       "4  0.018 -0.030  0.003  0.001  0.006 -0.031  0.005 -0.001  0.001  0.004"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document topic matrix for our LSI model\n",
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_topics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T8', 'T1', 'T4']\n",
      "Paper Summary:\n",
      "412 \n",
      "CAPACITY FOR PATTERNS AND SEQUENCES IN KANERVA'S SDM \n",
      "AS COMPARED TO OTHER ASSOCIATIVE MEMORY MODELS \n",
      "James D. Keeler \n",
      "Chemistry Department, Stanford University, Stanford, CA 94305 \n",
      "and RIACS, NASA-AMES 230-5 Moffett Field, CA 94035. \n",
      "e.rnail: jdk hydra.riacs. edu \n",
      "ABSTRACT \n",
      "The information capacity of Kanerva's Sparse, Distributed Memory (SDM) and Hopfield-type \n",
      "neural networks is investigated. Under the approximations used here, it is shown that the to- \n",
      "tal information stored in these s\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T8', 'T1', 'T2']\n",
      "Paper Summary:\n",
      "68 Baird \n",
      "Associative Memory in a Simple Model of \n",
      "Oscillating Cortex \n",
      "Bill Baird \n",
      "Dept Molecular and Cell Biology, \n",
      "U.C.Berkeley, Berkeley, Ca. 94720 \n",
      "ABSTRACT \n",
      "A generic model of oscillating cortex, which assumes \"minimal\" \n",
      "coupling justified by known anatomy, is shown to function as an \n",
      "sociative memory, using previously developed theory. The network \n",
      "has explicit excitatory neurons with local inhibitory interneuron \n",
      "feedback that forms a set of nonlinear oscillators coupled only by \n",
      "long ran\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T10', 'T4', 'T9']\n",
      "Paper Summary:\n",
      "Interpretation of Artificial Neural Networks: \n",
      "Mapping Knowledge-Based Neural Networks into Rules \n",
      "Geoffrey Towell Jude W. Shavlik \n",
      "Computer Sciences Department \n",
      "University of Wisconsin \n",
      "Madison, WI 53706 \n",
      "Abstract \n",
      "We propose and empirically evaluate a method for the extraction of expert- \n",
      "comprehensible rules from trained neural networks. Our method operates in \n",
      "the context of a three-step process for learning that uses rule-based domain \n",
      "knowledge in combination with neural networks. Empirica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_numbers = [13, 250, 500]\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.\n",
    "                      columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7756, 1740)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Implementing LSI Topic Models from Scratch\n",
    "td_matrix = gensim.matutils.corpus2dense(corpus=bow_corpus, num_terms=len(dictionary))\n",
    "print(td_matrix.shape)\n",
    "td_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['3the', 'ability', 'absence', ..., 'smola', 'mozer_jordan',\n",
       "       'kearns_solla'], dtype='<U28')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = np.array(list(dictionary.values()))\n",
    "print('Total vocabulary size:', len(vocabulary))\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "u, s, vt = svds(td_matrix, k=TOTAL_TOPICS, maxiter=10000)\n",
    "term_topic = u\n",
    "singular_values = s\n",
    "topic_document = vt\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7756)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_weights = term_topic.transpose() * singular_values[:,None]\n",
    "tt_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('training', 92.619), ('task', 80.732), ('pattern', 70.618), ('classifier', 56.988), ('control', 50.676), ('rule', 45.926), ('action', 41.202), ('neuron', 38.194)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -188.487), ('vector', -85.973), ('node', -54.378), ('recognition', -53.232), ('sequence', -50.351), ('circuit', -45.395), ('cell', -44.811), ('hmm', -34.085), ('character', -34.022), ('chip', -32.161), ('matrix', -32.093), ('structure', -30.993)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('node', 173.276), ('circuit', 92.999), ('chip', 73.593), ('classifier', 58.718), ('current', 55.844), ('voltage', 53.489), ('control', 51.708), ('rule', 45.295), ('layer', 40.265), ('analog', 38.344), ('tree', 33.483)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -78.349), ('neuron', -69.793), ('stimulus', -63.234), ('feature', -53.819), ('distribution', -53.119), ('response', -30.954), ('state', -29.343), ('probability', -29.099), ('estimate', -28.908)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('pattern', 116.971), ('rule', 69.783), ('state', 68.605), ('class', 64.259), ('cell', 59.979), ('feature', 59.607), ('node', 49.175), ('neuron', 47.998), ('probability', 43.813), ('classifier', 42.612), ('image', 42.061)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('signal', -93.805), ('control', -91.041), ('training', -77.88), ('noise', -64.397), ('word', -62.392), ('motion', -56.699), ('task', -53.882), ('target', -44.765), ('circuit', -44.129)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('word', 147.792), ('training', 113.693), ('classifier', 107.386), ('recognition', 73.948), ('feature', 63.454), ('state', 60.126), ('pattern', 59.561), ('cell', 53.768), ('task', 53.693), ('classification', 44.936), ('class', 43.161), ('neuron', 41.092)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -117.727), ('distribution', -66.719), ('vector', -58.881), ('approximation', -50.931), ('variable', -50.83), ('equation', -46.229), ('noise', -44.247), ('matrix', -42.214)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('cell', 285.803), ('response', 40.216), ('rat', 35.975), ('distribution', 33.085), ('probability', 29.79), ('stimulus', 27.789), ('class', 24.02), ('cortical', 22.185), ('firing', 21.66)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -220.116), ('image', -92.391), ('chip', -44.422), ('unit', -41.922), ('object', -39.001), ('circuit', -30.444), ('memory', -26.475), ('analog', -25.207), ('activation', -24.953), ('bit', -22.997), ('net', -22.699)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('image', 209.795), ('state', 170.208), ('unit', 129.106), ('object', 82.185), ('action', 72.136), ('visual', 59.503), ('motion', 50.605), ('feature', 48.665), ('control', 47.427), ('task', 46.496), ('cell', 42.366), ('representation', 40.564)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -130.053), ('training', -88.668), ('class', -85.213), ('classifier', -81.92), ('vector', -57.532), ('node', -56.341), ('distribution', -51.622), ('classification', -47.645)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('image', 215.856), ('feature', 55.647), ('neuron', 48.495), ('pixel', 35.095), ('object', 33.584), ('state', 32.543), ('distribution', 29.977), ('face', 29.256), ('estimate', 27.556)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -341.83), ('pattern', -90.771), ('layer', -65.337), ('hidden_unit', -61.12), ('net', -60.035), ('training', -56.741), ('activation', -54.268), ('rule', -53.377), ('word', -38.903), ('connection', -34.618), ('architecture', -28.439)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('image', 229.287), ('feature', 121.397), ('unit', 79.44), ('object', 76.204), ('training', 75.153), ('classifier', 59.872), ('class', 52.527), ('classification', 46.696), ('layer', 45.149), ('recognition', 44.192), ('representation', 40.179), ('pattern', 39.252)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -364.388), ('neuron', -127.022), ('action', -109.245), ('control', -75.369), ('policy', -63.103), ('step', -47.226), ('dynamic', -46.907), ('reinforcement_learning', -42.747)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('state', 161.465), ('training', 117.319), ('class', 68.732), ('vector', 59.558), ('classifier', 52.589), ('action', 52.113), ('word', 49.239)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -306.151), ('cell', -249.243), ('response', -119.758), ('stimulus', -106.762), ('activity', -73.499), ('spike', -62.039), ('pattern', -60.957), ('circuit', -60.602), ('synaptic', -60.282), ('signal', -56.665), ('firing', -56.597), ('visual', -55.571), ('cortical', -48.867)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: []\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -260.793), ('state', -258.146), ('training', -227.312), ('neuron', -215.681), ('pattern', -197.232), ('image', -175.735), ('vector', -170.154), ('feature', -151.547), ('cell', -148.138), ('layer', -133.593), ('task', -122.389), ('class', -117.849), ('probability', -110.526), ('signal', -108.232), ('step', -105.202), ('response', -104.465), ('representation', -103.255), ('noise', -100.573), ('rule', -99.611), ('distribution', -98.973)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_terms = 20\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(tt_weights), axis=1)[:, :top_terms]\n",
    "topic_keyterm_weights = np.array([tt_weights[row, columns]\n",
    "                                 for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    terms, weights = topic_keyterms_weights[n]\n",
    "    term_weights = sorted([(t,w) for t, w in zip(terms, weights)], key=lambda row: -abs(row[1]))\n",
    "    for term, wt in term_weights:\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T3', 'T10', 'T7']\n",
      "Paper Summary:\n",
      "412 \n",
      "CAPACITY FOR PATTERNS AND SEQUENCES IN KANERVA'S SDM \n",
      "AS COMPARED TO OTHER ASSOCIATIVE MEMORY MODELS \n",
      "James D. Keeler \n",
      "Chemistry Department, Stanford University, Stanford, CA 94305 \n",
      "and RIACS, NASA-AMES 230-5 Moffett Field, CA 94035. \n",
      "e.rnail: jdk hydra.riacs. edu \n",
      "ABSTRACT \n",
      "The information capacity of Kanerva's Sparse, Distributed Memory (SDM) and Hopfield-type \n",
      "neural networks is investigated. Under the approximations used here, it is shown that the to- \n",
      "tal information stored in these s\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T3', 'T10', 'T9']\n",
      "Paper Summary:\n",
      "68 Baird \n",
      "Associative Memory in a Simple Model of \n",
      "Oscillating Cortex \n",
      "Bill Baird \n",
      "Dept Molecular and Cell Biology, \n",
      "U.C.Berkeley, Berkeley, Ca. 94720 \n",
      "ABSTRACT \n",
      "A generic model of oscillating cortex, which assumes \"minimal\" \n",
      "coupling justified by known anatomy, is shown to function as an \n",
      "sociative memory, using previously developed theory. The network \n",
      "has explicit excitatory neurons with local inhibitory interneuron \n",
      "feedback that forms a set of nonlinear oscillators coupled only by \n",
      "long ran\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T1', 'T7', 'T2']\n",
      "Paper Summary:\n",
      "Interpretation of Artificial Neural Networks: \n",
      "Mapping Knowledge-Based Neural Networks into Rules \n",
      "Geoffrey Towell Jude W. Shavlik \n",
      "Computer Sciences Department \n",
      "University of Wisconsin \n",
      "Madison, WI 53706 \n",
      "Abstract \n",
      "We propose and empirically evaluate a method for the extraction of expert- \n",
      "comprehensible rules from trained neural networks. Our method operates in \n",
      "the context of a three-step process for learning that uses rule-based domain \n",
      "knowledge in combination with neural networks. Empirica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_numbers = [13, 250, 500]\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.\n",
    "                      columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 1.15 s, total: 1min 32s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Latent Dirichlet Allocation\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, \n",
    "                                   chunksize=1740, alpha='auto', eta='auto', random_state=42, \n",
    "                                   iterations=500, num_topics=TOTAL_TOPICS, \n",
    "                                   passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.012*\"classifier\" + 0.010*\"class\" + 0.010*\"classification\" + 0.009*\"training\" + 0.008*\"feature\" + 0.006*\"pattern\" + 0.006*\"vector\" + 0.005*\"tree\" + 0.004*\"probability\" + 0.004*\"test\" + 0.004*\"expert\" + 0.004*\"cluster\" + 0.004*\"clustering\" + 0.004*\"training_set\" + 0.004*\"distance\" + 0.004*\"node\" + 0.003*\"sample\" + 0.003*\"table\" + 0.003*\"technique\" + 0.003*\"application\"\n",
      "\n",
      "Topic #2:\n",
      "0.017*\"cell\" + 0.017*\"unit\" + 0.016*\"pattern\" + 0.010*\"layer\" + 0.007*\"activity\" + 0.006*\"connection\" + 0.005*\"synaptic\" + 0.004*\"synapsis\" + 0.004*\"activation\" + 0.004*\"simulation\" + 0.004*\"rule\" + 0.004*\"rat\" + 0.004*\"kernel\" + 0.004*\"perturbation\" + 0.004*\"active\" + 0.004*\"training\" + 0.003*\"hidden_unit\" + 0.003*\"effect\" + 0.003*\"memory\" + 0.003*\"region\"\n",
      "\n",
      "Topic #3:\n",
      "0.016*\"training\" + 0.015*\"unit\" + 0.009*\"word\" + 0.008*\"recognition\" + 0.007*\"net\" + 0.007*\"layer\" + 0.007*\"task\" + 0.007*\"trained\" + 0.007*\"hidden_unit\" + 0.006*\"feature\" + 0.006*\"pattern\" + 0.006*\"speech\" + 0.006*\"architecture\" + 0.004*\"representation\" + 0.004*\"character\" + 0.004*\"sequence\" + 0.004*\"context\" + 0.003*\"experiment\" + 0.003*\"training_set\" + 0.003*\"frame\"\n",
      "\n",
      "Topic #4:\n",
      "0.021*\"neuron\" + 0.014*\"circuit\" + 0.011*\"chip\" + 0.010*\"current\" + 0.009*\"cell\" + 0.008*\"voltage\" + 0.007*\"analog\" + 0.006*\"signal\" + 0.005*\"synaptic\" + 0.005*\"channel\" + 0.005*\"response\" + 0.005*\"synapse\" + 0.004*\"neural\" + 0.004*\"threshold\" + 0.004*\"synapsis\" + 0.004*\"frequency\" + 0.004*\"bit\" + 0.004*\"pulse\" + 0.003*\"implementation\" + 0.003*\"connection\"\n",
      "\n",
      "Topic #5:\n",
      "0.019*\"neuron\" + 0.009*\"signal\" + 0.009*\"dynamic\" + 0.009*\"noise\" + 0.007*\"state\" + 0.007*\"spike\" + 0.007*\"equation\" + 0.005*\"solution\" + 0.004*\"neural\" + 0.004*\"rate\" + 0.004*\"eq\" + 0.004*\"phase\" + 0.004*\"rule\" + 0.003*\"fixed_point\" + 0.003*\"correlation\" + 0.003*\"distribution\" + 0.003*\"matrix\" + 0.003*\"delay\" + 0.003*\"constant\" + 0.003*\"energy\"\n",
      "\n",
      "Topic #6:\n",
      "0.049*\"image\" + 0.013*\"object\" + 0.011*\"feature\" + 0.010*\"pixel\" + 0.008*\"face\" + 0.006*\"filter\" + 0.006*\"visual\" + 0.006*\"view\" + 0.005*\"representation\" + 0.004*\"surface\" + 0.004*\"region\" + 0.004*\"local\" + 0.004*\"scale\" + 0.004*\"scene\" + 0.004*\"ica\" + 0.004*\"recognition\" + 0.003*\"position\" + 0.003*\"shape\" + 0.003*\"linear\" + 0.003*\"location\"\n",
      "\n",
      "Topic #7:\n",
      "0.012*\"rule\" + 0.011*\"node\" + 0.010*\"memory\" + 0.009*\"pattern\" + 0.008*\"vector\" + 0.008*\"unit\" + 0.007*\"structure\" + 0.006*\"representation\" + 0.006*\"sequence\" + 0.004*\"state\" + 0.004*\"matrix\" + 0.004*\"activation\" + 0.004*\"symbol\" + 0.004*\"graph\" + 0.004*\"attractor\" + 0.003*\"capacity\" + 0.003*\"similarity\" + 0.003*\"language\" + 0.003*\"level\" + 0.003*\"element\"\n",
      "\n",
      "Topic #8:\n",
      "0.007*\"distribution\" + 0.006*\"vector\" + 0.006*\"training\" + 0.005*\"approximation\" + 0.005*\"linear\" + 0.005*\"estimate\" + 0.005*\"probability\" + 0.004*\"variable\" + 0.004*\"class\" + 0.004*\"sample\" + 0.004*\"matrix\" + 0.004*\"let\" + 0.004*\"gaussian\" + 0.003*\"equation\" + 0.003*\"bound\" + 0.003*\"prior\" + 0.003*\"optimal\" + 0.003*\"noise\" + 0.003*\"consider\" + 0.003*\"prediction\"\n",
      "\n",
      "Topic #9:\n",
      "0.012*\"stimulus\" + 0.011*\"response\" + 0.011*\"cell\" + 0.008*\"visual\" + 0.008*\"neuron\" + 0.007*\"motion\" + 0.007*\"unit\" + 0.006*\"activity\" + 0.006*\"map\" + 0.005*\"direction\" + 0.005*\"pattern\" + 0.004*\"cortical\" + 0.004*\"spatial\" + 0.004*\"orientation\" + 0.004*\"receptive_field\" + 0.004*\"cortex\" + 0.004*\"location\" + 0.004*\"et_al\" + 0.004*\"signal\" + 0.004*\"field\"\n",
      "\n",
      "Topic #10:\n",
      "0.030*\"state\" + 0.012*\"control\" + 0.010*\"action\" + 0.007*\"step\" + 0.006*\"task\" + 0.006*\"policy\" + 0.005*\"controller\" + 0.005*\"trajectory\" + 0.005*\"reinforcement_learning\" + 0.004*\"optimal\" + 0.004*\"environment\" + 0.004*\"dynamic\" + 0.004*\"robot\" + 0.003*\"training\" + 0.003*\"goal\" + 0.003*\"current\" + 0.003*\"transition\" + 0.003*\"adaptive\" + 0.003*\"reward\" + 0.003*\"sequence\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view topics in trained topic model\n",
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score: -1.0976687786641732\n"
     ]
    }
   ],
   "source": [
    "# view overall mean coherence score of model\n",
    "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
    "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
    "print('Avg. Coherence Score:', avg_coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "[('distribution', 0.007), ('vector', 0.006), ('training', 0.006), ('approximation', 0.005), ('linear', 0.005), ('estimate', 0.005), ('probability', 0.005), ('variable', 0.004), ('class', 0.004), ('sample', 0.004), ('matrix', 0.004), ('let', 0.004), ('gaussian', 0.004), ('equation', 0.003), ('bound', 0.003), ('prior', 0.003), ('optimal', 0.003), ('noise', 0.003), ('consider', 0.003), ('prediction', 0.003)]\n",
      "\n",
      "Topic #2:\n",
      "[('stimulus', 0.012), ('response', 0.011), ('cell', 0.011), ('visual', 0.008), ('neuron', 0.008), ('motion', 0.007), ('unit', 0.007), ('activity', 0.006), ('map', 0.006), ('direction', 0.005), ('pattern', 0.005), ('cortical', 0.004), ('spatial', 0.004), ('orientation', 0.004), ('receptive_field', 0.004), ('cortex', 0.004), ('location', 0.004), ('et_al', 0.004), ('signal', 0.004), ('field', 0.004)]\n",
      "\n",
      "Topic #3:\n",
      "[('classifier', 0.012), ('class', 0.01), ('classification', 0.01), ('training', 0.009), ('feature', 0.008), ('pattern', 0.006), ('vector', 0.006), ('tree', 0.005), ('probability', 0.004), ('test', 0.004), ('expert', 0.004), ('cluster', 0.004), ('clustering', 0.004), ('training_set', 0.004), ('distance', 0.004), ('node', 0.004), ('sample', 0.003), ('table', 0.003), ('technique', 0.003), ('application', 0.003)]\n",
      "\n",
      "Topic #4:\n",
      "[('training', 0.016), ('unit', 0.015), ('word', 0.009), ('recognition', 0.008), ('net', 0.007), ('layer', 0.007), ('task', 0.007), ('trained', 0.007), ('hidden_unit', 0.007), ('feature', 0.006), ('pattern', 0.006), ('speech', 0.006), ('architecture', 0.006), ('representation', 0.004), ('character', 0.004), ('sequence', 0.004), ('context', 0.004), ('experiment', 0.003), ('training_set', 0.003), ('frame', 0.003)]\n",
      "\n",
      "Topic #5:\n",
      "[('neuron', 0.021), ('circuit', 0.014), ('chip', 0.011), ('current', 0.01), ('cell', 0.009), ('voltage', 0.008), ('analog', 0.007), ('signal', 0.006), ('synaptic', 0.005), ('channel', 0.005), ('response', 0.005), ('synapse', 0.005), ('neural', 0.004), ('threshold', 0.004), ('synapsis', 0.004), ('frequency', 0.004), ('bit', 0.004), ('pulse', 0.004), ('implementation', 0.003), ('connection', 0.003)]\n",
      "\n",
      "Topic #6:\n",
      "[('state', 0.03), ('control', 0.012), ('action', 0.01), ('step', 0.007), ('task', 0.006), ('policy', 0.006), ('controller', 0.005), ('trajectory', 0.005), ('reinforcement_learning', 0.005), ('optimal', 0.004), ('environment', 0.004), ('dynamic', 0.004), ('robot', 0.004), ('training', 0.003), ('goal', 0.003), ('current', 0.003), ('transition', 0.003), ('adaptive', 0.003), ('reward', 0.003), ('sequence', 0.003)]\n",
      "\n",
      "Topic #7:\n",
      "[('neuron', 0.019), ('signal', 0.009), ('dynamic', 0.009), ('noise', 0.009), ('state', 0.007), ('spike', 0.007), ('equation', 0.007), ('solution', 0.005), ('neural', 0.004), ('rate', 0.004), ('eq', 0.004), ('phase', 0.004), ('rule', 0.004), ('fixed_point', 0.003), ('correlation', 0.003), ('distribution', 0.003), ('matrix', 0.003), ('delay', 0.003), ('constant', 0.003), ('energy', 0.003)]\n",
      "\n",
      "Topic #8:\n",
      "[('image', 0.049), ('object', 0.013), ('feature', 0.011), ('pixel', 0.01), ('face', 0.008), ('filter', 0.006), ('visual', 0.006), ('view', 0.006), ('representation', 0.005), ('surface', 0.004), ('region', 0.004), ('local', 0.004), ('scale', 0.004), ('scene', 0.004), ('ica', 0.004), ('recognition', 0.004), ('position', 0.003), ('shape', 0.003), ('linear', 0.003), ('location', 0.003)]\n",
      "\n",
      "Topic #9:\n",
      "[('cell', 0.017), ('unit', 0.017), ('pattern', 0.016), ('layer', 0.01), ('activity', 0.007), ('connection', 0.006), ('synaptic', 0.005), ('synapsis', 0.004), ('activation', 0.004), ('simulation', 0.004), ('rule', 0.004), ('rat', 0.004), ('kernel', 0.004), ('perturbation', 0.004), ('active', 0.004), ('training', 0.004), ('hidden_unit', 0.003), ('effect', 0.003), ('memory', 0.003), ('region', 0.003)]\n",
      "\n",
      "Topic #10:\n",
      "[('rule', 0.012), ('node', 0.011), ('memory', 0.01), ('pattern', 0.009), ('vector', 0.008), ('unit', 0.008), ('structure', 0.007), ('representation', 0.006), ('sequence', 0.006), ('state', 0.004), ('matrix', 0.004), ('activation', 0.004), ('symbol', 0.004), ('graph', 0.004), ('attractor', 0.004), ('capacity', 0.003), ('similarity', 0.003), ('language', 0.003), ('level', 0.003), ('element', 0.003)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output of topic models as tuples of terms and weights\n",
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt,3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics without Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "['distribution', 'vector', 'training', 'approximation', 'linear', 'estimate', 'probability', 'variable', 'class', 'sample', 'matrix', 'let', 'gaussian', 'equation', 'bound', 'prior', 'optimal', 'noise', 'consider', 'prediction']\n",
      "\n",
      "Topic #2:\n",
      "['stimulus', 'response', 'cell', 'visual', 'neuron', 'motion', 'unit', 'activity', 'map', 'direction', 'pattern', 'cortical', 'spatial', 'orientation', 'receptive_field', 'cortex', 'location', 'et_al', 'signal', 'field']\n",
      "\n",
      "Topic #3:\n",
      "['classifier', 'class', 'classification', 'training', 'feature', 'pattern', 'vector', 'tree', 'probability', 'test', 'expert', 'cluster', 'clustering', 'training_set', 'distance', 'node', 'sample', 'table', 'technique', 'application']\n",
      "\n",
      "Topic #4:\n",
      "['training', 'unit', 'word', 'recognition', 'net', 'layer', 'task', 'trained', 'hidden_unit', 'feature', 'pattern', 'speech', 'architecture', 'representation', 'character', 'sequence', 'context', 'experiment', 'training_set', 'frame']\n",
      "\n",
      "Topic #5:\n",
      "['neuron', 'circuit', 'chip', 'current', 'cell', 'voltage', 'analog', 'signal', 'synaptic', 'channel', 'response', 'synapse', 'neural', 'threshold', 'synapsis', 'frequency', 'bit', 'pulse', 'implementation', 'connection']\n",
      "\n",
      "Topic #6:\n",
      "['state', 'control', 'action', 'step', 'task', 'policy', 'controller', 'trajectory', 'reinforcement_learning', 'optimal', 'environment', 'dynamic', 'robot', 'training', 'goal', 'current', 'transition', 'adaptive', 'reward', 'sequence']\n",
      "\n",
      "Topic #7:\n",
      "['neuron', 'signal', 'dynamic', 'noise', 'state', 'spike', 'equation', 'solution', 'neural', 'rate', 'eq', 'phase', 'rule', 'fixed_point', 'correlation', 'distribution', 'matrix', 'delay', 'constant', 'energy']\n",
      "\n",
      "Topic #8:\n",
      "['image', 'object', 'feature', 'pixel', 'face', 'filter', 'visual', 'view', 'representation', 'surface', 'region', 'local', 'scale', 'scene', 'ica', 'recognition', 'position', 'shape', 'linear', 'location']\n",
      "\n",
      "Topic #9:\n",
      "['cell', 'unit', 'pattern', 'layer', 'activity', 'connection', 'synaptic', 'synapsis', 'activation', 'simulation', 'rule', 'rat', 'kernel', 'perturbation', 'active', 'training', 'hidden_unit', 'effect', 'memory', 'region']\n",
      "\n",
      "Topic #10:\n",
      "['rule', 'node', 'memory', 'pattern', 'vector', 'unit', 'structure', 'representation', 'sequence', 'state', 'matrix', 'activation', 'symbol', 'graph', 'attractor', 'capacity', 'similarity', 'language', 'level', 'element']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view topics as a list of terms without weights, understand context or theme of each topic\n",
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.48502663515630856\n",
      "Avg. Coherence Score (UMass): -1.0976687786641732\n",
      "Model Perplexity: -7.799326326702988\n"
     ]
    }
   ],
   "source": [
    "# use perplexity and coherence scores as measures to evaluate topic model\n",
    "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                      texts=norm_corpus_bigrams, \n",
    "                                                      dictionary=dictionary, coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
    "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                         texts=norm_corpus_bigrams, \n",
    "                                                         dictionary=dictionary, coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
    "\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)\n",
    "\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LDA Models with MALLET\n",
    "# download MALLET framework\n",
    "# !wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract contents from archive\n",
    "# !unzip -q mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['state', 'dynamic', 'control', 'recurrent', 'trajectory', 'memory', 'equation', 'module', 'sequence', 'behavior', 'nonlinear', 'attractor', 'controller', 'field', 'movement', 'architecture', 'mapping', 'feedback', 'motor', 'signal']\n",
      "\n",
      "Topic #2:\n",
      "['image', 'object', 'feature', 'visual', 'map', 'motion', 'location', 'direction', 'pixel', 'region', 'position', 'local', 'field', 'representation', 'view', 'face', 'filter', 'surface', 'distance', 'target']\n",
      "\n",
      "Topic #3:\n",
      "['neuron', 'circuit', 'current', 'chip', 'signal', 'bit', 'analog', 'voltage', 'code', 'channel', 'implementation', 'neural', 'design', 'memory', 'computation', 'processor', 'element', 'noise', 'vector', 'connection']\n",
      "\n",
      "Topic #4:\n",
      "['neuron', 'cell', 'response', 'stimulus', 'activity', 'pattern', 'signal', 'spike', 'frequency', 'synaptic', 'effect', 'neural', 'cortical', 'connection', 'firing', 'et_al', 'brain', 'cortex', 'simulation', 'temporal']\n",
      "\n",
      "Topic #5:\n",
      "['state', 'action', 'step', 'task', 'policy', 'optimal', 'environment', 'search', 'goal', 'reinforcement_learning', 'cost', 'control', 'trial', 'rate', 'strategy', 'current', 'stochastic', 'expected', 'machine', 'robot']\n",
      "\n",
      "Topic #6:\n",
      "['unit', 'training', 'layer', 'pattern', 'net', 'hidden_unit', 'task', 'trained', 'architecture', 'activation', 'training_set', 'generalization', 'hidden_layer', 'back_propagation', 'noise', 'prediction', 'connection', 'backpropagation', 'hidden', 'rate']\n",
      "\n",
      "Topic #7:\n",
      "['distribution', 'gaussian', 'estimate', 'variable', 'prior', 'variance', 'mixture', 'sample', 'density', 'probability', 'noise', 'estimation', 'approximation', 'component', 'bayesian', 'prediction', 'vector', 'linear', 'regression', 'matrix']\n",
      "\n",
      "Topic #8:\n",
      "['training', 'class', 'classification', 'feature', 'classifier', 'word', 'recognition', 'test', 'speech', 'experiment', 'trained', 'vector', 'character', 'pattern', 'training_set', 'table', 'accuracy', 'database', 'hmm', 'sample']\n",
      "\n",
      "Topic #9:\n",
      "['vector', 'linear', 'bound', 'class', 'equation', 'solution', 'convergence', 'theory', 'size', 'theorem', 'optimal', 'matrix', 'defined', 'approximation', 'xi', 'probability', 'constant', 'property', 'distribution', 'finite']\n",
      "\n",
      "Topic #10:\n",
      "['node', 'rule', 'representation', 'structure', 'sequence', 'tree', 'level', 'graph', 'cluster', 'language', 'symbol', 'string', 'clustering', 'similarity', 'connectionist', 'represented', 'part', 'represent', 'context', 'pattern']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MALLET_PATH = 'mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus,\n",
    "                                              num_topics=TOTAL_TOPICS, id2word=dictionary, \n",
    "                                              iterations=500, workers=16)\n",
    "\n",
    "topics=[[(term, round(wt,3)) \n",
    "         for term, wt in lda_mallet.show_topic(n, topn=20)]\n",
    "             for n in range(0, TOTAL_TOPICS)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.512416855365222\n",
      "Avg. Coherence Score (UMass): -1.0409440698946946\n",
      "Model Perplexity: -8.53533\n"
     ]
    }
   ],
   "source": [
    "# evaluate model using perplexity and coherence metrics\n",
    "cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                             texts=norm_corpus_bigrams, \n",
    "                                                             dictionary=dictionary, \n",
    "                                                             coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, \n",
    "                                                                corpus=bow_corpus, \n",
    "                                                                texts=norm_corpus_bigrams, \n",
    "                                                                dictionary=dictionary, \n",
    "                                                                coherence='u_mass')\n",
    "\n",
    "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "# from STDOUT: <500> LL/token: -8.53533\n",
    "perplexity = -8.53533\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [1:21:43<00:00, 169.09s/it]\n"
     ]
    }
   ],
   "source": [
    "## LDA Tuning: Finding the Optimal Number of Topics\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "# iterate and build several models with differing number of topics\n",
    "# select one that has highest coherence score\n",
    "def topic_model_coherence_generator(corpus, texts, dictionary, start_topic_count=2, \n",
    "                                    end_topic_count=10, step=1, cpus=1):\n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, \n",
    "                                                            corpus=corpus, num_topics=topic_nums, \n",
    "                                                            id2word=dictionary, iterations=500, \n",
    "                                                            workers=cpus)\n",
    "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, \n",
    "                                                                     corpus=corpus, texts=texts, \n",
    "                                                                     dictionary=dictionary, \n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(mallet_lda_model)\n",
    "    \n",
    "    return models, coherence_scores\n",
    "\n",
    "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, \n",
    "                                                               texts=norm_corpus_bigrams, \n",
    "                                                               dictionary=dictionary, \n",
    "                                                               start_topic_count=2, \n",
    "                                                               end_topic_count=30, step=1, \n",
    "                                                               cpus=16)\n",
    "\n",
    "# save model for later use\n",
    "filename = 'lda_models.sav'\n",
    "pickle.dump(lda_models, open(filename, 'wb'))\n",
    "\n",
    "# save coherence scores\n",
    "np.savetxt(\"coherence_scores.csv\", a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>0.5587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.5430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.5426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.5401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>0.5393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>0.5387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.5344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.5312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.5306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Topics  Coherence Score\n",
       "28                30           0.5587\n",
       "19                21           0.5430\n",
       "24                26           0.5426\n",
       "17                19           0.5416\n",
       "21                23           0.5401\n",
       "25                27           0.5393\n",
       "27                29           0.5387\n",
       "16                18           0.5344\n",
       "22                24           0.5312\n",
       "20                22           0.5306"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1), \n",
    "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
    "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAy8AAAFzCAYAAAA3/jaVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4VGXax/HvMz2NsqIUKbKK62sDG+BaEFRERV1XbKsrKGJFERZYUEARQUAFCygK9oYNFZW1gai4IiBiAQuIusoqiC6QMiUz87x/zBBykgCTkMmk/D7XNRc593POmXs4BnPnacZai4iIiIiISG3nynQCIiIiIiIiqVDxIiIiIiIidYKKFxERERERqRNUvIiIiIiISJ2g4kVEREREROoET6YTSKfNmzdrKTURERERkTqocePGpmxMPS8iIiIiIlInqHgREREREZE6QcWL1CqrV6/OdApSA/ScGwY954ZBz7lh0HNuGOrCc1bxIiIiIiIidYKKFxERERERqRNUvIiIiIiISJ2g4kVEREREROoEFS8iIiIiIlInqHgREREREZE6QcWLiIiIiIjUCSpeRERERESkTlDxIiIiIiIidYKKFxERERERqRNUvIiIiIiINGSFhZnOIGUqXkREREREGijP66+Td+iheN5+O9OppETFi4iIiIhIA2TWrydr4EBc69eT06cPbe64A0KhTKe1QypeREREREQaGmvJuvpqXBs3loT2eO45XF99lcGkdk7Fi4iIiIhIA+O7/368ZYaK/XfAAOKdOmUoo9SoeBERERERaUBcK1cSuPFGRyx65JH83K9fZhKqBBUvIiIiIiINRShE9oABmHC4JGQbNaLo/vvB7c5gYqlR8SIiIiIi0kAEbrwR96pVjlhwyhRs27YZyqhyVLyIiIiIiDQAnrfewn///Y5Y5NxzKe7TJ0MZVZ6KFxERERGRes78+itZV1/tiMXbtSN4220ZyqhqVLyIiIiIiNRn1ib2c9mwYVvI7abogQegUaMMJlZ5Kl5EREREROox34MP4n3jDUcsPGwYsS5dMpRR1al4ERERERGpp1xffklg1ChHLNq5M+GhQzOU0a6pseLFGNPLGPO1MWaNMWZEBe39jDG/GmNWJF+XlmqLlYrPLRVvb4z5KHnPZ4wxvpr6PCIiIiIitVo4TPall2JCoZKQzctLDBfzeDKYWNXVSPFijHED04GTgf2B840x+1dw6jPW2k7J16xS8WCp+Oml4pOAqdbafYD/Af3T9RlEREREROqSwM0341650hEL3n47dq+9MpNQNaipnpfOwBpr7VprbQSYDZyxKzc0xhigB/B8MvQo8JddylJEREREpB7wLFiAf/p0RyzSpw/F55yToYyqR00VL3sCP5Y6/ikZK+ssY8xnxpjnjTFtSsUDxphlxpjFxpitBcpuwCZrbXQn9xQRERERaTDMb7+RdeWVjli8TRuCt98OxmQoq+pRmwa7vQI8ba0NG2MuJ9GT0iPZ1s5au84Y80dggTHmc2BzZW6+evXq6s1W0kbPqmHQc24Y9JwbBj3nhkHPuY6wlr2HDcO1fv22kMvFN6NHU/Drr/Drrzu8PNPPuUOHDjtsr6niZR1QuieldTJWwlr7W6nDWcDkUm3rkn+uNcYsBA4BXgCaGGM8yd6XcvcsbWd/EVI7rF69Ws+qAdBzbhj0nBsGPeeGQc+57vA9/DBZ777riIWHDKFlCsPF6sJzrqlhY0uBDsnVwXzAecDc0icYY1qWOjwd+DIZb2qM8Se/bgYcBayy1lrgHaBP8pq+wMtp/RQiIiIiIrWU65tvCFx/vSMWPfxwwv/8Z4Yyqn410vNirY0aYwYCbwBu4CFr7UpjzM3AMmvtXOBaY8zpQBT4HeiXvPz/gPuNMXESxdZEa+2qZNs/gdnGmFuAT4AHa+LziIiIiIjUKluXRQ4GS0I2N5fgzJng9WYwsepVY3NerLXzgHllYmNKfT0SGFnBdf8GDtrOPdeSWMlMRERERKTBCowfj/uzzxyx4KRJxNu3z1BG6VFjm1SKiIiIiEj1c7/7Lv6773bEImeeSfHf/pahjNJHxYuIiIiISB1lfv+d7CuucMTirVsTnDq1zi+LXBEVLyIiIiIidZG1ZF17La6ff94WMoaiGTOgSZMMJpY+Kl5EREREROog7+OP4331VUcsPHgwsaOPzlBG6afiRURERGqvWCzTGYjUSq41a8gaMcIRix5yCOEysfpGxYuIiIjUOq4vviD3kENo1KYN/rFjVcTUV9bieestfA88gPuDD6DUMr+yA5EIWZdeiikqKgnZ7GyCs2aBz5fBxNKvxpZKFhEREUlJOEz2RRfh/u47AAJTp+L+8kuKHnwQcnIynJxUm0iErGuuwffMMyUh6/US69SJWJcuRLt2Jda1K7ZZswwmWTv5b70Vz4oVjlhw4kTie++doYxqjooXERGResb89hu+WbNwr1pF5JxziJ56aqZTqhT/vffiXrvWEfO+/jo5p55K0TPPYJs3z1BmUm3y88nu2xfvggWOsCkuxrN0KZ6lS/FPmwZAbO+9iXXtSrRLF2JHHkl8n33q5SpaqXK//z7+O+90xIpPO43iv/89QxnVLBUvIiIi9YT53//wTZuG//77MQUFAHjmzqXwpZeIdeuW4exSY9atw3/77RW2eVasIPeEEyh87jni++1Xw5lJdTHr15Nzzjm4P/00pfPd336L+9tv8T35JADx3XZz9MzEOnYEvz+dKdcemzaRfcUVGGtLQvFWrQjefXeDKehUvIiIiNR1mzbhnz4d/4wZmPx8R5OxlqwhQyj44AMIBDKUYOoCY8ZgCgu32+768Udye/ak8IkniB17bA1mVkVFRYkfKrOyMp1JreBas4acs87C9cMPjnh8zz3B4ykXr/Aev/2Ga948vPPmAWD9fmKHHpooZrp0IdalC7Zp07Tkn1HWknXddbjWrdsWMoai++6rn593OzRhX0REpK7avBn/pEk0OvhgArfdVq5w2cr97bf477ijhpOrPPeiRfheeMERC44bR/GJJzpiZssWcs46C2+puRK1TjBIYPRoGu29N43atycwYgRs5/k0FO5ly8g56aRyBUr0kEMoWLiQ/E8/ZcuXX1L4yCOEr7iCaKdOWLd7p/c14TCeDz8kMHUqOeedR6P27cnt2pXAddfhffppzPffQ6meirrK+9RT+F56yRGLXHttnelVrS7G1oOHuT2bN2+uvx+unlq9ejUdOnTIdBqSZnrODYOecxrl5+O//35806bh2rSpwlOs240ptUKX9XopWLSI+J/+VK2pVNtzjkbJPfZY3KtWlYRiBx9MwTvvgLUEhg3D//DD5S4LXX894WHDatWQGfeSJWRddRXuNWsc8XirVgQnTybau3eGMqu6XX3OntdfJ/viizFlVhMrPvFEih5+GHJzK76woAD3xx/jWbwY90cf4Vm6dLtF+o7Emzen+PTTCY8cif3DH6ryETLKtXYtucceWzIcFCDWsSMFb71VrauL1bZ/txs3blzuG1s9LyIiInVFQQH+qVPJO/hgArfcUmHhEv/DHwiOHUv+F18QLzWx3RQXk3XddRCP12TGKfM9+KCjcAEITp4Mbjd4PISmTCE4dmy56wITJpA1cCAUF9dUqtuX7G3J6dWrXOEC4Prvf8m58EKy//Y3zE8/ZSDBzPA+9ljiM5cpXCIXXEDRU09tv3AByM0l1q0b4X/+k6I5c9jy/ffkv/cewcmTiZx1VmK4WQpc69fjnzmT3M6d8b7wQt3qidmyhawBAxyFi83KomjmzHq/LHJFVLyIiIjUdoWF+O6+m7yOHQmMHYvrf/8rd0q8SRNCY8aQ/+mnRAYNwrZsSXDSJMc5ng8/xPvEEzWVdcrMxo0EJkxwxCLnnkusa9dSJxkigwZR9NBD2DI/sPmefJLss8+GzZtrIt0KuZcuJffYY/Hfcw9mJwWid9488rp2xXffffV7/xpr8U+cSPa115b7OwkNHUpw2jTweit3T7eb+MEHE7nsMoIPPkj+ypVs+fxzimbNInzppcQOPBC7g14418aNZPfvT/Z559X+AtJavM8+S94RR+D5+GNHU/DWW4nvu2+GEsssFS8iIiK1VVERvmnTyOvUiawxY3D99lu5U2zjxoSuv578zz4jPGQI5OWVtEXPOIPik05ynB8YMwbz669pT70yAjffjClVeNi8PEIV9LIAFP/1rxS+/DLxMhOUvQsXknvyyTX/A2koRGDMGHJOOgn36tXlmsP9+hG67jqsx7lGkikoIGvkSHKOPx5Xmf066oVolKxBgwhMnOgIW5eL4JQphEeNqrahfrZNG4r79CF0++0ULFrElu+/p/CFFwgNG0b0mGOw2dnlrvG+8QZ5Rx6Jb9asWtkb6Vq1ipxTTyX7sstwrV/vaCs+5RSK+/bNUGaZp+JFRESktgmF8N13H3mHHELWqFG4Kig2bKNGhP75T7Z8+inh4cOhUaPy9zGG4OTJjh/eXJs2EbjhhnRmXynu5cvxPv64IxYaPhzbosV2r4kdeSSFb75JbK+9nPdatYrcE0/E9dln6Ui1HPeyZYnelrvvLtezEG/dmsIXXyR0552Eb7qJgnffJdq5c7l7eFasILdHDwIjR9afCf2FhWRfcAG+xx5zhG0gQNHjjxO55JL0vn/jxkSPP57wDTdQ+MorbPn+e0KjRpXrsTP5+WQNHUrOqafi+uab9OaUqi1bCNxwA7nHHIPn3/8u1xz7v/8jeM89tWqOV01T8SIiIlJbhMP4Zs5MFC0jR5b7jSskeyWGDmXLZ58RHjkSmjTZ4S1tu3aERo50xHzPPovnnXeqNfUqiccJDBvm2LMi1qEDkcsv3/mlHTpQ+NZbRA8/3BF3/fwzuaecguett6o93RKhEIEbbySnZ0/cFfzQG+nbl/x//5to9+7b8j3gAApff53glCnYMoWmicfx33cfeV274nnttfTlXQPMxo3knHEG3jfecMTjTZtS+PLLmdkw1ecjPHQoBYsWES09FDHJ8+GH5B59dGJ/oUzNnbIW7/PPk9e5M/7p0x2LbQBYn4/QsGEUzJ+P3W23zORYS6h4ERERybRIBN9DD5F36KFkDRuG6+efy51ic3IIDRlC/qefJobc7KRocdz+iiuIHXigIxYYMgTKTKCuad6nnio3lj80aVLKk5Dt7rtT+MorFJ92miNuCgrIPu88vI88Uk2ZbuP++GNyu3XDf9ddFfe2zJlD8K67Ku4Jc7mIXHIJ+UuWEPnrX8s3r1tHzgUXkH3BBbV/PkYFzPffk3PSSXiWLXPE423aUPjGG8S6dMlQZsk89t2XwnnzCN5+O7bMIgEmEiFwyy3kHncc7k8+qdG8XF99Rc5pp5F96aW4fvmlXHvxCSdQsHgx4RtugAqGwDU0Kl5EREQypbgY76OPJoqWIUMcm89tZbOzCQ8alChaxoyp2jKvXi/Bu+5yTGR2f/ddZvd+2bSJQJl5LcW9exPt0aNy98nKouiRRwhfdZUjbGIxsq+7Dv/YsdUzpyEUwj92LDknnoj766/LNUcuuoj8Dz5IKX/bogXBhx6i8LnniLdtW67d+9prdW5Cv2vFCnJ79sT97beOeOzAAyl4883aM7nc5SJy6aXkL15cbj4YgHvlSnKOP57AqFGwg81Sq0V+PoHRo8k9+mg8ixaVa463bk3hE09Q9NxzxP/4x/TmUoeoeBEREalpxcV4n3iCvMMPJ3vQIFwV/JbdBgKEBw4k/9NPCY0di23WbJfeMnbYYUQuvdQR8995J64vv9yl+1ZVYOJEx1weGwgQHD++ajdzuwlNmEBw0qRyK00Fpk4la8AACIernKt7+XJyjzuOwNSp5Xtb9tyTwhdeIHj33dC4caXuGz3xRPIXL05M6C+zGWNdmtDvWbCA3N69cW3Y4IhHu3WjYN48bMuWGcps+2zr1hTNnk3Rgw8SL/O9ZeJx/NOmkffnP+N+9900vLnFO2dOYojYPfdgolFns89HaOhQ8pcsSewJ1IDnt1TIWltvX5s2bbJbX0C515133lnSfuedd1Z4ztZX6Xt17Nhxu+f17du35LyFCxfu8J4LFy4sObdv377bPa9jx452Z59Fn0mfqS59pqVLl9a7z1Qfn5M+Uxo+088/26Lbb7exNm12eM9p3brZzV9/Xf2f6T//sbGWLe2yHdyvsp+p9Pdzqs/pruHDa/w5LT7oILt57drK/be3fv0O7zm9Sxe76YcfqvU5DQBrk6/qfE7p+n4qnDHDxj0ee+gOzqtL/0bYUq90fKZ+Z5yx3fMOBRvp0cNuWbYsY//ubf1+zvRz2vqq6Od79byIiIjUALNhA3kdO5I1dCiuH3/c4bnRM8/Eltpgsto0alRu75cal/ytc03zfP45OT17Yr7/PqXz3cuXk9ut2w7PKT7//Er3tuxMtGvXchP6ayvfnXeSfcUV5XoO6rJ469bpuXFBAYEbb8Qzd+7233uvvSh64QXi++yTnhzqCWPr0g6jlbR58+b6++HqqdWrV9OhQ4dMpyFppufcMOg5g/n9d3wzZuC//37HPialWa+XyEUXER48GJuuH5wcb2jJPv98vK+/vi3UuDH5S5ZUqWCq7HP2vPQSOf36OWKFjz9OtMyk+11lvv+enHPOKbcaWLxZM4pmzyZWZpWyEuEw/smT8d95Z7kVnyCxK3xw/PhKLZhQWeaXXwiMHInvxRcrbC/u3TsxRC7F3eWrg+M5x2IERozAP3Om4xxrDKHx44mUmX9UpxQUEBg3Dt8DDzhWwduq+JRTCN5xR+pD4azF8/LLZF1/Pa7//rd8s9dL+JprCP/jH5CTs6vZ77La9u9248aNy42ZU8+LiIhINTM//0xg1CjyDjqIwOTJFRYu1ucjfMkl5H/8MaE77qiZwgUSe7/cdhu21A9KZvPmmtn7pbCQrDLvU9y9e2JcfzWze+1FwZtvEj3qKEfctXEjOaedhueVV8pd41qxgtzu3QnccUe5wiXeqhWFzz5LcPr0tBYuQGJC/8MPU/jss8TbtCnX7n31VfK6dME3Y0bNT+gPhci++OLyhYvPR/Chh+p24QKQm0to0qTE6mj77Veu2TtvHnlduuB95JGdLgTh+uYbss88k5x+/SosXIqPO46Cf/+b8JgxtaJwqStUvIiIiFQT8/33BAYPJq9jR/zTpmEqWK3I5uQQvuYa8j/7jNCUKdgKVptKN9umDaHrr3fEfM8/j2f+/LS+r3/qVMeKatbjSSyNnK4JyU2aUDhnDpFzznGETTBI9kUX4bv33kQgHMZ/yy3kHn887lWryt0mcsEFiX1bevZMT57bEe3Zk/zFiwlfe23FE/pHjCDnhBNwffppzSS0aRM5Z56Jt8zQJ9uoEYUvvEDxmWfWTB41INa5MwXvvktoxAis1+toM1u2kH3ddeScdhquMqurAVBYiH/sWHKPOgrvwoXlmuN77knho49S9OKLxGtRL0ddoWFjUqvUtu5KSQ8954ahIT1n15df4p86Fe8LL1Q41Agg3qQJkcsvJ3L55VVb7ri6RaPk9uiBu9Ru9PF27cj/8MNK7SWR6nN2ffcduV26YCKRklj4mmsIjRtXubyrwlr848cTuP32ck2RCy/EvXx5hUVLvGVLgnfdVeNFS0Vcn39O1nXXldsXB8C6XMQ6dcLuvjt2jz2I7757hV/bpk3BVbXfW//w/vscMGwY7q++csTjrVollnw+4IAq3bcucH35JVnXXotn6dJybTYQIDRiBJGrrwaPB8/cuWTdcEPFKwh6PIQHDiQ8dCiU2Wemtqht/25XNGxMxYvUKrXtm0bSQ8+5YWgIz9m9fDn+KVPwvvrqds+JN29OeOBAIv36QV5ezSWXAvcnn5Bz/PGO5X9DgwcTvvHGlO+R6nPOPu88xzybePPm5C9dWvFmjmnifewxsgYP3m6BWVrk/PMJ3npr2oeIVUoshu+hhwjcfDMmP7/Sl1uPB9usGXb33Z0Fzh57JOJbi5099kjs4p7scXCtXIn/zDPxlVkKObbffhQ+/3zNDXnMpFgM38yZBMaNq7BHNXbwwcSbNcO7YEGFl0ePPZbgbbcR/9Of0p3pLqlt/25XVLx4MpGIiIhInWUt7kWLEkXLO+9s97R427aEBw0icsEFEAjUYIKpix1yCJHLLsM/Y0ZJzH/PPRT36VOtv0n3vPmmo3ABCI0dW6OFC0DxRRdhW7cmu2/f7f7wH2/RItHbUsEGhhnndhMZMIDi3r3JGjEC78svV+pyE41ifvkFfvkF985PJ/6HP2D32APXunXl/r6iRx5J4dNP167iLp3cbiJXXEHxKaeQNWQI3rffdjZ/9lmFf6fxli0JTZhA8V/+ov1aqonmvIiIiKTCWjxvvEFOr17knnbadguX2J/+RNGMGeR//DGR/v1rbeGyVeiGG4i3alVybKJRsgYPrp5d6QHCYQIjRjhC0a5dKT733Oq5fyVFe/SgYN48x2feKnLeeeQvXlw7C5dSbMuWFD36KIWzZxNL487rrt9/x/3VV+UKl+LTT6fwxRcbTuFSim3blqLnnqPo/vuJ72D4p/V4CF97LflLliTmAqlwqTbqeREREdmRWAzvyy/jnzIF9xdfbPe0aKdOhIcMSaycVcV5BRmRl0dw8mRyLrywJORZsgTfI48QueSSXb69/957ca9dW3JsjUnsNZPBH+biBx1Ewdtvk33ZZXgWLSLerh3BiROJnnxyxnKqimivXhScdBKu777DrF+P+fVXXL/+itmwAbNxI64NGzDJY9fGjZgtW3b5PcMDBhCaOBHcqfTd1FPGUHzuuUR79Egsaf38847m6DHHJIaIVbBamew6FS8iIiIViUTwPvMM/jvvxF3RikJJ0T//mfDQoUS7d6+zv12N9u5N8Smn4J03ryQWuOkmik85BduiRZXva9atw3/bbY5Y5OKLiXfsWOV7VhfbqhWFr76K2bgxMb+jjj47jCH+xz9CKj0wwWCiwNm4MVHgbNiQKHaSL1ey6DEbNmB+/92xz4l1uQiNGUNk0KC6+3dVzezuuxOcNYvis8/Gf/fdEI8T6d+f4rPO0t9RGql4ERER2aqoCPfSpXjefx/f7NkVrhi0VXHPnoQHDyZ25JE1mGD6BCdPxvPee5iCAiCxHGxg5EiCDz9c5XsGxozBFBWVHMebNiU8atQu51qdbLNmmU6h5mRlYdu2JZbK8tzRKOa330oKmbXW0u6449KeYl0UPemkWj/UsD5R8SIiIg1XMIh7yRI8ixbhWbQI97JlmOLi7Z5ujaH4jDMIDx5cK3oPqpNt3ZrQDTeQNXJkScz34osUn39+lZYKdi9ahO+FFxyx8OjRtWOZaNk5jwfbvDm2eXMAIqtXZzghkQQVLyIi0nCEQiU9KyXFSql9R7bHejwUn3su4euuq9ebykUuuwzvM8/gWbGiJJb1j3+Qv3hx5XYAj0bJGj7cEYodfDCRvn2rK1URaaBqrHgxxvQC7gLcwCxr7cQy7f2A24CtW+9Os9bOMsZ0Au4DGgExYLy19pnkNY8A3YDNyWv6WWtXICIiAhAO4162bFuxsnQpJhxO+XIbCBD5+98JX3MNNpWhNnWd203wzjvJ7dGjZO8X148/Epg0idDNN6d8G9+DD5bb9DE4eXLDnuQtItWiRooXY4wbmA6cCPwELDXGzLXWlt3O9hlr7cAysSLgImvtamNMK+BjY8wb1tpNyfZh1trnERERCYdxf/xxYhjY++8nipVQqFK3iLVvT+zoo4kefTTRE05ITOZuQOKdOhG54gr8995bEvNNn07k7LOJH3TQTq83GzcSmDDBEYucey6xrl2rPVcRaXhqquelM7DGWrsWwBgzGzgDKFu8lGOt/abU1/81xmwAdgc2bf8qERFpECIR3MuXbytWlizBBIOVukW8XbtEoXLMMUSPOgrbpk2akq07Qtdfj3fu3JIFC0wsRtbgwRS+8cZOe08CN9+M2by55Njm5SU2pBQRqQY1VbzsCfxY6vgnoEsF551ljDkW+AYYbK0tfQ3GmM6ADyi9ZuV4Y8wYYD4wwlqb+ngAERGpGdZCJAKhUGKOSThc8ifhcGIoV6nY1mMikW1tZc5xff01no8+cqxmlYp469aJQuWYY4gefXTDGA5WWbm5BG+7jZzzzy8JeZYtw/fQQ0QGDNjuZe7ly/E+/rgjFho+fJeWWxYRKc3YUmt4p+1NjOkD9LLWXpo8/jvQpfQQMWPMbkCBtTZsjLkcONda26NUe0tgIdDXWru4VOwXEgXNA8C31tqSQbmbN28u+XCrtUqGiEiNaDZnDs2fegrP5s24iosxkQiuHazglW6RPfZgy+GHk3/YYeQfdhiRPffMWC51zd7Dh9P0nXdKjmM5OXzx3HMU7757+ZPjcfa75BJyV64sCQXbtWPV009jvd6aSFdE6oEOpRZFady4cbkNc2qq52UdULofvjXbJuYDYK39rdThLGDy1gNjTCPgNeCGrYVL8pqfk1+GjTEPA0O3l0CHerw6TH2yevVqPasGQM+5/vLfdhuBW2/NaA7xVq0Sw8COPproscdi27XDawx/ALRIb+WY6dOxXbpg8vMBcBcWsv+MGRQ99ljJOVu/n71PPEF2qcIFID51Kvvsv3+N5izpoX+3G4a68JxrqnhZCnQwxrQnUbScB/yt9AnGmJalipHTgS+TcR/wIvBY2Yn5W68xxhjgL8AX6f0YIiJSIWvxT5xIYNKkGn/reIsWJUPAYsccQ7x9e+1uXU1sq1aERo92LHvsnTsXz7/+RfTkk7eduGkTgTLzWop79ybaowciItWpRooXa23UGDMQeIPEUskPWWtXGmNuBpZZa+cC1xpjTgeiwO9Av+Tl5wDHArsll1OGbUsiP2mM2R0wwArgipr4PCIiUoq1+MePJ3D77Ts+zesFvx/r8yX+9PvB7wefL/H11j+TL7ujNp8P26QJsa5die+9t4qVNIr074939mw8y5eXxLKGDSP/mGMgNxeAwMSJuH79taTdBgIEx4+v8VxFpP6rsX1erLXzgHllYmNKfT0SGFnBdU8AT2znnvqVjohIJlmL/+abCUyd6gzn5vLNpEm06N27pEDB5cpQkrJLtu790r07JhYDwPXTTwRuvZWJZV61AAAgAElEQVTQ+PEE1qzBN3Om45LwoEHYdu0yka2I1HP6P4mIiFSNtQTGjClfuOTlUThnDvmdO0PjxhAIqHCp4+IHH0zkyisdMd999+FasYK2d9xRUtQAxNu2JXzddTWdoog0EPq/iYiIVJ61BK6/Hv899zjDjRpR+NJLxDp3zlBiki6hkSOJt25dcmzicXLOPptGy5Y5zguOHw9ZWTWdnog0ECpeRESkcqwlMHw4/vvuc4TjTZpQMHcuscMOy1BiklY5OQTLzGsqPc8FoLh7d6K9e9dkViLSwKh4ERGR1MXjBP7xD/xl5jjEmzal8OWXiXfqlKHEpCZEe/Wi+IwzKmyzHg+hSZO0eIKIpJWKFxERSU08TtZ11+F/6CFneLfdKJw7l3jHjhlKTGpScOJEbKNG5eKRK68kvu++GchIRBqSGlttTEREtqOoCNePP5a8zLp1xNu2pfj006FJk0xnlxCLkXXNNfieesoRjjdrlihctBFhg2FbtiQ0ZgxZQ7ftCx1v3pzQsGEZzEpEGgoVLyIi6bZpk6M4cf3nP4kiZevxxo0VXha/6SbCI0YQufhi8HprOOlSYjGyrroK3zPPOMLxPfZIFC777ZehxCRTIhdfjHv5cnxPPUU0N5fQAw9ABb0xIiLVTcWLiMiusBazcWOiGEkWJVuLk5KelC1bqnRr1++/kzV8OL6ZMwmNHZvY0bym5xNEo2RdeSW+555zhOMtWiQKFw0TapjcboLTpxMaOZJvN2zgj1qkQURqiIoXEZFKcH/4Id7nn8f1/feJIuWnnzDBYHrfc/Vqcv72N6LHHEPwlltqbm5JcTFZl12G78UXHeF4q1YUvvJKYmd7abiMwbZpQywUynQmItKAqHgREUmR+733yDnzTMeGfNXBut3YVq2It2lDvG1bbG4uvtmzMQUFjvM8779P7nHHUXz++YRGjcK2alWteTgUF5Pdvz/euXMd4Xjr1onCpX379L23iIjIdqh4ERFJxZYtZF91VZUKF+v3JwqTNm2wyT+3FirxNm2wLVuCx/nPcXjYMAITJuB9/HFMPF4SN9bie+opvC+9RPiaawhfey3k5Ozyx3OIRMi++GK8r73mCMfbtKHglVewe+1Vve8nIiKSIhUvIiIpyBo1CtdPP1XYZvPythUkW3tPSh3b3XcHV+VWprfNmxO86y7Cl11GYNQovO+842g3RUUEJk3C9+ijhEaNovj888HtrvLnKxEOk923L97XX3eE4+3aJQqXtm13/T1ERESqSMWLiMhOeN56C99jjzlikYsuIty/P/F27aBx47RNpI8fcABFc+bgefttAqNH4/7qK0e765dfyB44kNj99xO85RZi3bpV/c1CIbIvugjvm286wrH27Sl85RVs69ZVv7eIiEg10CaVIiI7smkTWdde6wjF9t2X4KRJiYnzTZqkfwUwY4ieeCIFixYRnDKFeLNm5U5xf/45uWecQfZ55+H65pvKv0cwSPYFF5QvXPbem8LXXlPhIiIitYKKFxGRHcgaPhzXzz+XHFuXi+B990FWVs0n4/EQueQS8pcvJzR4MNbvL3eK9/XXyT3ySALDhmF++y21+xYVkX3++Xjnz3eEY/vumyhc0rkwgIiISCWoeBER2Q7Pq6/ie/ZZRyw8eDCxTO9p0agR4RtvJH/JEiJ9+pRrNrEY/pkzyTvkEHz33APh8PbvVVhIzjnn4F240BGO7bdfYqhYixbVnLyIiEjVqXgREamA+e03sgYPdsRi++9PePjwDGVUnm3XjuCsWRS89RbRzp3LtZstW8gaPZq8zp3xvPQSWOs8IT+fnD598Cxa5AjH9t8/Ubg0b57O9EVERCpNxYuISAUC//gHrl9/LTm2Hg9FM2ZABUO1Mi12xBEUvvEGhY88klhAoAzXDz+Q068fOb164V62LBHcsoWcs8/G8+GHznsdeGCicNl995pIXUREpFJUvIiIlOGdMwffSy85YuFhw4gffHCGMkqBMUT/8hfylywhOG4ctlGjcqd4PvqI3BNOIKt/f3LOOgvP4sWO9ljHjonCZbfdaiprERGRSlHxIiJSilm/nsA//uGIRTt1IjxkSIYyqiS/n8g115D/ySeEBwzAVrD3i++FF/AsXeqIRQ85hIKXX8Y2bVpTmYqIiFSaihcRka2sJWvQIFz/+9+2kM+XWF3M681gYpVnd9uN0G23UfDhhxT36rXDc6OHH07hiy8mln0WERGpxVS8iIgkeZ9+utzO8qEbbiD+f/+XoYx2XXzffSmaPZuCl18mduCB5dqjXbpQOGeOChcREakTVLyI1HLmf//D++KLZA0cSO5hh5HTvTued97JdFr1jlm3jqwRIxyxaOfORAYOzFBG1SvWrRsF775L0bRpxNu2BSDyl79Q+PzzUMH8GBERkdrIk+kERKSMWAz3ihV43n4bz/z5uJctw8TjjlM8Z55J+JprCI0eDT5fhhKtR6wl65prMFu2bAtlZRG8916oYM5IneV2U3zhhRRfeCEUFkJOTqYzEhERqRQVLyK1gFm/Hs/8+XgWLMCzYAGu33/f6TX+e+7B/f77BGfNIr7PPjWQ5a5zrV6NZ948muTkwN57g6t2dP56H30U74IFjlhozJg68/daJSpcRESkDlLxIpIJkQjuJUvwzJ+P9+23cX/+eZVu41mxgtxu3QhOmkTxBReAMdWcaDUpKsJ/223477kHE42yD1A8fz5FDzwAeXkZTc388ANZo0Y5YtGjjiJy+eUZykhERES2R8WLSA0xP/yAd/78xHCw997DFBSkfG1s//2JHn88sf32IzBhAq5167bdt7CQ7IEDicyfT3Dq1Fo38drz9ttk/eMfuH74wRH3/utf5PbsSeHTT2P32iszycXjZF99teNZ2JwciqZPrzW9QiIiIrKNiheRdCkqwvPBB4nhYPPn4169OuVLbePGFHfvTvT444n26IHdc8+Stugpp5B17bV4X3nFcY3vxRfxLF1K0axZxLp2rbaPUVXml18IXH89vjlztnuO+8svye3Rg6JHHyV2zDE1mF2Cb+ZMPIsWOWKhceMyV0yJiIjIDql4Eaku1uL65puSifaeDz7AhMOpXWoMsUMPTRQrxx9P7LDDwFPxt6dt2pSixx7D+9hjZI0YgQkGS9pcP/1EzimnEB4+nPDQodu9R1rF4/gefpjA2LGOCfBbWZfLsQCB6/ffyTnzTEKTJhHp37/G0nStWUPgppscseLu3YlcfHGN5SAiIiKVo+JFpDoUFJBz3nnlfou/I/E99iDaowfRE04g2r07drfdUn8/Yyju25fYkUeS3b+/Y86MiccJTJyI5913Kbr/fmxyWdya4PriC7IGDy63ezskipbIgAGEhwwhevXV/OHtt7flHI0mhpatXElo0qT0bwgZi5F11VWOws82akTwnntq77whERER0T4vItUhMHHiTgsX6/EQPeooQjfeSP5775H/1VcEZ8yguE+fyhUupcT33ZeCt98mfNVV5do8H35I3tFH43nppSrdu1IKCwnceCO53bpVWLjEOnakcP58QpMmYZs3Z+2ECYTKTJIH8D/0EDlnnon57be0puubPh3PkiWOWPDWW7GtW6f1fUVERGTXqHgR2UWutWvx3X9/hW3xNm0IX3IJhU88wZa1ayl87TXCgwcTP/jg6psQ7vcTmjCBwuefJ7777o4ms2ULOf36kTVwYGJfjzTwvPkmeUceif+uuzCxmKPN5uQQnDCBgvnziR1ySKnEDOGhQyl84glsmSV7PYsWkdujB65Vq9KSr+urrwiMH++IFZ90EsV/+1ta3k9ERESqT0o/PRljuhtj2ie/bmmMedQY87AxpkV60xOp/QJjxmCKi0uO4y1aELz1VvKXLiX/s88ITZlCtHfvtO9iHj3hBAo++IDiE04o1+Z74glyu3XDtWJFtb2f+flnsvr1I+ecc3D95z/l2otPPZX8jz4ictVV2517E+3dm4I33yzZ8X0r1w8/kNuzJ57XXqu2fBNvGCXryisdc5HiTZoQvOsuDRcTERGpA1L91e+9wNZfqd4BeIE48EA6khKpK9zvv4/31VcdsdC4cUSuvJJ4hw41/gOx3WMPip59luCECVifz9HmXrOG3BNPxHfPPVBqwnylxWL4Zs4kr0sXfBUMSYvvuSeFTzxB0ZNPpjQMK37AARQsWED0z392xE1BAdkXXoj/jjvA2qrnW4p/6lQ8n3ziiIVuvx3bQr+HERERqQtSLV72tNb+xxjjAU4CLgOuBP6848u2Mcb0MsZ8bYxZY4wZUUF7P2PMr8aYFcnXpaXa+hpjVidffUvFDzPGfJ68593G6FenUoNiMbJuuMERih5+OMV9+mQooSSXi8hVV1Hw1lvEOnRwNJniYrJGjya7Tx/M+vWVv/Vnn5HTsydZw4aVW0nMulyEr7yS/MWLEz1NlWCbNaPwpZcIl1npy1hLYNw4si69FIqKKp2vI/fPP8c/ebIjVnz66RSfddYu3VdERERqTqrFyxZjTHOgG7DKWrt1R7eUlgQyxriB6cDJwP7A+caY/Ss49Rlrbafka1by2j8ANwJdgM7AjcaYpsnz7wMGAB2Sr14pfh6RXeadPRv3Z585YqHx42vN8KN4x44ULFxIpG/fcm3eBQvIPeooPG++mdrNCgoIjBpFbvfueD7+uFxztFMnChYsIHTrrZCXV7WEfT5CU6YQvP12rNvtbHrhBXJOOQVTanPOSolEyL7iCufwvmbNCE6ZUmuel4iIiOxcqsXLPcBS4EkSRQjAUcBXKV7fGVhjrV1rrY0As4EzUrz2JOAta+3v1tr/AW8BvYwxLYFG1trF1loLPAb8JcV7iuyaggIC48Y5QpG//pVYly4ZSmg7cnII3nUXhY8+im3c2NHk2riRnHPOITBiBIRC272F5/XXyevaFf+0aeUn5OfmEpw0icL584l36rTr+RpD5NJLKZwzh3jTpo4mz4oV5PbogbuC1cx2xj95Mu6VKx2x4JQp2GbNdildERERqVkpFS/W2knACcBR1trZyfA64NLtX+WwJ/BjqeOfkrGyzjLGfGaMed4Y02Yn1+6Z/Hpn9xSpdv677sL1yy8lx9bvJ1Rmw8PaJHrGGeR/8EG5eSUA/hkzyD3hBFxff+2Im//+l+yLLiLnvPNw/fRTueuKTzstMSH/8suhTE/Jrop160bhggXE9tvPEXetX09O7954n3465Xu5ly/HP3WqIxY5+2yip59eLbmKiIhIzTE2xYmwxhgv0BVoZa19xhiTA2Ct3en6q8aYPkAva+2lyeO/A12stQNLnbMbUGCtDRtjLgfOtdb2MMYMBQLW2luS540GgsBCYKK19oRk/Bjgn9baksH2mzdvLvlwq1evTulziuyM95dfOLBPH9ylVqz6uV8/1l19dQazSlEsRsuHH6bVrFnlelFifj8/DhnCxjPOYI/nn2fP++7DXcHyyuEWLfjPsGFsPvbYtKfrKijgj6NH06SCPXR+ufBCfho4cIeFkwmH2f/vfyfru+9KYpFmzVg5ezaxMj1RIiIiknkdSs3Xbdy4cbmx3SkVL8aYg4C5QBhoba3NNcacAvS11p6bwvVHAjdZa09KHo8EsNbeup3z3cDv1trGxpjzgeOstZcn2+4nUbgsBN6x1u6XjDvOA2fxInXD6tWrHf/R1kZZl12G79lnS47ju+9O/scfp30p5Ork/ugjsgcMqHCJ43jz5rgqmMxv3W4iV15JaMQIyM3dpfev1HOOxfDfcguBMr0nAMUnnkjRrFmwnUIkMHo0/nvuccQKn3mG6EknVTpnqby68P0su07PuWHQc24Yattzrqh4SXXOy33AmGShsHXG67vA0SlevxToYIxpb4zxAeeRKIZKJOewbHU68GXy6zeAnsaYpsmJ+j2BN6y1P5NYSKBrcpWxi4CXU8xHpErcH3/sKFyAxE7xdahwAYh16UL+++8TqWClrYoKl+hhh1HwzjuEbrlllwuXSnO7Cd94I0UPPID1+x1N3rfeIvfEE3F9+235yxYvxjdtmiMWufBCFS4iIiJ1WKrFywHAE8mvLZQMF8tK5WJrbRQYSKIQ+RJ41lq70hhzszFm68Dza40xK40xnwLXAv2S1/4OjCNRAC0Fbk7GAK4CZgFrgG+Bf6X4eUQqz1oCZZZGjh1wAMUXXpihhHZR48YEZ82i6N57y+1yv5XNyyN4220Uvvkm8YMPruEEnYrPOYfCf/2LeMuWjrj7m2/I7dEDzzvvbAsWFpJ11VWYUj3L8datCY4fX1PpioiISBqkWrx8DxxWOmCM6UyiaEiJtXaetXZfa+3e1trxydgYa+3c5NcjrbUHWGs7Wmu7W2u/KnXtQ9bafZKvh0vFl1lrD0zec6BNdQKPSBV4X3oJz+LFjlhwwoRqn6xeo4yh+G9/o+C994gecoijqfiMM8hfsoTIgAG15jPGDj00saHlYY5/jjCbN5Pdpw++GTMSRebYsbjXrnWcUzRt2naHl4mIiEjd4EnxvNHAa8aYGYAvOWflChJ7rIjUf6EQgRtvdISKe/Ui1q1bhhKqXvG996bwjTfwPfkkrpUriZ56KtHu3TOdVoVsy5YUvvoqWYMGOYbwmViMrBEj8LzzDt433nBcE+7fn9hxx9VwpiIiIlLdUiperLWvGmN6kShW3gXaAX+11pbfrU6kHvLfd59jcrv1eAiV2eelzvP5iJTZ4b7WysoieP/9xA44gMBNNzmGh5UtXGJ77UVo7NiazlBERETSYKfFS3Llr4eAy6y1V6U/JZHaxWzYgH/KFEcs0r8/8Vq0GkeDZAyRQYOI77cf2ZdeisnPL3eKNYbg9Ok1v8iAiIiIpMVO57xYa2MkVviKpz8dkdrHP2GC4wfjeJMmhEeMyGBGUlr0pJMoeOstYu3bl2uLXHEFsaOOykBWIiIikg6pTtifCoxNblQp0mC4Vq7E99hjjlj4n//ENm2aoYykIvH99qNwwQKipeYgxQ48kNCYMRnMSkRERKpbqhP2rwFaAEOMMb+SXC4ZwFrbNh2JiWRccmlkE9/W6Rjbe28i/ftnMCnZHtu0KYUvvIBn3jzM779T/Ne/QlZKq7mLiIhIHZFq8VJHN7IQqTrPm2/iXbjQEQuNGwc+X2YSkp3zeIiefvrOzxMREZE6KdXVxt5NdyIitUpxMYFRoxyh6LHHEj355AwlJCIiIiIpzXkxxniNMWONMWuNMaHkn2ONMfoVtNRLvocewr16dcmxNSaxO7sxGcxKREREpGFLddjYZKAziY0pfyCxz8tooBEwOD2piWTIpk34J050hIovvJD4QQdlKCERERERgdSLl7OBjtba35LHXxtjlgOfouJF6pnApEm4/ve/kmObm0uozBAyEREREal5qS6VvL2xMhpDI/WKa80afDNnOmLhwYOxzZtnKCMRERER2SrV4uU54BVjzEnGmP8zxvQCXgKeTV9qIjUvMGYMJhotOY63bk34qqsymJGIiIiIbJXqsLHhwChgOtAKWAfMBm5JU14iNc793nt4581zxEI33aS9QkRERERqiVSXSo4AY5IvkfonFiPr+usdoegRR1B81lkZSkhEREREykp1qeQRxpgjysQ6G2OGpyctkZrlffJJ3F984YiFJkzQ0sgiIiIitUiqc14GAavKxFYB11VvOiIZkJ9PYPx4RyjSpw+xI47YzgUiIiIikgmpFi8+oLhMLAIEqjcdkZrnv+suXOvXlxzbQIDQGI2QFBEREaltUi1ePgbKLrl0BbC8etMRqVnmxx/xT5vmiIWvvhrbtm2GMhIRERGR7Ul1tbHBwFvGmL8D3wJ7Ay2AE9OVmEhNCIwdiwmFSo7jzZsTvk6jIUVERERqo1RXG1tpjNkX6A20AeYAr1prC9KZnEg6uZcuxff8845Y6IYbIC8vQxmJiIiIyI6k2vNCslCZbYxpArQH4mnLSiTdrCVQZmnk2IEHUnzBBRlKSERERER2ZodzXowxw40xfy113Av4D4k5MD8aY7qkOT+RtPDOmYNn6VJHLDh+PLjdGcpIRERERHZmZxP2LwFKb35xN3APkAdMAW5NU14i6RMMErjxRkeo+OSTiXXrlqGERERERCQVOyteWlprvwEwxuwDtANutdYWArcDB6c5P5Fq57/3Xlw//VRybD0eQuPGZTAjEREREUnFzoqXImNMo+TXRwOflZqkH6cSc2ZEagOzfj3+qVMdsciAAcT32SdDGYmIiIhIqnZWvMwDHjDGnA4MBV4o1dYR+DFdiYmkQ2D8eEzBtkXy4k2aEB4+PIMZiYiIiEiqdla8DAGKgPHAh0DpX1n3AmanKS+Rauf6/HO8jz/uiIVHjMA2bZqhjERERESkMnY47Mtau5nEpP2K2m5JS0Yi6WAtWTfcgLG2JBTr0IFI//4ZTEpEREREKmNnPS8i9YLnX//C8957jlho3DjwejOUkYiIiIhUlooXaRD8U6Y4jqPduhE96aQMZSMiIiIiVaHiReq/LVtwL1/uCAXHjwdjMpSQiIiIiFSFihep99zLl2Pi8ZLj2L77Ej/wwAxmJCIiIiJVkVLxYhIGGGMWGGM+S8aONcack+obGWN6GWO+NsasMcaM2MF5ZxljrDHm8OTxBcaYFaVecWNMp2TbwuQ9t7btkWo+0nB4PvrIcRzr0iVDmYiIiIjIrki15+VmoD/wANA2GfsJ+GcqFxtj3MB04GRgf+B8Y8z+FZyXBwwCSn7atNY+aa3tZK3tBPwd+M5au6LUZRdsbbfWbkjx80gD4l6yxHEc7dw5Q5mIiIiIyK5ItXjpB/S21s4Gtq41+x3wxxSv7wyssdautdZGSOwPc0YF540DJgGh7dznfLS3jFRGLIZn6VJnSD0vIiIiInVSqsWLG9i6LfnW4iW3VGxn9gR+LHX8UzJWwhhzKNDGWvvaDu5zLvB0mdjDySFjo43RDGxxcn31FWbLlpLjeNOmxPfZJ4MZiYiIiEhV7XCTylLmAVOMMYMhMQeGRC/JK9WRhDHGBUwh0cOzvXO6AEXW2i9KhS+w1q5LDjd7gcSwsscqun716tXVkarUgOp8Vs1efZW8UsdbDjiANd9+W233l6rT92TDoOfcMOg5Nwx6zg1Dpp9zhw4ddtieavEyBHgU2Ax4SfS4vAlclOL164A2pY5bJ2Nb5QEHAguTnSctgLnGmNOttcuS55xHmV4Xa+265J/5xpinSAxPq7B42dlfhNQOq1evrtZnlfXdd47jQI8e+m+hFqju5yy1k55zw6Dn3DDoOTcMdeE5p1S8WGu3AGcmV/NqB/xorf2lEu+zFOhgjGlPomg5D/hbqftvBpptPTbGLASGbi1ckj0z5wDHlDrHAzSx1m40xniB3sDblchJGgBN1hcRERGpP1IqXowxPYHvrbXfABuSsT8Bba21b+3semtt1BgzEHiDxPyZh6y1K40xNwPLrLVzd3KLY0kUTGtLxfzAG8nCxU2icJmZyueRhsFs2IB77bb/ZKzbTezQQzOYkYiIiIjsilSHjU0nUUCUlp+M75vKDay180jMnSkdG7Odc48rc7wQ6FomVggclsp7S8NUttcldvDBkJ2doWxEREREZFelutrYHtban8vEfiYxN0WkVvKULV40ZExERESkTku1eFlrjOlRJnYcib1eRGqlcj0vXbtu50wRERERqQtSHTZ2EzDHGPMg8C2wN3Bx8iVS+4TDuD/5xBHSZH0RERGRui2lnhdr7ctATyAHODX550nJuEit4/70U0w4XHIcb90au+eeO7hCRERERGq7VHtesNYuAZbs9ESRWsD90UeOY/W6iIiIiNR9qS6V7AP6AZ2A3NJt1tpUN6oUqTGarC8iIiJS/6Ta8/Io0BF4BVifvnREqoG15Ten1GR9ERERkTov1eKlF9DeWrspncmIVAfzww+41m+rsW12NvEDDshgRiIiIiJSHVJdKvk/JHa0F6n1PGXmu8QOPRS83gxlIyIiIiLVJdWel8eAl40xd1Fm2Ji1dkG1ZyWyC8oNGevSJUOZiIiIiEh1SrV4GZj8c0KZuAX+WH3piOy6cj0vKl5ERERE6oWUihdrbft0JyJSLbZswbVqlSMUO+KIDCUjIiIiItUp1TkvGGO8xphjjDHnJo9zjDE56UtNpPLcy5dj4vGS49if/oRt2jSDGYmIiIhIdUmpeDHGHAR8A8wEHkyGuwEPpSkvkSopN2RM+7uIiIiI1Bup9rzcB4yx1u4HFCdj7wJHpyUrkSpylyleoipeREREROqNVIuXA4Ankl9bAGttIZCVjqREqiQWw7NsmTOkzSlFRERE6o1Ui5fvgcNKB4wxnYE11Z2QSFW5vvoKs2VLyXG8aVPi++yTwYxEREREpDqlulTyaOA1Y8wMwGeMGQlcAQxIW2YileQps79LrHNnMCZD2YiIiIhIdUup58Va+yrQC9idxFyXdsBfrbVvpjE3kUopO99F+7uIiIiI1C877XkxxrhJrCp2mbX2qvSnJFI1mqwvIiIiUr/ttOfFWhsDegLxnZ0rkilmwwbc331Xcmw9HmKHHprBjERERESkuqU6YX8qMNYY401nMiJV5S473+XggyE7O0PZiIiIiEg6pDph/xqgBTDEGPMryeWSAay1bdORmEhlVDhZX0RERETqlVSLlwvTmoXILirX86LJ+iIiIiL1TkrFi7X23XQnIlJl4TDuTz5xhDRZX0RERKT+SWnOizHGb4wZb4xZa4zZnIz1NMYMTG96Ijvn/vRTTDhcchxv3Rq7554ZzEhERERE0qEyE/YPBC5g23yXlcCV6UhKpDLKLZGsIWMiIiIi9VKqc17OBPax1hYaY+IA1tp1xhj9elsyTpP1RURERBqGVHteIpQpdIwxuwO/VXtGIpVhbbnJ+up5EREREamfUi1engMeNca0BzDGtASmAbPTlZhIKswPP+Bav77k2GZnEz/ggAxmJCIiIiLpkmrxcj3wHfA50ARYDY71QBUAAB3xSURBVPwXuDlNeYmkxFNmvkvssMPAq71URUREROqjVJdKjgCDgcHJ4WIbrbV2J5eJpJ2GjImIiIg0HKlO2McY0xj4E5CbPAbAWrsgLZmJpKBcz4sm64uIiIjUWykVL8aYfsB0oAAoKtVkgT9Wf1oiKdiyBdeqVY5Q7IgjMpSMiIiIiKRbqnNexgN9rLXNrbXtS71SLlyMMb2MMV8bY9YYY0bs4LyzjDHWGHN48ngvY0zQGLMi+ZpR6tzDjDGfJ+95t9naHSQNgufjjzHxeMlxbL/9sE2bZjAjEREREUmnVIeNeYA3q/omxhg3iZ6bE4GfgKXGmLnW2lVlzssDBgEflbnFt9baThXc+j5gQPL8eUAv4F9VzVPqlrKbU2rImIiIiEj9lmrPyyRglDEm1fPL6gyssdauTU7+nw2cUcF545LvFdrZDZPLNTey1v5/e3ceJWV953v88+2qamgWRdCILIpRXBFFxH1BEY05LsnEcSRxjOc62SbecNVx9JpEg2KM3glmzozXyYzRJM4Y48QscCWyGBFcUEABBWMaRA+gsePCKr1U1ff+UU8XVdUrdHc9z1P1fp3Th/p9n+1b/TvPsb/+fr/nWRo8PODnkj63l/khhtos1qd4AQAAqGgdjryY2Ubl1rRIkkkaLukfzazoxZTufnA3rjNS0saC9iZJRY+FMrMTJY129yfN7KaS4w81s1clbZP0HXdfEpxzU8k5R3YjF1SCTEbJ5cuLQzxpDAAAoKJ1Nm3sqnIlEYzozJJ0TTub35N0sLt/aGYTJf3WzPb4LYT19fU9SxJl052+qlu3Tsdu25Zvt+y7r950l+jn2OCerA70c3Wgn6sD/Vwdwu7nsWPHdrq9w+LF3Z/txTw2Sxpd0B4VxFoNljRO0qJgzf1wSbPN7FJ3Xy6pKchphZmtl3REcPyoTs5ZpKtfBKKhvr6+W31Vu2RJceC00zT2iCP6KCv0tu72M+KNfq4O9HN1oJ+rQxz6uVtrWMwsZWYzzOwtM2sM/p1hZrXdvM4ySWPN7NDgmCslzW7d6O5b3X1/dx/j7mMkLZV0qbsvN7MDggX/MrNPSxor6S13f0/SNjM7NXjK2NWSftfdL454a7NYnyljAAAAFa+7Txu7V7lF91+X9I6kQyR9V9I+kq7v6mB3T5vZdZLmSUpIesjd15jZHZKWu/vsTg4/W9IdZtYiKSvp6+7+UbDt7yX9VFKdck8Z40ljVYLF+gAAANWnu8XLX0s63t1bF+u/aWavSFqlbhQvkuTuc5V7nHFh7LYO9p1c8PkJSU90sN9y5aaboYpYQ4MSGzbk255MKjNhQogZAQAAoBy6++jjjl7+yEshUXaloy6Z8eOlAQNCygYAAADl0t3i5b8lzTGzC83saDP7jKTfSnq871ID2pdkvQsAAEBV6u60sX+U9B1J90saodxTvR6TNLOP8gI61Ga9C8ULAABAVehW8eLuzZJuC36A8DQ1KfHqq0WhzKRJISUDAACAcup02piZnWFm93Sw7QdmdmrfpAW0L7Fqlay5Od/OjholHzkyxIwAAABQLl2teblV0uIOtj0r6du9mw7QudL3uzBlDAAAoHp0VbycIOmpDrYtkDSxd9MBOsdifQAAgOrVVfGyj6TaDralJA3u3XSATrjzckoAAIAq1lXx8kdJF3Sw7YJgO1AW9s47qmloyLd9wABlx/GOUgAAgGrR1dPG7pP0YzNLSPqtu2fNrEbS55R7bPINfZ0g0KrNlLGJE6Vkd5/2DQAAgLjr9C8/d3/UzIZL+pmkfmb2gaT9JTVJut3df1GGHAFJvN8FAACg2nX5v63dfZaZPSjpNEnDJH0o6UV339bXyQGFkkuXFrVZrA8AAFBduvuSym2S5vVxLogo+/hjJRctkrZvV/qii+QHHFD+JLZtU83atUWhNC+nBAAAqCosGEBb2awSq1YpuWCBkgsXKrF8uSybzW0aNUo7Fi6UDx9e1pSSK1bI3PPtzFFHSUOGlDUHAAAAhIviBZKC0ZU//CFXsDz9tGr+8pd296vZtEn9b71Vux56qKz5lb6cMsMjkgEAAKoOxUu1ymZVs3q1UvPntxld6Urtr3+tlmnTlJ46tY+T3I3F+gAAAKB4qSLdHV1pjw8cKNu5M9+uu+EGbV+6VBo4sC9SLZbJKLlsWXGI4gUAAKDqULxUstbRlQULlFywYI9GV3yffZQ+5xy1TJ2q9PnnyxoaNOi88/LH12zcqP733KPGO+7oy2+Qu9Ybb8i2b8+3s0OHKnvYYX1+XQAAAEQLxUuF6cnoSubYY/PFSuaUU6RUKr/NR4xQ89e+pn4PPJCP1d5/v5ovv1zZ8eN79TuUSpZMGcucfLJk1qfXBAAAQPRQvFSCHTtU++CDSv3+90osW9b90ZXBg5WePDlXsEyZIh85stP9G7/9baXmzFHNpk2SJMtkVHf99do5f76USPT4a3SkzWJ9powBAABUJYqXuHPXwMsvb/MCx45kjjlG6alT1TJ1apvRlS4NGqRd996rgV/8Yj6UXLFCtT/5iZq/+tU9zbzbWKwPAAAAieIl9mpWr+60cNnT0ZWupD/7WbVccolSc+bkY/3vvFMtF18sHzGiR+dujzU0KLFhQ77tyaQyEyb0+nUAAAAQfRQvMZeaP79NLD+60rp2pba2V6+56557lFy0KL+I3rZvV93NN+uTRx7p1etI7UwZO/54qa6u168DAACA6KsJOwH0THLBgqL2rh/+UDteeEGNM2Yoc9ZZvV64SLnF+43f/W5RLDVnjpJz5/b6tdpdrA8AAICqRPESY/bhh0qUvP+k5aKLynLt5muvVXrixKJY3U03SQWPNO4NrHcBAABAK4qXGEs+/bTMPd/OjBvXJ+tO2pVIaNePfiQveMpYzebN6v/97/feNZqalHj11aIQTxoDAACoXhQvMVY6ZazlwgvLev3sccep+ZvfLIrV/vjHqlm5slfOn1i5UtbcvPt6o0fLDzqoV84NAACA+KF4iatMRsmFC4tC6alTy55G4803Kzt6dL5t2awGTJ8updM9PjdTxgAAAFCI4iWmEsuXq+bjj/Pt7H77KTNpUvkTGThQu2bNKgolVq1S7b//e49PnSx90hiL9QEAAKoaxUtMlU4ZS0+Z0qdvue9MeupUNX/+80Wx/nfdJdu4ce9P6t525IXiBQAAoKpRvMRUat68onYYU8YKNd59t3yfffJt27kz9/SxggcK7Al75x3VNDTk2z5woLLjxvU4TwAAAMQXxUsM2bvvKvHaa/m2myl9/vkhZiT58OFq/N73imKpp55Scs6cvTpfcunSonZm4kQpyTtVAQAAqhnFSwyVLtTPnHSSfNiwkLLZrfmaa9osqq+7+WZp69Y9PhdTxgAAAFCK4iWGUvPnF7XDnjKWV1OjXffdJy8YIal57z31nzlzj0/VZrE+TxoDAACoemUrXszsM2b2ppmtM7NbOtnvC2bmZnZS0J5qZivM7LXg3/MK9l0UnHNl8POpcnyXUDU3K7loUVGo5YILwsmlHdljjlHTt75VFKt98EElli/v/km2bVPN2rVFoXQYT1IDAABApJSleDGzhKT7JV0k6RhJ08zsmHb2GyxpuqTC/+3+gaRL3P04SV+W9EjJYV9y9xOCnwZVuMSLL8p27Mi3swceqOz48SFm1FbTTTcpM2ZMvm3uqps+XWpp6dbxyRUrZAUL/TNHHy0NGdLbaQIAACBmyjXycrKkde7+lrs3S3pM0mXt7HenpHskNbYG3P1Vd383aK6RVGdm/fo64ahqd8pYTcRm/9XVqfG++4pCiTVrVPvAA906PFG6WJ/1LgAAAFD5ipeRkgpf+rEpiOWZ2YmSRrv7k52c5wuSXnH3poLYw8GUse+amfVaxhFV+n6XlqisdymRPvdcNV9xRVGs/913y95+u8tjWawPAACA9kTi2bNmViNplqRrOtnnWOVGZQoXeHzJ3TcH082ekPS3kn7e3vH19fW9lm9Yajdt0vg//SnfziYS+tPBBysT0e+WvPZajXvqKSW3bZMk2a5d8m98Q/X//M9SR3VmJqOakuJl/YEHqimi3xF7rxLuSXSNfq4O9HN1oJ+rQ9j9PHbs2E63l6t42SxpdEF7VBBrNVjSOEmLgsGT4ZJmm9ml7r7czEZJ+o2kq919fetB7r45+He7mT2q3PS0douXrn4RcVD7zDNF7ezpp+vTEyaElE33NM+cqWTBAv59X3xRx7z+ulr+6q/a3X/T3LlK7NyZb2eHDdPBU6Z0XOwglurr6yvinkTn6OfqQD9XB/q5OsShn8s1bWyZpLFmdqiZ1Uq6UtLs1o3uvtXd93f3Me4+RtJSSa2FyxBJT0q6xd2fbz3GzJJmtn/wOSXpYkmvl+n7hCJZst4lSk8Z60jLVVcpfdppRbH+t9wibdnS7v6DVq8uamdOPpnCBQAAAJLKVLy4e1rSdZLmSXpD0uPuvsbM7jCzS7s4/DpJh0u6reSRyP0kzTOz1ZJWKjeS8x999y1C9sknSi5ZUhSKzPtdOlNTo10/+pE8ldodamhQ/xkz2t190KpVRe3Sl14CAACgepVtzYu7z5U0tyR2Wwf7Ti74PFNSR285nNhb+UVdcskSWdPu5xRkDz5Y2SOPDDGj7sseeaSarr9e/e+9Nx/r9/DDavmbv1Hm1FOL9h3Y3sgLAAAAoDK+pBI90+6UsRhNp2q64QZlDj+8KFZ3/fVSc3O+be+/r/6bdy+F8lRKmYiv6QEAAED5ULzEgXvb97vEYL1Lkf79tWvWrKJQ4o031O9f/mV3u+QpY5njj5fq6sqSHgAAAKKP4iUGav74R9Vs3P2aHO/fX+kzzwwxo72TOftsNU+bVhTrd++9qnnrLUlSsrR4YcoYAAAAClC8xEDpiynTZ50lDRgQUjY90zhzprJDh+bb1tSk/jfcILkr8dJLRfuyWB8AAACFKF5iIPZTxgr4sGFqnFn8/IXUokVKPfKIEitXFsUZeQEAAEAhipeo27pViaVLi0ItcXhEcidapk1T+uyzi2J1N94oK1i8nx09Wn7QQeVODQAAABFG8RJxyUWLZOl0vp058kj5mDHhJdQbzLRr1ix5v367Qy0tRbukSx6hDAAAAFC8RFybKWMxH3VplT38cDXdeGOH25kyBgAAgFIUL1GWzbZZrB/3KWOFmqZPV6aDF22mKV4AAABQguIlwmpWr1ZNQ0O+7YMHK3PaaSFm1Mv69dOu++5rE/aBA5U99tgQEgIAAECUUbxEWGrevKJ2evJkqbY2nGT6SOb009V89dXFsYkTpWQypIwAAAAQVRQvEVbJU8YKNc6YocwRR0iS3ExN110XckYAAACIIv73dkTZBx8osWJFUaxSFuuX8v32047585VcskQbUimNjvF7bAAAANB3GHmJqOTChTL3fDszfnxlv/dkyBClL7lEjYcdFnYmAAAAiCiKl4hqM2WM0QgAAABUOYqXKEqnlVq4sDhE8QIAAIAqR/ESQYlly2Rbt+bb2aFDc0/gAgAAAKoYxUsElU4ZS59/vpRIhJQNAAAAEA0ULxHU5v0uFfqUMQAAAGBPULxEjG3erMSaNfm219QoPWVKiBkBAAAA0UDxEjGlU8YykybJhw4NKRsAAAAgOiheIiY1f35RmyljAAAAQA7FS5Q0NSn57LNFId7vAgAAAORQvERI8oUXZDt35tvZ4cOVPe64EDMCAAAAooPiJUKS7U0ZMwspGwAAACBaKF4ipLR4YcoYAAAAsBvFS0TUrF+vxPr1+banUkpPnhxeQgAAAEDEULxERJtHJJ9+ujR4cEjZAAAAANFD8RIRbaaM8YhkAAAAoAjFSxTs3Knkc88VhdKsdwEAAACKULxEQHLxYllzc76dGTNG2bFjQ8wIAAAAiB6KlwjgEckAAABA1yhewuauVMlifaaMAQAAAG1RvISsZu1a1WzalG97XZ3SZ54ZYkYAAABANJWteDGzz5jZm2a2zsxu6WS/L5iZm9lJBbH/HRz3pplduKfnjLLSRySnzz5bqqsLKRsAAAAgupLluIiZJSTdL2mqpE2SlpnZbHdfW7LfYEnTJb1UEDtG0pWSjpU0QtJCMzsi2NzlOaMuVbrehSljAAAAQLvKNfJysqR17v6WuzdLekzSZe3sd6ekeyQ1FsQuk/SYuze5+wZJ64Lzdfec0bVlixIvvVQUajn//JCSAQAAAKKtXMXLSEkbC9qbgliemZ0oabS7P9nNY7s8Z9SlnnlGlsnk25mjjpIfckiIGQEAAADRVZZpY10xsxpJsyRd01fXqK+v76tT77Uxv/qVBhS0/zJpkjZFMM9yi2JfoffRz9WBfq4O9HN1oJ+rQ9j9PLaLdx2Wq3jZLGl0QXtUEGs1WNI4SYss936T4ZJmm9mlXRzb2TmLdPWLKLtsVoNLpowNuuKK6OVZZvX19VX/O6gG9HN1oJ+rA/1cHejn6hCHfi7XtLFlksaa2aFmVqvcAvzZrRvdfau77+/uY9x9jKSlki519+XBfleaWT8zO1TSWEkvd3XOqEusXKmaDz7It32ffZQ59dQQMwIAAACirSwjL+6eNrPrJM2TlJD0kLuvMbM7JC139w6LjmC/xyWtlZSW9E13z0hSe+fs6+/SW5Lz5hW10+eeK6VSIWUDAAAARF/Z1ry4+1xJc0tit3Ww7+SS9l2S7urOOeOi9P0uLVOnhpQJAAAAEA9le0kldrOGBiVfeaUolqZ4AQAAADpF8RKC5MKFRe30CSfIDzwwpGwAAACAeKB4CUHplDFGXQAAAICuUbyUW0uLUk8/XRRKX3hhSMkAAAAA8UHxUmaJl1+WbduWb2eHDVNmwoQQMwIAAADigeKlzFLz5xe101OmSIlESNkAAAAA8UHxUmZt1rswZQwAAADoFoqXMrKNG5VYuzbf9poapc87L8SMAAAAgPigeCmjVMmoS+aUU+T77RdSNgAAAEC8ULyUUbJ0vQuPSAYAAAC6jeKlXBoblVy8uCjUQvECAAAAdBvFS5kkn39e9skn+XZ2xAhlx40LMSMAAAAgXiheyqTdKWNmIWUDAAAAxA/FSzm4tyleWi64IKRkAAAAgHiieCmDmvXrldiwId/2VErpc84JMSMAAAAgfiheyqDNlLEzzpAGDQopGwAAACCeKF7KoE3xwpQxAAAAYI9RvPS1HTuUfP75ohDFCwAAALDnKF76WPK552QtLfl25tBDlT3ssBAzAgAAAOIpGXYClS594YXavnixUgsWKLlggTInnsgjkgEAAIC9QPHS18yUHT9eTePHq+nGGyX3sDMCAAAAYolpY+XGqAsAAACwVyheAAAAAMQCxQsAAACAWKB4AQAAABALFC8AAAAAYoHiBQAAAEAsULwAAAAAiAWKFwAAAACxQPECAAAAIBYoXgAAAADEAsULAAAAgFigeAEAAAAQC+buYefQZ7Zu3Vq5Xw4AAACoYPvuu6+Vxhh5AQAAABALFC8AAAAAYqGip40BAAAAqByMvAAAAACIBYoXRIKZvW1mr5nZSjNbHnY+6D1m9pCZNZjZ6wWxoWa2wMzqg3/3CzNH9FwH/fw9M9sc3NcrzeyzYeaInjGz0Wb2jJmtNbM1ZjY9iHM/V5BO+pn7uYKYWX8ze9nMVgX9PCOIH2pmL5nZOjP7pZnVhp1rKaaNIRLM7G1JJ7n7B2Hngt5lZmdL2iHp5+4+LojdK+kjd/+Bmd0iaT93vznMPNEzHfTz9yTtcPd/CjM39A4zO0jSQe7+ipkNlrRC0uckXSPu54rRST9fIe7nimFmJmmgu+8ws5Sk5yRNl3SDpF+7+2Nm9m+SVrn7A2HmWoqRFwB9yt0XS/qoJHyZpJ8Fn3+m3H8YEWMd9DMqiLu/5+6vBJ+3S3pD0khxP1eUTvoZFcRzdgTNVPDjks6T9KsgHsn7meIFUeGS5pvZCjP7atjJoM8d6O7vBZ//LOnAMJNBn7rOzFYH08qYTlQhzGyMpAmSXhL3c8Uq6WeJ+7mimFnCzFZKapC0QNJ6SVvcPR3sskkRLFwpXhAVZ7r7iZIukvTNYAoKqoDn5q4yf7UyPSDpMEknSHpP0g/DTQe9wcwGSXpC0v9y922F27ifK0c7/cz9XGHcPePuJ0gaJelkSUeFnFK3ULwgEtx9c/Bvg6TfKHcToXK9H8yrbp1f3RByPugD7v5+8B/HrKT/EPd17AVz45+Q9F/u/usgzP1cYdrrZ+7nyuXuWyQ9I+k0SUPMLBlsGiVpc2iJdYDiBaEzs4HBokCZ2UBJF0h6vfOjEHOzJX05+PxlSb8LMRf0kdY/aAOfF/d1rAULfH8i6Q13n1Wwifu5gnTUz9zPlcXMDjCzIcHnOklTlVvf9Iyky4PdInk/87QxhM7MPq3caIskJSU96u53hZgSepGZ/ULSZEn7S3pf0u2SfivpcUkHS3pH0hXuzmLvGOugnycrN8XEJb0t6WsFayMQM2Z2pqQlkl6TlA3Ctyq3HoL7uUJ00s/TxP1cMcxsvHIL8hPKDWY87u53BH+TPSZpqKRXJV3l7k3hZdoWxQsAAACAWGDaGAAAAIBYoHgBAAAAEAsULwAAAABigeIFAAAAQCxQvAAAAACIBYoXAECfMLOfmtnMkK5tZvawmX1sZi+X8bpHmNmWcl0PAKoNxQsAVAkze9vMGoKXwbbG/s7MFoWYVl85U7mXro1y96I3gZvZrWa2I/hpNLNMQXtNTy7q7n9y9yE9OQcAoGMULwBQXRKSpoedxJ4ys8QeHnKIpLfdfWfpBnf/vrsPcvdBkr4u6cXWtrsf2xv5AgD6BsULAFSX/yPpH8yszeiAmY0xMzezZEFskZn9XfD5GjN73szuM7MtZvaWmZ0exDcGozpfLjnt/ma2wMy2m9mzZnZIwbmPCrZ9ZGZvmtkVBdt+amYPmNlcM9sp6dx28h1hZrOD49eZ2VeC+LWSHpR0WjCaMmNPf0lmdo6ZvWJmW81sqZlNKti21MzuNLMVwfYnzGzfgu+ULth3fzP7uZn9OZjC9ssgPtzMngp+jx+a2R/2NEcAqEYULwBQXZZLWiTpH/by+FMkrZY0TNKjkh6TNEnS4ZKukvSvZjaoYP8vSbpT0v6SVkr6L0kKpq4tCM7xKUlXSvq/ZnZMwbFflHSXpMGSnmsnl8ckbZI0QtLlkr5vZue5+09UPKJy+558QTP7lKQ5kn4QfM9/kzS3tUAJXB18t5GSaiX9sIPT/VKSSTpK0oGS7g/iN0t6U7nfy0GSvrcnOQJAtaJ4AYDqc5uk/2lmB+zFsRvc/WF3zyj3h/loSXe4e5O7z5fUrFwh0+pJd1/s7k2Svq3caMhoSRcrN63rYXdPu/urkp6Q9NcFx/7O3Z9396y7NxYmEZzjDEk3u3uju69UbrTl6r34TqUuk7TS3R8PcvupckXSRQX7POzuf3T3HZJulzSt9CRmdqiksyT9vbtvcfdmd18cbG5Rrug6uCQOAOgExQsAVBl3f13S/5N0y14c/n7B513B+UpjhSMvGwuuu0PSR8r90X6IpFOCaVNbgid0fUnS8PaObccISR+5+/aC2DvKjYT01IjgXIVKz72xZNuAkpEZKVfYNZTk2OouSe9KeiaY8nZDD3MGgKpA8QIA1el2SV9R8R/krYvbBxTECouJvTG69UMwnWyocn+0b5T0rLsPKfgZ5O7fKDjWOznvu5KGmtnggtjBkjb3MN/Wcx9SEis99+iSbZ+4+9aSYzZK+lTJNDpJkrtvdffp7n6IpC9I+o6ZndHz1AGgslG8AEAVcvd1yk37+lZB7C/K/YF+lZklzOx/SDqsh5f6rJmdaWa1yq19WeruG5Ub+TnCzP7WzFLBzyQzO7qb+W+U9IKku82sv5mNl3StpP/sYb6SNFvSBDO73MySZna1cgXK7wv2uSZ4p8sg5dar/LKdHDdIWqzcOqB9zazWzM6WJDO71Mw+bWYmaaukjKRsL+QOABWN4gUAqtcdkgaWxL4i6SZJH0o6VrkCoSceVW6U5yNJE5Vb1K9gKtUFyi3Uf1fSnyXdI6nfHpx7mqQxwfG/kXS7uy/sYb6t0+AuVW6NzoeSrpN0ccnIyiOSfqFcsZeVdGMnOaYk1Sv3HVtHlo6W9Iyk7coVOP/k7i/2NHcAqHTm3tmoPAAAKGRmSyX9q7v3xigPAGAPMPICAAAAIBYoXgAAAADEAtPGAAAAAMQCIy8AAAAAYoHiBQAAAEAsULwAAAAAiAWKFwAAAACxQPECAAAAIBYoXgAAAADEwv8HtiKJUBX321AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot graph showing number of topics per model and corresponding coherence scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "x_ax = range(2,31,1)\n",
    "y_ax = coherence_scores\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_ax, y_ax,c='r')\n",
    "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "x1 = plt.xlabel('Number of Topics')\n",
    "y1 = plt.ylabel('Coherence Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on graph, choose optimal number of topics as 20\n",
    "# retrieve best model\n",
    "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 20].index[0]\n",
    "best_lda_model = lda_models[best_model_idx]\n",
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['training', 'kernel', 'noise', 'training_set', 'test', 'regression', 'optimal', 'estimate', 'machine', 'size', 'ensemble', 'average', 'variance', 'generalization', 'experiment', 'cross_validation', 'regularization', 'generalization_error', 'margin', 'pruning']\n",
      "\n",
      "Topic #2:\n",
      "['cell', 'neuron', 'activity', 'pattern', 'response', 'stimulus', 'synaptic', 'cortical', 'layer', 'connection', 'receptive_field', 'cortex', 'map', 'orientation', 'simulation', 'et_al', 'synapsis', 'visual', 'mechanism', 'spatial']\n",
      "\n",
      "Topic #3:\n",
      "['prediction', 'expert', 'nonlinear', 'linear', 'training', 'variable', 'time_series', 'predicted', 'trained', 'predictive', 'predictor', 'estimate', 'predict', 'selection', 'spline', 'architecture', 'risk', 'table', 'ann', 'test']\n",
      "\n",
      "Topic #4:\n",
      "['class', 'classification', 'classifier', 'feature', 'node', 'pattern', 'tree', 'cluster', 'clustering', 'search', 'category', 'experiment', 'training', 'probability', 'test', 'distance', 'measure', 'rule', 'database', 'sample']\n",
      "\n",
      "Topic #5:\n",
      "['unit', 'training', 'layer', 'net', 'hidden_unit', 'pattern', 'task', 'architecture', 'trained', 'activation', 'back_propagation', 'hidden_layer', 'hidden', 'connection', 'training_set', 'learn', 'backpropagation', 'generalization', 'epoch', 'target']\n",
      "\n",
      "Topic #6:\n",
      "['memory', 'bit', 'vector', 'code', 'capacity', 'processor', 'parallel', 'block', 'graph', 'size', 'connection', 'cost', 'stored', 'operation', 'address', 'communication', 'node', 'application', 'cycle', 'associative_memory']\n",
      "\n",
      "Topic #7:\n",
      "['image', 'object', 'feature', 'motion', 'pixel', 'visual', 'face', 'view', 'representation', 'location', 'filter', 'vision', 'part', 'field', 'scale', 'recognition', 'direction', 'spatial', 'scene', 'edge']\n",
      "\n",
      "Topic #8:\n",
      "['technique', 'task', 'center', 'rbf', 'application', 'rate', 'level', 'sample', 'accuracy', 'user', 'detection', 'important', 'domain', 'test', 'resolution', 'location', 'difficult', 'range', 'type', 'study']\n",
      "\n",
      "Topic #9:\n",
      "['vector', 'matrix', 'linear', 'component', 'source', 'transformation', 'nonlinear', 'signal', 'basis', 'coefficient', 'map', 'pca', 'dimensional', 'ica', 'rule', 'projection', 'technique', 'operator', 'representation', 'mapping']\n",
      "\n",
      "Topic #10:\n",
      "['word', 'recognition', 'speech', 'training', 'character', 'hmm', 'feature', 'frame', 'letter', 'speaker', 'context', 'sequence', 'state', 'digit', 'trained', 'speech_recognition', 'phoneme', 'segmentation', 'experiment', 'vowel']\n",
      "\n",
      "Topic #11:\n",
      "['circuit', 'neuron', 'current', 'chip', 'voltage', 'analog', 'synapse', 'neural', 'gain', 'implementation', 'signal', 'design', 'device', 'pulse', 'synaptic', 'transistor', 'digital', 'threshold', 'synapsis', 'array']\n",
      "\n",
      "Topic #12:\n",
      "['state', 'action', 'control', 'step', 'policy', 'controller', 'reinforcement_learning', 'environment', 'task', 'robot', 'optimal', 'goal', 'reward', 'trajectory', 'td', 'agent', 'current', 'trial', 'dynamic', 'adaptive']\n",
      "\n",
      "Topic #13:\n",
      "['target', 'control', 'subject', 'human', 'movement', 'motor', 'position', 'response', 'behavior', 'change', 'trajectory', 'stimulus', 'direction', 'location', 'cue', 'sensory', 'task', 'feedback', 'et_al', 'hand']\n",
      "\n",
      "Topic #14:\n",
      "['distribution', 'probability', 'gaussian', 'prior', 'variable', 'density', 'mixture', 'bayesian', 'estimate', 'log', 'likelihood', 'approximation', 'sample', 'component', 'em', 'posterior', 'variance', 'step', 'estimation', 'structure']\n",
      "\n",
      "Topic #15:\n",
      "['dynamic', 'state', 'equation', 'solution', 'energy', 'neuron', 'theory', 'eq', 'fixed_point', 'noise', 'attractor', 'phase', 'field', 'behavior', 'limit', 'teacher', 'temperature', 'find', 'student', 'stable']\n",
      "\n",
      "Topic #16:\n",
      "['local', 'region', 'distance', 'fig', 'surface', 'global', 'group', 'element', 'mapping', 'constraint', 'edge', 'shape', 'contour', 'direction', 'configuration', 'path', 'boundary', 'curve', 'neighborhood', 'line']\n",
      "\n",
      "Topic #17:\n",
      "['bound', 'class', 'probability', 'threshold', 'theorem', 'size', 'polynomial', 'node', 'linear', 'complexity', 'hypothesis', 'proof', 'theory', 'concept', 'distribution', 'variable', 'definition', 'dimension', 'assume', 'defined']\n",
      "\n",
      "Topic #18:\n",
      "['signal', 'neuron', 'frequency', 'spike', 'noise', 'firing', 'channel', 'temporal', 'response', 'phase', 'rate', 'stimulus', 'delay', 'neural', 'threshold', 'amplitude', 'filter', 'event', 'oscillator', 'sound']\n",
      "\n",
      "Topic #19:\n",
      "['convergence', 'vector', 'rate', 'equation', 'optimal', 'condition', 'approximation', 'gradient', 'iteration', 'update', 'xi', 'constant', 'line', 'note', 'defined', 'define', 'gradient_descent', 'loss', 'stochastic', 'optimization']\n",
      "\n",
      "Topic #20:\n",
      "['rule', 'sequence', 'representation', 'structure', 'recurrent', 'state', 'pattern', 'module', 'node', 'activation', 'unit', 'symbol', 'memory', 'language', 'level', 'string', 'connectionist', 'context', 'step', 'role']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view all the 20 topics generated by selected best model\n",
    "topics = [[(term, round(wt, 3)) \n",
    "           for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
    "              for n in range(0, best_lda_model.num_topics)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "      <th>Topic 16</th>\n",
       "      <th>Topic 17</th>\n",
       "      <th>Topic 18</th>\n",
       "      <th>Topic 19</th>\n",
       "      <th>Topic 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Term1</th>\n",
       "      <td>training</td>\n",
       "      <td>cell</td>\n",
       "      <td>prediction</td>\n",
       "      <td>class</td>\n",
       "      <td>unit</td>\n",
       "      <td>memory</td>\n",
       "      <td>image</td>\n",
       "      <td>technique</td>\n",
       "      <td>vector</td>\n",
       "      <td>word</td>\n",
       "      <td>circuit</td>\n",
       "      <td>state</td>\n",
       "      <td>target</td>\n",
       "      <td>distribution</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>local</td>\n",
       "      <td>bound</td>\n",
       "      <td>signal</td>\n",
       "      <td>convergence</td>\n",
       "      <td>rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term2</th>\n",
       "      <td>kernel</td>\n",
       "      <td>neuron</td>\n",
       "      <td>expert</td>\n",
       "      <td>classification</td>\n",
       "      <td>training</td>\n",
       "      <td>bit</td>\n",
       "      <td>object</td>\n",
       "      <td>task</td>\n",
       "      <td>matrix</td>\n",
       "      <td>recognition</td>\n",
       "      <td>neuron</td>\n",
       "      <td>action</td>\n",
       "      <td>control</td>\n",
       "      <td>probability</td>\n",
       "      <td>state</td>\n",
       "      <td>region</td>\n",
       "      <td>class</td>\n",
       "      <td>neuron</td>\n",
       "      <td>vector</td>\n",
       "      <td>sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term3</th>\n",
       "      <td>noise</td>\n",
       "      <td>activity</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>classifier</td>\n",
       "      <td>layer</td>\n",
       "      <td>vector</td>\n",
       "      <td>feature</td>\n",
       "      <td>center</td>\n",
       "      <td>linear</td>\n",
       "      <td>speech</td>\n",
       "      <td>current</td>\n",
       "      <td>control</td>\n",
       "      <td>subject</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>equation</td>\n",
       "      <td>distance</td>\n",
       "      <td>probability</td>\n",
       "      <td>frequency</td>\n",
       "      <td>rate</td>\n",
       "      <td>representation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term4</th>\n",
       "      <td>training_set</td>\n",
       "      <td>pattern</td>\n",
       "      <td>linear</td>\n",
       "      <td>feature</td>\n",
       "      <td>net</td>\n",
       "      <td>code</td>\n",
       "      <td>motion</td>\n",
       "      <td>rbf</td>\n",
       "      <td>component</td>\n",
       "      <td>training</td>\n",
       "      <td>chip</td>\n",
       "      <td>step</td>\n",
       "      <td>human</td>\n",
       "      <td>prior</td>\n",
       "      <td>solution</td>\n",
       "      <td>fig</td>\n",
       "      <td>threshold</td>\n",
       "      <td>spike</td>\n",
       "      <td>equation</td>\n",
       "      <td>structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term5</th>\n",
       "      <td>test</td>\n",
       "      <td>response</td>\n",
       "      <td>training</td>\n",
       "      <td>node</td>\n",
       "      <td>hidden_unit</td>\n",
       "      <td>capacity</td>\n",
       "      <td>pixel</td>\n",
       "      <td>application</td>\n",
       "      <td>source</td>\n",
       "      <td>character</td>\n",
       "      <td>voltage</td>\n",
       "      <td>policy</td>\n",
       "      <td>movement</td>\n",
       "      <td>variable</td>\n",
       "      <td>energy</td>\n",
       "      <td>surface</td>\n",
       "      <td>theorem</td>\n",
       "      <td>noise</td>\n",
       "      <td>optimal</td>\n",
       "      <td>recurrent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term6</th>\n",
       "      <td>regression</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>variable</td>\n",
       "      <td>pattern</td>\n",
       "      <td>pattern</td>\n",
       "      <td>processor</td>\n",
       "      <td>visual</td>\n",
       "      <td>rate</td>\n",
       "      <td>transformation</td>\n",
       "      <td>hmm</td>\n",
       "      <td>analog</td>\n",
       "      <td>controller</td>\n",
       "      <td>motor</td>\n",
       "      <td>density</td>\n",
       "      <td>neuron</td>\n",
       "      <td>global</td>\n",
       "      <td>size</td>\n",
       "      <td>firing</td>\n",
       "      <td>condition</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term7</th>\n",
       "      <td>optimal</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>time_series</td>\n",
       "      <td>tree</td>\n",
       "      <td>task</td>\n",
       "      <td>parallel</td>\n",
       "      <td>face</td>\n",
       "      <td>level</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>feature</td>\n",
       "      <td>synapse</td>\n",
       "      <td>reinforcement_learning</td>\n",
       "      <td>position</td>\n",
       "      <td>mixture</td>\n",
       "      <td>theory</td>\n",
       "      <td>group</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>channel</td>\n",
       "      <td>approximation</td>\n",
       "      <td>pattern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term8</th>\n",
       "      <td>estimate</td>\n",
       "      <td>cortical</td>\n",
       "      <td>predicted</td>\n",
       "      <td>cluster</td>\n",
       "      <td>architecture</td>\n",
       "      <td>block</td>\n",
       "      <td>view</td>\n",
       "      <td>sample</td>\n",
       "      <td>signal</td>\n",
       "      <td>frame</td>\n",
       "      <td>neural</td>\n",
       "      <td>environment</td>\n",
       "      <td>response</td>\n",
       "      <td>bayesian</td>\n",
       "      <td>eq</td>\n",
       "      <td>element</td>\n",
       "      <td>node</td>\n",
       "      <td>temporal</td>\n",
       "      <td>gradient</td>\n",
       "      <td>module</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term9</th>\n",
       "      <td>machine</td>\n",
       "      <td>layer</td>\n",
       "      <td>trained</td>\n",
       "      <td>clustering</td>\n",
       "      <td>trained</td>\n",
       "      <td>graph</td>\n",
       "      <td>representation</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>basis</td>\n",
       "      <td>letter</td>\n",
       "      <td>gain</td>\n",
       "      <td>task</td>\n",
       "      <td>behavior</td>\n",
       "      <td>estimate</td>\n",
       "      <td>fixed_point</td>\n",
       "      <td>mapping</td>\n",
       "      <td>linear</td>\n",
       "      <td>response</td>\n",
       "      <td>iteration</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term10</th>\n",
       "      <td>size</td>\n",
       "      <td>connection</td>\n",
       "      <td>predictive</td>\n",
       "      <td>search</td>\n",
       "      <td>activation</td>\n",
       "      <td>size</td>\n",
       "      <td>location</td>\n",
       "      <td>user</td>\n",
       "      <td>coefficient</td>\n",
       "      <td>speaker</td>\n",
       "      <td>implementation</td>\n",
       "      <td>robot</td>\n",
       "      <td>change</td>\n",
       "      <td>log</td>\n",
       "      <td>noise</td>\n",
       "      <td>constraint</td>\n",
       "      <td>complexity</td>\n",
       "      <td>phase</td>\n",
       "      <td>update</td>\n",
       "      <td>activation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term11</th>\n",
       "      <td>ensemble</td>\n",
       "      <td>receptive_field</td>\n",
       "      <td>predictor</td>\n",
       "      <td>category</td>\n",
       "      <td>back_propagation</td>\n",
       "      <td>connection</td>\n",
       "      <td>filter</td>\n",
       "      <td>detection</td>\n",
       "      <td>map</td>\n",
       "      <td>context</td>\n",
       "      <td>signal</td>\n",
       "      <td>optimal</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>likelihood</td>\n",
       "      <td>attractor</td>\n",
       "      <td>edge</td>\n",
       "      <td>hypothesis</td>\n",
       "      <td>rate</td>\n",
       "      <td>xi</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term12</th>\n",
       "      <td>average</td>\n",
       "      <td>cortex</td>\n",
       "      <td>estimate</td>\n",
       "      <td>experiment</td>\n",
       "      <td>hidden_layer</td>\n",
       "      <td>cost</td>\n",
       "      <td>vision</td>\n",
       "      <td>important</td>\n",
       "      <td>pca</td>\n",
       "      <td>sequence</td>\n",
       "      <td>design</td>\n",
       "      <td>goal</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>approximation</td>\n",
       "      <td>phase</td>\n",
       "      <td>shape</td>\n",
       "      <td>proof</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>constant</td>\n",
       "      <td>symbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term13</th>\n",
       "      <td>variance</td>\n",
       "      <td>map</td>\n",
       "      <td>predict</td>\n",
       "      <td>training</td>\n",
       "      <td>hidden</td>\n",
       "      <td>stored</td>\n",
       "      <td>part</td>\n",
       "      <td>domain</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>state</td>\n",
       "      <td>device</td>\n",
       "      <td>reward</td>\n",
       "      <td>direction</td>\n",
       "      <td>sample</td>\n",
       "      <td>field</td>\n",
       "      <td>contour</td>\n",
       "      <td>theory</td>\n",
       "      <td>delay</td>\n",
       "      <td>line</td>\n",
       "      <td>memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term14</th>\n",
       "      <td>generalization</td>\n",
       "      <td>orientation</td>\n",
       "      <td>selection</td>\n",
       "      <td>probability</td>\n",
       "      <td>connection</td>\n",
       "      <td>operation</td>\n",
       "      <td>field</td>\n",
       "      <td>test</td>\n",
       "      <td>ica</td>\n",
       "      <td>digit</td>\n",
       "      <td>pulse</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>location</td>\n",
       "      <td>component</td>\n",
       "      <td>behavior</td>\n",
       "      <td>direction</td>\n",
       "      <td>concept</td>\n",
       "      <td>neural</td>\n",
       "      <td>note</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term15</th>\n",
       "      <td>experiment</td>\n",
       "      <td>simulation</td>\n",
       "      <td>spline</td>\n",
       "      <td>test</td>\n",
       "      <td>training_set</td>\n",
       "      <td>address</td>\n",
       "      <td>scale</td>\n",
       "      <td>resolution</td>\n",
       "      <td>rule</td>\n",
       "      <td>trained</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>td</td>\n",
       "      <td>cue</td>\n",
       "      <td>em</td>\n",
       "      <td>limit</td>\n",
       "      <td>configuration</td>\n",
       "      <td>distribution</td>\n",
       "      <td>threshold</td>\n",
       "      <td>defined</td>\n",
       "      <td>level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term16</th>\n",
       "      <td>cross_validation</td>\n",
       "      <td>et_al</td>\n",
       "      <td>architecture</td>\n",
       "      <td>distance</td>\n",
       "      <td>learn</td>\n",
       "      <td>communication</td>\n",
       "      <td>recognition</td>\n",
       "      <td>location</td>\n",
       "      <td>projection</td>\n",
       "      <td>speech_recognition</td>\n",
       "      <td>transistor</td>\n",
       "      <td>agent</td>\n",
       "      <td>sensory</td>\n",
       "      <td>posterior</td>\n",
       "      <td>teacher</td>\n",
       "      <td>path</td>\n",
       "      <td>variable</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>define</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term17</th>\n",
       "      <td>regularization</td>\n",
       "      <td>synapsis</td>\n",
       "      <td>risk</td>\n",
       "      <td>measure</td>\n",
       "      <td>backpropagation</td>\n",
       "      <td>node</td>\n",
       "      <td>direction</td>\n",
       "      <td>difficult</td>\n",
       "      <td>technique</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>digital</td>\n",
       "      <td>current</td>\n",
       "      <td>task</td>\n",
       "      <td>variance</td>\n",
       "      <td>temperature</td>\n",
       "      <td>boundary</td>\n",
       "      <td>definition</td>\n",
       "      <td>filter</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>connectionist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term18</th>\n",
       "      <td>generalization_error</td>\n",
       "      <td>visual</td>\n",
       "      <td>table</td>\n",
       "      <td>rule</td>\n",
       "      <td>generalization</td>\n",
       "      <td>application</td>\n",
       "      <td>spatial</td>\n",
       "      <td>range</td>\n",
       "      <td>operator</td>\n",
       "      <td>segmentation</td>\n",
       "      <td>threshold</td>\n",
       "      <td>trial</td>\n",
       "      <td>feedback</td>\n",
       "      <td>step</td>\n",
       "      <td>find</td>\n",
       "      <td>curve</td>\n",
       "      <td>dimension</td>\n",
       "      <td>event</td>\n",
       "      <td>loss</td>\n",
       "      <td>context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term19</th>\n",
       "      <td>margin</td>\n",
       "      <td>mechanism</td>\n",
       "      <td>ann</td>\n",
       "      <td>database</td>\n",
       "      <td>epoch</td>\n",
       "      <td>cycle</td>\n",
       "      <td>scene</td>\n",
       "      <td>type</td>\n",
       "      <td>representation</td>\n",
       "      <td>experiment</td>\n",
       "      <td>synapsis</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>et_al</td>\n",
       "      <td>estimation</td>\n",
       "      <td>student</td>\n",
       "      <td>neighborhood</td>\n",
       "      <td>assume</td>\n",
       "      <td>oscillator</td>\n",
       "      <td>stochastic</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term20</th>\n",
       "      <td>pruning</td>\n",
       "      <td>spatial</td>\n",
       "      <td>test</td>\n",
       "      <td>sample</td>\n",
       "      <td>target</td>\n",
       "      <td>associative_memory</td>\n",
       "      <td>edge</td>\n",
       "      <td>study</td>\n",
       "      <td>mapping</td>\n",
       "      <td>vowel</td>\n",
       "      <td>array</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>hand</td>\n",
       "      <td>structure</td>\n",
       "      <td>stable</td>\n",
       "      <td>line</td>\n",
       "      <td>defined</td>\n",
       "      <td>sound</td>\n",
       "      <td>optimization</td>\n",
       "      <td>role</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Topic 1          Topic 2       Topic 3         Topic 4  \\\n",
       "Term1               training             cell    prediction           class   \n",
       "Term2                 kernel           neuron        expert  classification   \n",
       "Term3                  noise         activity     nonlinear      classifier   \n",
       "Term4           training_set          pattern        linear         feature   \n",
       "Term5                   test         response      training            node   \n",
       "Term6             regression         stimulus      variable         pattern   \n",
       "Term7                optimal         synaptic   time_series            tree   \n",
       "Term8               estimate         cortical     predicted         cluster   \n",
       "Term9                machine            layer       trained      clustering   \n",
       "Term10                  size       connection    predictive          search   \n",
       "Term11              ensemble  receptive_field     predictor        category   \n",
       "Term12               average           cortex      estimate      experiment   \n",
       "Term13              variance              map       predict        training   \n",
       "Term14        generalization      orientation     selection     probability   \n",
       "Term15            experiment       simulation        spline            test   \n",
       "Term16      cross_validation            et_al  architecture        distance   \n",
       "Term17        regularization         synapsis          risk         measure   \n",
       "Term18  generalization_error           visual         table            rule   \n",
       "Term19                margin        mechanism           ann        database   \n",
       "Term20               pruning          spatial          test          sample   \n",
       "\n",
       "                 Topic 5             Topic 6         Topic 7      Topic 8  \\\n",
       "Term1               unit              memory           image    technique   \n",
       "Term2           training                 bit          object         task   \n",
       "Term3              layer              vector         feature       center   \n",
       "Term4                net                code          motion          rbf   \n",
       "Term5        hidden_unit            capacity           pixel  application   \n",
       "Term6            pattern           processor          visual         rate   \n",
       "Term7               task            parallel            face        level   \n",
       "Term8       architecture               block            view       sample   \n",
       "Term9            trained               graph  representation     accuracy   \n",
       "Term10        activation                size        location         user   \n",
       "Term11  back_propagation          connection          filter    detection   \n",
       "Term12      hidden_layer                cost          vision    important   \n",
       "Term13            hidden              stored            part       domain   \n",
       "Term14        connection           operation           field         test   \n",
       "Term15      training_set             address           scale   resolution   \n",
       "Term16             learn       communication     recognition     location   \n",
       "Term17   backpropagation                node       direction    difficult   \n",
       "Term18    generalization         application         spatial        range   \n",
       "Term19             epoch               cycle           scene         type   \n",
       "Term20            target  associative_memory            edge        study   \n",
       "\n",
       "               Topic 9            Topic 10        Topic 11  \\\n",
       "Term1           vector                word         circuit   \n",
       "Term2           matrix         recognition          neuron   \n",
       "Term3           linear              speech         current   \n",
       "Term4        component            training            chip   \n",
       "Term5           source           character         voltage   \n",
       "Term6   transformation                 hmm          analog   \n",
       "Term7        nonlinear             feature         synapse   \n",
       "Term8           signal               frame          neural   \n",
       "Term9            basis              letter            gain   \n",
       "Term10     coefficient             speaker  implementation   \n",
       "Term11             map             context          signal   \n",
       "Term12             pca            sequence          design   \n",
       "Term13     dimensional               state          device   \n",
       "Term14             ica               digit           pulse   \n",
       "Term15            rule             trained        synaptic   \n",
       "Term16      projection  speech_recognition      transistor   \n",
       "Term17       technique             phoneme         digital   \n",
       "Term18        operator        segmentation       threshold   \n",
       "Term19  representation          experiment        synapsis   \n",
       "Term20         mapping               vowel           array   \n",
       "\n",
       "                      Topic 12    Topic 13       Topic 14     Topic 15  \\\n",
       "Term1                    state      target   distribution      dynamic   \n",
       "Term2                   action     control    probability        state   \n",
       "Term3                  control     subject       gaussian     equation   \n",
       "Term4                     step       human          prior     solution   \n",
       "Term5                   policy    movement       variable       energy   \n",
       "Term6               controller       motor        density       neuron   \n",
       "Term7   reinforcement_learning    position        mixture       theory   \n",
       "Term8              environment    response       bayesian           eq   \n",
       "Term9                     task    behavior       estimate  fixed_point   \n",
       "Term10                   robot      change            log        noise   \n",
       "Term11                 optimal  trajectory     likelihood    attractor   \n",
       "Term12                    goal    stimulus  approximation        phase   \n",
       "Term13                  reward   direction         sample        field   \n",
       "Term14              trajectory    location      component     behavior   \n",
       "Term15                      td         cue             em        limit   \n",
       "Term16                   agent     sensory      posterior      teacher   \n",
       "Term17                 current        task       variance  temperature   \n",
       "Term18                   trial    feedback           step         find   \n",
       "Term19                 dynamic       et_al     estimation      student   \n",
       "Term20                adaptive        hand      structure       stable   \n",
       "\n",
       "             Topic 16      Topic 17    Topic 18          Topic 19  \\\n",
       "Term1           local         bound      signal       convergence   \n",
       "Term2          region         class      neuron            vector   \n",
       "Term3        distance   probability   frequency              rate   \n",
       "Term4             fig     threshold       spike          equation   \n",
       "Term5         surface       theorem       noise           optimal   \n",
       "Term6          global          size      firing         condition   \n",
       "Term7           group    polynomial     channel     approximation   \n",
       "Term8         element          node    temporal          gradient   \n",
       "Term9         mapping        linear    response         iteration   \n",
       "Term10     constraint    complexity       phase            update   \n",
       "Term11           edge    hypothesis        rate                xi   \n",
       "Term12          shape         proof    stimulus          constant   \n",
       "Term13        contour        theory       delay              line   \n",
       "Term14      direction       concept      neural              note   \n",
       "Term15  configuration  distribution   threshold           defined   \n",
       "Term16           path      variable   amplitude            define   \n",
       "Term17       boundary    definition      filter  gradient_descent   \n",
       "Term18          curve     dimension       event              loss   \n",
       "Term19   neighborhood        assume  oscillator        stochastic   \n",
       "Term20           line       defined       sound      optimization   \n",
       "\n",
       "              Topic 20  \n",
       "Term1             rule  \n",
       "Term2         sequence  \n",
       "Term3   representation  \n",
       "Term4        structure  \n",
       "Term5        recurrent  \n",
       "Term6            state  \n",
       "Term7          pattern  \n",
       "Term8           module  \n",
       "Term9             node  \n",
       "Term10      activation  \n",
       "Term11            unit  \n",
       "Term12          symbol  \n",
       "Term13          memory  \n",
       "Term14        language  \n",
       "Term15           level  \n",
       "Term16          string  \n",
       "Term17   connectionist  \n",
       "Term18         context  \n",
       "Term19            step  \n",
       "Term20            role  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build term topic dataframe\n",
    "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
    "                              for topic in topics], \n",
    "                         columns=['Term'+str(i) for i in range(1,21)], \n",
    "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-b134729433ab>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-b134729433ab>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for topic in topics],\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# create topic term dataframe: each topic represented in a row with terms of topic\n",
    "# represented as comma-separated string\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic]) \n",
    "                              for topic in topics], \n",
    "                         columns=['Terms per Topic'], \n",
    "                         index=['Topic'+str(t) for t in range (1, best_lda_model.num_topics+1)])\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and scores\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "filename = 'lda_models.sav'\n",
    "loaded_ldas = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "coherence_scores = np.genfromtxt('coherence_scores.csv', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
