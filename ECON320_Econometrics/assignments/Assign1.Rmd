---
title: "Assignment 1 Econ320"
author: "Belicia Rodriguez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document: 
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(wooldridge)
library(AER)
library(knitr)
```

# Effects of wages on education
 
From the package AER use the dataset PSID1982 (Cross-section data originating from the Panel Study on Income Dynamics, 1982). In this assignment we will use this data to investigate the effect of eduction on wages for this population. 

Let's first investigate our data and a few relationships in it. This is a little of what I call the motivation part of your regression analysis. This is very simple you will have to do more involved things in your final project. 


These two tables show the proportion of women and men in the dataset and the proportion of people that reside in a standard metropolitan statistical area. 
```{r}
data("PSID1982", package = "AER")
prop.table(table(PSID1982$gender))
prop.table(table(PSID1982$smsa))

```

The following table looks at the correlation table between wages education and experience. 
What can you say about this correlations, do they have the expected sign?
```{r}
round(cor(PSID1982 %>% select(wage, education, experience)), 3)
```

What about the average of some variables for the sample, and some statistics by gender?

Here we use the package dplyr, the function `summarise_all()`, `summarise()` to make the calculations, and the functions `gather()` and `spread()` to present the tables in a better way. Figure out where to use the right function. 

What can you say about these results? What can you say about the avergae values for women vs men?

The results show that although women and men receive the same amount of education, men get more experience and attain higher wages than women.

```{r, results='asis'}
PSID1982 %>% select(wage, education, experience) %>% summarise_all(mean) %>% gather(means, values) %>% kable()
```

```{r}
PSID1982 %>% select(wage, education, experience, gender) %>% summarise(avgeduc=round(mean(education),1), avgexper=round(mean(experience),1), avgwage=round(mean(wage),0), cor_wagvseduc=round(cor(wage,education),3)) %>% gather(mean, wage)

PSID1982 %>% group_by(gender) %>% select(wage, education, experience, gender) %>% summarise(avgeduc=round(mean(education),1), avgexper=round(mean(experience),1), avgwage=round(mean(wage),0), cor_wagvseduc=round(cor(wage,education),3))

```





# Graphs 

Let's look at those numbers using graphs. 
```{r}

ggplot(PSID1982 , aes(education, wage))+
  geom_point(color="red", alpha=.5)+
  geom_smooth(method="lm")+ 
   ggtitle("Wage vs Educ")


ggplot(PSID1982 , aes(education , wage))+
  geom_point(color = "red")+
  geom_smooth(method="lm")+ 
  facet_grid(~gender)+ 
  ggtitle('Wage vs Educ') + 
  xlab('Education') +
  ylab('Wage')
  
```

# Simple regression analysis

Now let's use the data to estimate the following equation
$$ wage = \beta_0 + \beta_1*education + u $$

Estimate this equation using the step by step method learned last class, the method the minimizes SSR and the variance covarance method. (3 ways first)

Var(X) = $\frac{\sum_{i=1}^{n} (x_i-\tilde{X})^2}{n-1}$
Cov(X) = $\frac{\sum_{i=1}^{n} (x_i-\tilde{X})(y_i-\tilde{Y})}{n-1}$

### Equation system results: step-by-step
```{r}
x <- PSID1982$education
y <- PSID1982$wage

(b1<-(sum((x-mean(x))*(y-mean(y))))/(sum((x- mean(x))^2)))
(b0<-mean(y)-b1*mean(x)) 
```

### Function minimization results 
```{r}
dat<-data.frame(x,y)

min.SSR <- function(data, par){sum((y - par[1] - (par[2]*x))^2)}

result<-optim(par=c(b0,b1) , fn=min.SSR, data=dat)

round(result$par,3)
```

### Covariance , variance method
Using the `cov(x,y)` and `var(x)` functions in R calculate the $\hat\beta_0, \hat\beta_1$ based on the equation below.
$$\hat\beta_1=\frac{Cov(x,y)}{Var(x)}$$ 
$$\hat\beta_0 = \bar{y} - \hat\beta_1 \bar{x}$$
```{r}
(b1 <- cov(x, y)/var(x))

(b0 <- mean(y) - b1*mean(x))
```

### lm() command 

Finally use the lm() command to estimate. Save your estimation in an object called reg and show the summary of your model. 
$$ log(wage) = \beta_0 + \beta_1*education + u $$
What can you say about this new results? Why is it better to use $log(wages)$?

I can say that for every additional year of education, wages increase by 0.07174%. It is better to use log(wage) because it is easier to interpret the amount of wage increase as a percentage rather than a monetary amount, where one cannot understand if 83.88 is a big or small wage increase relative to the wage before the increase.

What is your interpretation of the coeficients and the $R^2$?

The intercept (b_0) is the predicted log wage when education is 0. For education (b_1), for every additional year of education, wages increase by 0.07174%. $R^2$ says that education variable explains 20.85% of the variance in log(wage).
```{r}
(reg <- lm(log(y)~x, dat))
summary(reg)
 
```




