{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Feature Engineering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 30103\n",
      "\n",
      "Sample line: ['1', ':', '6', 'And', 'God', 'said', ',', 'Let', 'there', 'be', 'a', 'firmament', 'in', 'the', 'midst', 'of', 'the', 'waters', ',', 'and', 'let', 'it', 'divide', 'the', 'waters', 'from', 'the', 'waters', '.']\n",
      "\n",
      "Processed line: god said let firmament midst waters let divide waters waters\n"
     ]
    }
   ],
   "source": [
    "# Load Bible Corpus\n",
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation\n",
    "import nlp_models as nm\n",
    "import preprocessing as pre\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "\n",
    "bible = gutenberg.sents('bible-kjv.txt')\n",
    "remove_terms = punctuation + '0123456789'\n",
    "\n",
    "norm_bible = [[word.lower() for word in sent if word not in remove_terms] for sent in bible]\n",
    "norm_bible = [' '.join(tok_sent) for tok_sent in norm_bible]\n",
    "norm_bible = filter(None, pre.normalize_corpus(norm_bible))\n",
    "norm_bible = [tok_sent for tok_sent in norm_bible if len(tok_sent.split()) > 2]\n",
    "\n",
    "print('Total lines:', len(bible))\n",
    "print('\\nSample line:', bible[10])\n",
    "print('\\nProcessed line:', norm_bible[10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Word2Vec Models with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.3 s, sys: 273 ms, total: 39.6 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# build model\n",
    "w2v_model = nm.trainword2vec(norm_bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'god': ['lord', 'predestinated', 'redeemed', 'worldly', 'mercy'],\n",
       " 'jesus': ['messias', 'peter', 'synagogue', 'apostles', 'immediately'],\n",
       " 'noah': ['shem', 'japheth', 'ham', 'enosh', 'kenan'],\n",
       " 'egypt': ['pharaoh', 'egyptians', 'bondage', 'rod', 'flowing'],\n",
       " 'john': ['james', 'baptist', 'peter', 'baptism', 'galilee'],\n",
       " 'gospel': ['christ', 'faith', 'godly', 'hope', 'sufferings'],\n",
       " 'moses': ['congregation', 'aaron', 'joshua', 'sinai', 'children'],\n",
       " 'famine': ['pestilence', 'peril', 'sword', 'blasting', 'mildew']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view similar words based off model\n",
    "similar_words = nm.viewsimilarwords(w2v_model, search_term_list=['god', 'jesus', 'noah', 'egypt', \n",
    "                                                                  'john', 'gospel', 'moses', 'famine'])\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Word2Vec Features for ML Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type up corpus and labels\n",
    "corpus = ['The sky is blue and beautiful.',\n",
    "          'Love this blue and beautiful sky!',\n",
    "          'The quick brown fox jumps over the lazy dog.',\n",
    "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "          'I love green eggs, ham, sausages, and bacon!',\n",
    "          'The brown fox is quick and the blue dog is lazy!',\n",
    "          'The sky is very blue and the sky is very beautiful today',\n",
    "          'The dog is lazy but the brown fox is quick!']\n",
    "\n",
    "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
    "\n",
    "# normalize corpus\n",
    "norm_corpus = pre.normalize_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "w2v_model = nm.trainword2vec(norm_corpus, feature_size=10, window_context=10, iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: can't get same embedding visualizations as the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
