{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 3: Processing Pipelines\n",
    "\n",
    "This chapter will show you everything you need to know about spaCy's processing pipeline. You'll learn what goes on under the hood when you process a text, how to write your own components and add them to the pipeline, and how to use custom attributes to add your own metadata to the documents, spans and tokens.\n",
    "\n",
    "**Sections**\n",
    "\n",
    "1. Processing pipelines \n",
    "2. What happens when you call nlp? \n",
    "3. Inspecting the pipeline \n",
    "4. Custom pipeline components \n",
    "5. Use cases for custom components \n",
    "6. Simple components \n",
    "7. Complex components \n",
    "8. Extension attributes \n",
    "9. Setting extension attributes (Part 1) \n",
    "10. Setting extension attributes (Part 2) \n",
    "11. Entities and extensions \n",
    "12. Components with extensions \n",
    "13. Scaling and performance \n",
    "14. Processing streams \n",
    "15. Processing data with context \n",
    "16. Selective processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Processing pipelines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}